<?xml version="1.0" encoding=""utf-8"" ?> 
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" 
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">  
<!--http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd-->  
<html xmlns="http://www.w3.org/1999/xhtml"  
> 
<head><title>12 Correlation and linear regression</title> 
<meta http-equiv="Content-Type" content="text/html; charset="utf-8"" /> 
<meta name="generator" content="TeX4ht (http://www.tug.org/tex4ht/)" /> 
<meta name="originator" content="TeX4ht (http://www.tug.org/tex4ht/)" /> 
<!-- 2,html,xhtml,NoFonts,ext=htm,charset="utf-8" --> 
<meta name="src" content="lsj.tex" /> 
<link rel="stylesheet" type="text/css" href="lsj.css" /> 
</head><body 
>
   <!--l. 5--><div class="crosslinks"><p class="noindent">[<a 
href="lsjch13.html" >next</a>] [<a 
href="lsjch11.html" >prev</a>] [<a 
href="lsjch11.html#taillsjch11.html" >prev-tail</a>] [<a 
href="#taillsjch12.html">tail</a>] [<a 
href="lsjpa5.html#lsjch12.html" >up</a>] </p></div>
   <h2 class="chapterHead"><span class="titlemark">Chapter 12</span><br /><a 
 id="x114-24000012"></a>Correlation and linear regression</h2>
<!--l. 8--><p class="noindent" >The goal in this chapter is to introduce <span id="textcolor320">correlation</span> and <span id="textcolor321">linear regression</span>. These are the
standard tools that statisticians rely on when analysing the relationship between continuous
predictors and continuous outcomes.
</p>
   <h3 class="sectionHead"><span class="titlemark">12.1   </span> <a 
 id="x114-24100012.1"></a>Correlations</h3>
<!--l. 13--><p class="noindent" >In this section we’ll talk about how to describe the relationships between variables in the data. To
do that, we want to talk mostly about the <span id="textcolor322">correlation</span> between variables. But ﬁrst, we need some
data.
</p><!--l. 15--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">12.1.1   </span> <a 
 id="x114-24200012.1.1"></a>The data</h4>
   <div class="table">
                                                                                          

                                                                                          
<!--l. 17--><p class="indent" >   <a 
 id="x114-2420011"></a></p><hr class="float" /><div class="float" 
>
                                                                                          

                                                                                          
 <div class="caption" 
><span class="id">Table 12.1: </span><span  
class="content">Descriptive statistics for the parenthood data.</span></div><!--tex4ht:label?: x114-2420011 -->
<div class="center" 
>
<!--l. 20--><p class="noindent" >
</p>
<div class="tabular"> <table id="TBL-69" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-69-1g"><col 
id="TBL-69-1" /><col 
id="TBL-69-2" /><col 
id="TBL-69-3" /><col 
id="TBL-69-4" /><col 
id="TBL-69-5" /><col 
id="TBL-69-6" /><col 
id="TBL-69-7" /></colgroup><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-69-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-69-1-1"  
class="td11">variable                   </td><td  style="white-space:nowrap; text-align:right;" id="TBL-69-1-2"  
class="td11">min</td><td  style="white-space:nowrap; text-align:right;" id="TBL-69-1-3"  
class="td11"> max</td><td  style="white-space:nowrap; text-align:right;" id="TBL-69-1-4"  
class="td11">mean</td><td  style="white-space:nowrap; text-align:right;" id="TBL-69-1-5"  
class="td11">median</td><td  style="white-space:nowrap; text-align:right;" id="TBL-69-1-6"  
class="td11">std. dev</td><td  style="white-space:nowrap; text-align:right;" id="TBL-69-1-7"  
class="td11">IQR</td>
</tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-69-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-69-2-1"  
class="td11">Dan’s grumpiness       </td><td  style="white-space:nowrap; text-align:right;" id="TBL-69-2-2"  
class="td11"> 41</td><td  style="white-space:nowrap; text-align:right;" id="TBL-69-2-3"  
class="td11">  91</td><td  style="white-space:nowrap; text-align:right;" id="TBL-69-2-4"  
class="td11">63.71</td><td  style="white-space:nowrap; text-align:right;" id="TBL-69-2-5"  
class="td11">    62</td><td  style="white-space:nowrap; text-align:right;" id="TBL-69-2-6"  
class="td11">  10.05</td><td  style="white-space:nowrap; text-align:right;" id="TBL-69-2-7"  
class="td11">  14</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-69-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-69-3-1"  
class="td11">Dan’s hours slept       </td><td  style="white-space:nowrap; text-align:right;" id="TBL-69-3-2"  
class="td11">4.84</td><td  style="white-space:nowrap; text-align:right;" id="TBL-69-3-3"  
class="td11"> 9.00</td><td  style="white-space:nowrap; text-align:right;" id="TBL-69-3-4"  
class="td11"> 6.97</td><td  style="white-space:nowrap; text-align:right;" id="TBL-69-3-5"  
class="td11">   7.03</td><td  style="white-space:nowrap; text-align:right;" id="TBL-69-3-6"  
class="td11">   1.02</td><td  style="white-space:nowrap; text-align:right;" id="TBL-69-3-7"  
class="td11">1.45</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-69-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-69-4-1"  
class="td11">Dan’s son’s hours slept</td><td  style="white-space:nowrap; text-align:right;" id="TBL-69-4-2"  
class="td11">3.25</td><td  style="white-space:nowrap; text-align:right;" id="TBL-69-4-3"  
class="td11">12.07</td><td  style="white-space:nowrap; text-align:right;" id="TBL-69-4-4"  
class="td11"> 8.05</td><td  style="white-space:nowrap; text-align:right;" id="TBL-69-4-5"  
class="td11">   7.95</td><td  style="white-space:nowrap; text-align:right;" id="TBL-69-4-6"  
class="td11">   2.07</td><td  style="white-space:nowrap; text-align:right;" id="TBL-69-4-7"  
class="td11">3.21</td>
</tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-69-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-69-5-1"  
class="td11">                   </td></tr></table></div></div>
                                                                                          

                                                                                          
   </div><hr class="endfloat" />
   </div>
<!--l. 36--><p class="indent" >   Let’s turn to a topic close to every parent’s heart: sleep. The data set we’ll use is ﬁctitious, but
based on real events. Suppose I’m curious to ﬁnd out how much my infant son’s sleeping habits
aﬀect my mood. Let’s say that I can rate my grumpiness very precisely, on a scale from 0 (not
at all grumpy) to 100 (grumpy as a very, very grumpy old man or woman). And lets
also assume that I’ve been measuring my grumpiness, my sleeping patterns and my
son’s sleeping patterns for quite some time now. Let’s say, for 100 days. And, being a
nerd, I’ve saved the data as a ﬁle called parenthood.csv. If we load the data we can
see that the ﬁle contains four variables dan.sleep, baby.sleep, dan.grump and day.
Note that when you ﬁrst load this data set jamovi may not have guessed the data type
for each variable correctly, in which case you should ﬁx it: dan.sleep, baby.sleep,
dan.grump and day can be speciﬁed as continuous variables, and ID is a nominal(integer)
variable.<span class="footnote-mark"><a 
href="lsj115.html#fn1x13"><sup class="textsuperscript">1</sup></a></span><a 
 id="x114-242002f1"></a> 
</p><!--l. 38--><p class="indent" >   Next, I’ll take a look at some basic descriptive statistics and, to give a graphical depiction of what
each of the three interesting variables looks like, Figure <a 
href="#x114-2420041">12.1<!--tex4ht:ref: fig:parenthood --></a> plots histograms. One thing to note:
just because jamovi can calculate dozens of diﬀerent statistics doesn’t mean you should report all of
them. If I were writing this up for a report, I’d probably pick out those statistics that are of most
interest to me (and to my readership), and then put them into a nice, simple table like the one in
Table <a 
href="#x114-2420011">12.1<!--tex4ht:ref: tab:parenthood --></a>.<span class="footnote-mark"><a 
href="lsj116.html#fn2x13"><sup class="textsuperscript">2</sup></a></span><a 
 id="x114-242003f2"></a> 
Notice that when I put it into a table, I gave everything “human readable” names. This is always
good practice. Notice also that I’m not getting enough sleep. This isn’t good practice, but other
parents tell me that it’s pretty standard.
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x114-2420041"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 41--><p class="noindent" >
</p>
<div class="tabular">
 <table id="TBL-70" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-70-1g"><col 
id="TBL-70-1" /><col 
id="TBL-70-2" /><col 
id="TBL-70-3" /></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-70-1-"><td  style="white-space:nowrap; text-align:center;" id="TBL-70-1-1"  
class="td11"><img 
src="lsj202x.png" alt="PIC" class="graphics" width="128" height="128"  /><!--tex4ht:graphics  
name="lsj202x.png" src="../img/descriptives/grumpHist1.eps"  
--></td><td  style="white-space:nowrap; text-align:center;" id="TBL-70-1-2"  
class="td11"><img 
src="lsj203x.png" alt="PIC" class="graphics" width="128" height="128"  /><!--tex4ht:graphics  
name="lsj203x.png" src="../img/descriptives/grumpHist2.eps"  
--></td><td  style="white-space:nowrap; text-align:center;" id="TBL-70-1-3"  
class="td11"><img 
src="lsj204x.png" alt="PIC" class="graphics" width="128" height="128"  /><!--tex4ht:graphics  
name="lsj204x.png" src="../img/descriptives/grumpHist3.eps"  
--></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-70-2-"><td  style="white-space:nowrap; text-align:center;" id="TBL-70-2-1"  
class="td11">           (a)                 </td><td  style="white-space:nowrap; text-align:center;" id="TBL-70-2-2"  
class="td11">           (b)                  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-70-2-3"  
class="td11">            (c)                  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-70-3-"><td  style="white-space:nowrap; text-align:center;" id="TBL-70-3-1"  
class="td11">                        </td></tr></table></div>
<br /> <div class="caption" 
><span class="id">Figure 12.1: </span><span  
class="content">Histograms for the three interesting variables in the parenthood data set.</span></div><!--tex4ht:label?: x114-2420041 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
   <h4 class="subsectionHead"><span class="titlemark">12.1.2   </span> <a 
 id="x114-24300012.1.2"></a>The strength and direction of a relationship</h4>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x114-2430012"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 58--><p class="noindent" >
</p>
<div class="tabular">
 <table id="TBL-71" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-71-1g"><col 
id="TBL-71-1" /><col 
id="TBL-71-2" /></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-71-1-"><td  style="white-space:nowrap; text-align:center;" id="TBL-71-1-1"  
class="td11"><img 
src="lsj205x.png" alt="PIC" class="graphics" width="199" height="199"  /><!--tex4ht:graphics  
name="lsj205x.png" src="../img/descriptives/grumpCor1.eps"  
--></td><td  style="white-space:nowrap; text-align:center;" id="TBL-71-1-2"  
class="td11"><img 
src="lsj206x.png" alt="PIC" class="graphics" width="199" height="199"  /><!--tex4ht:graphics  
name="lsj206x.png" src="../img/descriptives/grumpCor2.eps"  
--></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-71-2-"><td  style="white-space:nowrap; text-align:center;" id="TBL-71-2-1"  
class="td11">                  (a)                            </td><td  style="white-space:nowrap; text-align:center;" id="TBL-71-2-2"  
class="td11">                 (b)                           </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-71-3-"><td  style="white-space:nowrap; text-align:center;" id="TBL-71-3-1"  
class="td11">                                      </td></tr></table></div>
<br /> <div class="caption" 
><span class="id">Figure 12.2: </span><span  
class="content">Scatterplots showing the relationship between dan.sleep and dan.grump (left)
and the relationship between baby.sleep and dan.grump (right).</span></div><!--tex4ht:label?: x114-2430012 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 70--><p class="noindent" >We can draw scatterplots to give us a general sense of how closely related two variables are.
Ideally though, we might want to say a bit more about it than that. For instance, let’s
compare the relationship between dan.sleep and dan.grump (Figure <a 
href="#x114-2430012">12.2<!--tex4ht:ref: fig:scatterparent --></a>, left) with that
between baby.sleep and dan.grump (Figure <a 
href="#x114-2430012">12.2<!--tex4ht:ref: fig:scatterparent --></a>, right). When looking at these two
plots side by side, it’s clear that the relationship is qualitatively the same in both cases:
more sleep equals less grump! However, it’s also pretty obvious that the relationship
between dan.sleep and dan.grump is stronger than the relationship between baby.sleep
and dan.grump. The plot on the left is “neater” than the one on the right. What it
feels like is that if you want to predict what my mood is, it’d help you a little bit to
know how many hours my son slept, but it’d be <span class="underline">more</span> helpful to know how many hours I
slept.
</p><!--l. 76--><p class="indent" >   In contrast, let’s consider the two scatterplots shown in Figure <a 
href="#x114-2430023">12.3<!--tex4ht:ref: fig:scatterparent2 --></a>. If we compare the
scatterplot of baby.sleep vs. dan.grump (left) to the scatterplot of baby.sleep vs.
dan.sleep (right), the overall strength of the relationship is the same, but the direction is
diﬀerent. That is, if my son sleeps more, I get more sleep (positive relationship, right
hand side), but if he sleeps more then I get less grumpy (negative relationship, left hand
side).
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x114-2430023"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 79--><p class="noindent" >
</p>
<div class="tabular">
 <table id="TBL-72" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-72-1g"><col 
id="TBL-72-1" /><col 
id="TBL-72-2" /></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-72-1-"><td  style="white-space:nowrap; text-align:center;" id="TBL-72-1-1"  
class="td11"><img 
src="lsj207x.png" alt="PIC" class="graphics" width="199" height="199"  /><!--tex4ht:graphics  
name="lsj207x.png" src="../img/descriptives/grumpCor2.eps"  
--></td><td  style="white-space:nowrap; text-align:center;" id="TBL-72-1-2"  
class="td11"><img 
src="lsj208x.png" alt="PIC" class="graphics" width="199" height="199"  /><!--tex4ht:graphics  
name="lsj208x.png" src="../img/descriptives/grumpCor3.eps"  
--></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-72-2-"><td  style="white-space:nowrap; text-align:center;" id="TBL-72-2-1"  
class="td11">                  (a)                            </td><td  style="white-space:nowrap; text-align:center;" id="TBL-72-2-2"  
class="td11">                 (b)                           </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-72-3-"><td  style="white-space:nowrap; text-align:center;" id="TBL-72-3-1"  
class="td11">                                      </td></tr></table></div>
<br /> <div class="caption" 
><span class="id">Figure 12.3: </span><span  
class="content">Scatterplots showing the relationship between baby.sleep and dan.grump
(left), as compared to the relationship between baby.sleep and dan.sleep (right).</span></div><!--tex4ht:label?: x114-2430023 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
   <h4 class="subsectionHead"><span class="titlemark">12.1.3   </span> <a 
 id="x114-24400012.1.3"></a>The correlation coeﬃcient</h4>
<!--l. 93--><p class="noindent" >We can make these ideas a bit more explicit by introducing the idea of a <span id="textcolor325">correlation coeﬃcient</span>
(or, more speciﬁcally, Pearson’s correlation coeﬃcient), which is traditionally denoted as r. The
correlation coeﬃcient between two variables X and Y (sometimes denoted r<sub>XY </sub>), which we’ll deﬁne
more precisely in the next section, is a measure that varies from  1 to 1. When r    1
it means that we have a perfect negative relationship, and when r   1 it means we
have a perfect positive relationship. When r   0, there’s no relationship at all. If you
look at Figure <a 
href="#x114-2440014">12.4<!--tex4ht:ref: fig:corr --></a>, you can see several plots showing what diﬀerent correlations look
like.
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x114-2440014"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 96--><p class="noindent" >
</p>
                                                                                          

                                                                                          
<div class="tabular"> <table id="TBL-73" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-73-1g"><col 
id="TBL-73-1" /><col 
id="TBL-73-2" /><col 
id="TBL-73-3" /><col 
id="TBL-73-4" /></colgroup><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-73-1-"><td colspan="2" style="white-space:nowrap; text-align:center;" id="TBL-73-1-1"  
class="td11">       <div class="multicolumn"  style="white-space:nowrap; text-align:center;">positive correlations</div>        </td><td colspan="2" style="white-space:nowrap; text-align:center;" id="TBL-73-1-3"  
class="td11">        <div class="multicolumn"  style="white-space:nowrap; text-align:center;">negative correlations</div>
</td></tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-73-2-"><td  style="white-space:nowrap; text-align:center;" id="TBL-73-2-1"  
class="td11">0.0
     </td><td  style="white-space:nowrap; text-align:center;" id="TBL-73-2-2"  
class="td11"><img 
src="lsj209x.png" alt="PIC" class="graphics" width="128" height="128"  /><!--tex4ht:graphics  
name="lsj209x.png" src="../img/descriptives/corr0.eps"  
--></td><td  style="white-space:nowrap; text-align:center;" id="TBL-73-2-3"  
class="td11"> 0.0
        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-73-2-4"  
class="td11"><img 
src="lsj210x.png" alt="PIC" class="graphics" width="128" height="128"  /><!--tex4ht:graphics  
name="lsj210x.png" src="../img/descriptives/corr0.eps"  
--></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-73-3-"><td  style="white-space:nowrap; text-align:center;" id="TBL-73-3-1"  
class="td11">0.33
     </td><td  style="white-space:nowrap; text-align:center;" id="TBL-73-3-2"  
class="td11"><img 
src="lsj211x.png" alt="PIC" class="graphics" width="128" height="128"  /><!--tex4ht:graphics  
name="lsj211x.png" src="../img/descriptives/corr33.eps"  
--></td><td  style="white-space:nowrap; text-align:center;" id="TBL-73-3-3"  
class="td11"> 0.33
        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-73-3-4"  
class="td11"><img 
src="lsj212x.png" alt="PIC" class="graphics" width="128" height="128"  /><!--tex4ht:graphics  
name="lsj212x.png" src="../img/descriptives/corr33n.eps"  
--></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-73-4-"><td  style="white-space:nowrap; text-align:center;" id="TBL-73-4-1"  
class="td11">0.66
     </td><td  style="white-space:nowrap; text-align:center;" id="TBL-73-4-2"  
class="td11"><img 
src="lsj213x.png" alt="PIC" class="graphics" width="128" height="128"  /><!--tex4ht:graphics  
name="lsj213x.png" src="../img/descriptives/corr67.eps"  
--></td><td  style="white-space:nowrap; text-align:center;" id="TBL-73-4-3"  
class="td11"> 0.66
        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-73-4-4"  
class="td11"><img 
src="lsj214x.png" alt="PIC" class="graphics" width="128" height="128"  /><!--tex4ht:graphics  
name="lsj214x.png" src="../img/descriptives/corr67n.eps"  
--></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-73-5-"><td  style="white-space:nowrap; text-align:center;" id="TBL-73-5-1"  
class="td11">1.0
     </td><td  style="white-space:nowrap; text-align:center;" id="TBL-73-5-2"  
class="td11"><img 
src="lsj215x.png" alt="PIC" class="graphics" width="128" height="128"  /><!--tex4ht:graphics  
name="lsj215x.png" src="../img/descriptives/corr100.eps"  
--></td><td  style="white-space:nowrap; text-align:center;" id="TBL-73-5-3"  
class="td11"> 1.0
        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-73-5-4"  
class="td11"><img 
src="lsj216x.png" alt="PIC" class="graphics" width="128" height="128"  /><!--tex4ht:graphics  
name="lsj216x.png" src="../img/descriptives/corr100n.eps"  
--></td>
</tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-73-6-"><td  style="white-space:nowrap; text-align:center;" id="TBL-73-6-1"  
class="td11">   </td></tr></table></div>
<br /> <div class="caption" 
><span class="id">Figure 12.4: </span><span  
class="content">Illustration of the eﬀect of varying the strength and direction of a correlation.
In the left hand column, the correlations are 0, .33, .66 and 1. In the right hand column, the
                                                                                          

                                                                                          
correlations are 0, -.33, -.66 and -1.</span></div><!--tex4ht:label?: x114-2440014 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 122--><p class="indent" >   The formula for the Pearson’s correlation coeﬃcient can be written in several diﬀerent ways. I
think the simplest way to write down the formula is to break it into two steps. Firstly, let’s
introduce the idea of a <span id="textcolor326">covariance</span>. The covariance between two variables X and Y
is a generalisation of the notion of the variance amd is a mathematically simple way
of describing the relationship between two variables that isn’t terribly informative to
humans
</p>
   <center class="math-display" >
<img 
src="lsj217x.png" alt="                1     N
CovpX,  Y q    ------    Xi    X¯   Yi    ¯Y
              N    1 i  1" class="math-display"  /></center> Because we’re
multiplying (i.e., taking the “product” of) a quantity that depends on X by a quantity that depends on Y and
then averaging<span class="footnote-mark"><a 
href="lsj117.html#fn3x13"><sup class="textsuperscript">3</sup></a></span><a 
 id="x114-244002f3"></a> ,
you can think of the formula for the covariance as an “average cross product” between X and
Y .
<!--l. 128--><p class="indent" >   The covariance has the nice property that, if X and Y are entirely unrelated, then the
covariance is exactly zero. If the relationship between them is positive (in the sense shown in
Figure <a 
href="#x114-2440014">12.4<!--tex4ht:ref: fig:corr --></a>) then the covariance is also positive, and if the relationship is negative then the
covariance is also negative. In other words, the covariance captures the basic qualitative idea of
correlation. Unfortunately, the raw magnitude of the covariance isn’t easy to interpret as it depends
on the units in which X and Y are expressed and, worse yet, the actual units that the covariance
                                                                                          

                                                                                          
itself is expressed in are really weird. For instance, if X refers to the dan.sleep variable (units:
hours) and Y refers to the dan.grump variable (units: grumps), then the units for their
covariance are “hours   grumps”. And I have no freaking idea what that would even
mean.
</p><!--l. 130--><p class="indent" >   The Pearson correlation coeﬃcient r ﬁxes this interpretation problem by standardising the
covariance, in pretty much the exact same way that the z-score standardises a raw score,
by dividing by the standard deviation. However, because we have two variables that
contribute to the covariance, the standardisation only works if we divide by both standard
deviations.<span class="footnote-mark"><a 
href="lsj118.html#fn4x13"><sup class="textsuperscript">4</sup></a></span><a 
 id="x114-244003f4"></a> 
In other words, the correlation between X and Y can be written as follows:
</p>
   <center class="math-display" >
<img 
src="lsj218x.png" alt="       CovpX,  Y q
rXY     --ˆσ---ˆσ----
          X   Y
" class="math-display"  /></center>
<!--l. 136--><p class="indent" >   By standardising the covariance, not only do we keep all of the nice properties of the covariance
discussed earlier, but the actual values of r are on a meaningful scale: r   1 implies a perfect
positive relationship and r    1 implies a perfect negative relationship. I’ll expand a little more on
this point later, in Section <a 
href="#x114-24600012.1.5">12.1.5<!--tex4ht:ref: sec:interpretingcorrelations --></a>. But before I do, let’s look at how to calculate correlations in
jamovi.
</p>
   <h4 class="subsectionHead"><span class="titlemark">12.1.4   </span> <a 
 id="x114-24500012.1.4"></a>Calculating correlations in jamovi</h4>
<!--l. 140--><p class="noindent" >Calculating correlations in jamovi can be done by clicking on the ‘Regression’ - ‘Correlation Matrix’
button. Transfer all four continuous variables across into the box on the right to get the output in
Figure <a 
href="#x114-2450015">12.5<!--tex4ht:ref: fig:correlations --></a>.
</p>
                                                                                          

                                                                                          
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x114-2450015"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 144--><p class="noindent" >

</p><!--l. 145--><p class="noindent" ><img 
src="../img/descriptives/correlations.png" alt="PIC"  
 />
<br />  </p><div class="caption" 
><span class="id">Figure 12.5:   </span><span  
class="content">A   jamovi   screenshot   showing   correlations   between   variables   in   the
parenthood.csv ﬁle</span></div><!--tex4ht:label?: x114-2450015 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
   <h4 class="subsectionHead"><span class="titlemark">12.1.5   </span> <a 
 id="x114-24600012.1.5"></a>Interpreting a correlation </h4>
<!--l. 154--><p class="noindent" >Naturally, in real life you don’t see many correlations of 1. So how should you interpret a
correlation of, say, r   .4? The honest answer is that it really depends on what you want to use the
data for, and on how strong the correlations in your ﬁeld tend to be. A friend of mine in
engineering once argued that any correlation less than .95 is completely useless (I think he was
exaggerating, even for engineering). On the other hand, there are real cases, even in psychology,
where you should really expect correlations that strong. For instance, one of the benchmark data
sets used to test theories of how people judge similarities is so clean that any theory that can’t
achieve a correlation of at least .9 really isn’t deemed to be successful. However, when looking for
(say) elementary correlates of intelligence (e.g., inspection time, response time), if you
get a correlation above .3 you’re doing very very well. In short, the interpretation of a
correlation depends a lot on the context. That said, the rough guide in Table <a 
href="#x114-2460012">12.2<!--tex4ht:ref: tab:interpretingcorrelations --></a> is pretty
typical.
</p>
   <div class="table">
                                                                                          

                                                                                          
<!--l. 156--><p class="indent" >   <a 
 id="x114-2460012"></a></p><hr class="float" /><div class="float" 
>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 157--><p class="noindent" >
<br /> </p><div class="caption" 
><span class="id">Table 12.2: </span><span  
class="content">A rough guide to interpreting correlations. Note that I say a rough guide. There
aren’t hard and fast rules for what counts as strong or weak relationships. It depends on the
context.</span></div><!--tex4ht:label?: x114-2460012 -->
<div class="tabular"> <table id="TBL-74" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-74-1g"><col 
id="TBL-74-1" /><col 
id="TBL-74-2" /><col 
id="TBL-74-3" /></colgroup><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-74-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-74-1-1"  
class="td11">Correlation</td><td  style="white-space:nowrap; text-align:left;" id="TBL-74-1-2"  
class="td11">Strength    </td><td  style="white-space:nowrap; text-align:left;" id="TBL-74-1-3"  
class="td11">Direction</td>
</tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-74-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-74-2-1"  
class="td11">-1.0 to -0.9  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-74-2-2"  
class="td11">Very strong</td><td  style="white-space:nowrap; text-align:left;" id="TBL-74-2-3"  
class="td11">Negative </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-74-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-74-3-1"  
class="td11">-0.9 to -0.7  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-74-3-2"  
class="td11">Strong       </td><td  style="white-space:nowrap; text-align:left;" id="TBL-74-3-3"  
class="td11">Negative </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-74-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-74-4-1"  
class="td11">-0.7 to -0.4  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-74-4-2"  
class="td11">Moderate   </td><td  style="white-space:nowrap; text-align:left;" id="TBL-74-4-3"  
class="td11">Negative </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-74-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-74-5-1"  
class="td11">-0.4 to -0.2  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-74-5-2"  
class="td11">Weak        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-74-5-3"  
class="td11">Negative </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-74-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-74-6-1"  
class="td11">-0.2 to 0     </td><td  style="white-space:nowrap; text-align:left;" id="TBL-74-6-2"  
class="td11">Negligible  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-74-6-3"  
class="td11">Negative </td>
</tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-74-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-74-7-1"  
class="td11">0 to 0.2      </td><td  style="white-space:nowrap; text-align:left;" id="TBL-74-7-2"  
class="td11">Negligible  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-74-7-3"  
class="td11">Positive  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-74-8-"><td  style="white-space:nowrap; text-align:left;" id="TBL-74-8-1"  
class="td11">0.2 to 0.4    </td><td  style="white-space:nowrap; text-align:left;" id="TBL-74-8-2"  
class="td11">Weak        </td><td  style="white-space:nowrap; text-align:left;" id="TBL-74-8-3"  
class="td11">Positive  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-74-9-"><td  style="white-space:nowrap; text-align:left;" id="TBL-74-9-1"  
class="td11">0.4 to 0.7    </td><td  style="white-space:nowrap; text-align:left;" id="TBL-74-9-2"  
class="td11">Moderate   </td><td  style="white-space:nowrap; text-align:left;" id="TBL-74-9-3"  
class="td11">Positive  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-74-10-"><td  style="white-space:nowrap; text-align:left;" id="TBL-74-10-1"  
class="td11">0.7 to 0.9    </td><td  style="white-space:nowrap; text-align:left;" id="TBL-74-10-2"  
class="td11">Strong       </td><td  style="white-space:nowrap; text-align:left;" id="TBL-74-10-3"  
class="td11">Positive  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-74-11-"><td  style="white-space:nowrap; text-align:left;" id="TBL-74-11-1"  
class="td11">0.9 to 1.0    </td><td  style="white-space:nowrap; text-align:left;" id="TBL-74-11-2"  
class="td11">Very strong</td><td  style="white-space:nowrap; text-align:left;" id="TBL-74-11-3"  
class="td11">Positive  </td>
</tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-74-12-"><td  style="white-space:nowrap; text-align:left;" id="TBL-74-12-1"  
class="td11">          </td></tr></table></div></div>
                                                                                          

                                                                                          
   </div><hr class="endfloat" />
   </div>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x114-2460026"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 182--><p class="noindent" >
</p>
<div class="tabular"> <table id="TBL-75" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-75-1g"><col 
id="TBL-75-1" /><col 
id="TBL-75-2" /></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-75-1-"><td  style="white-space:nowrap; text-align:center;" id="TBL-75-1-1"  
class="td11"><img 
src="lsj219x.png" alt="PIC" class="graphics" width="199" height="199"  /><!--tex4ht:graphics  
name="lsj219x.png" src="../img/descriptives/anscombe1.eps"  
--></td><td  style="white-space:nowrap; text-align:center;" id="TBL-75-1-2"  
class="td11"><img 
src="lsj220x.png" alt="PIC" class="graphics" width="199" height="199"  /><!--tex4ht:graphics  
name="lsj220x.png" src="../img/descriptives/anscombe2.eps"  
--></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-75-2-"><td  style="white-space:nowrap; text-align:center;" id="TBL-75-2-1"  
class="td11"><img 
src="lsj221x.png" alt="PIC" class="graphics" width="199" height="199"  /><!--tex4ht:graphics  
name="lsj221x.png" src="../img/descriptives/anscombe3.eps"  
--> </td><td  style="white-space:nowrap; text-align:center;" id="TBL-75-2-2"  
class="td11"><img 
src="lsj222x.png" alt="PIC" class="graphics" width="199" height="199"  /><!--tex4ht:graphics  
name="lsj222x.png" src="../img/descriptives/anscombe4.eps"  
--></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-75-3-"><td  style="white-space:nowrap; text-align:center;" id="TBL-75-3-1"  
class="td11">                                      </td></tr></table></div></div>
<br /> <div class="caption" 
><span class="id">Figure 12.6: </span><span  
class="content">Anscombe’s quartet. All four of these data sets have a Pearson correlation of
r   .816, but they are qualitatively diﬀerent from one another.</span></div><!--tex4ht:label?: x114-2460026 -->
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 196--><p class="indent" >   However, something that can never be stressed enough is that you should always look at the
scatterplot before attaching any interpretation to the data. A correlation might not mean what you
think it means. The classic illustration of this is “Anscombe’s Quartet” (Anscombe 1973), a
collection of four data sets. Each data set has two variables, an X and a Y . For all four data sets
the mean value for X is 9 and the mean for Y is 7.5. The standard deviations for all X variables
are almost identical, as are those for the Y variables. And in each case the correlation between X
and Y is r   0.816. You can verify this yourself, since I happen to have saved it in a ﬁle called
anscombe.csv.
</p><!--l. 198--><p class="indent" >   You’d think that these four data sets would look pretty similar to one another. They do not. If
we draw scatterplots of X against Y for all four variables, as shown in Figure <a 
href="#x114-2460026">12.6<!--tex4ht:ref: fig:anscombe --></a>,
we see that all four of these are spectacularly diﬀerent to each other. The lesson here,
which so very many people seem to forget in real life, is “always graph your raw data”
(Chapter <a 
href="lsjch5.html#x37-870005">5<!--tex4ht:ref: ch:graphics --></a>).
</p>
   <h4 class="subsectionHead"><span class="titlemark">12.1.6   </span> <a 
 id="x114-24700012.1.6"></a>Spearman’s rank correlations</h4>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x114-2470017"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 203--><p class="noindent" >
</p><!--l. 204--><p class="noindent" ><img 
src="lsj223x.png" alt="PIC" class="graphics" width="284" height="243"  /><!--tex4ht:graphics  
name="lsj223x.png" src="../img/descriptives/ordinalRelationship.eps"  
--></p></div>
<br /> <div class="caption" 
><span class="id">Figure 12.7: </span><span  
class="content">The relationship between hours worked and grade received for a toy data set
consisting of only 10 students (each circle corresponds to one student). The dashed line
through the middle shows the linear relationship between the two variables. This produces
a  strong  Pearson  correlation  of  r     .91.  However,  the  interesting  thing  to  note  here  is
that there’s actually a perfect monotonic relationship between the two variables. In this toy
example, increasing the hours worked always increases the grade received, as illustrated by
the solid line. This is reﬂected in a Spearman correlation of ρ   1. With such a small data
set, however, it’s an open question as to which version better describes the actual relationship
involved. </span></div><!--tex4ht:label?: x114-2470017 -->
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 211--><p class="indent" >   The Pearson correlation coeﬃcient is useful for a lot of things, but it does have shortcomings.
One issue in particular stands out: what it actually measures is the strength of the linear
relationship between two variables. In other words, what it gives you is a measure of the extent to
which the data all tend to fall on a single, perfectly straight line. Often, this is a pretty good
approximation to what we mean when we say “relationship”, and so the Pearson correlation is a
good thing to calculate. Sometimes though, it isn’t.
</p><!--l. 213--><p class="indent" >   One very common situation where the Pearson correlation isn’t quite the right thing to use
arises when an increase in one variable X really is reﬂected in an increase in another variable Y ,
but the nature of the relationship isn’t necessarily linear. An example of this might be the
relationship between eﬀort and reward when studying for an exam. If you put zero eﬀort (X) into
learning a subject then you should expect a grade of 0% (Y ). However, a little bit of eﬀort will
cause a massive improvement. Just turning up to lectures means that you learn a fair bit, and if
you just turn up to classes and scribble a few things down your grade might rise to
35%, all without a lot of eﬀort. However, you just don’t get the same eﬀect at the other
end of the scale. As everyone knows, it takes a lot more eﬀort to get a grade of 90%
than it takes to get a grade of 55%. What this means is that, if I’ve got data looking at
study eﬀort and grades, there’s a pretty good chance that Pearson correlations will be
misleading.
</p><!--l. 216--><p class="indent" >   To illustrate, consider the data plotted in Figure <a 
href="#x114-2470017">12.7<!--tex4ht:ref: fig:rankcorrpic --></a>, showing the relationship between hours
worked and grade received for 10 students taking some class. The curious thing about this (highly
ﬁctitious) data set is that increasing your eﬀort always increases your grade. It might be by a
lot or it might be by a little, but increasing eﬀort will never decrease your grade. If
we run a standard Pearson correlation, it shows a strong relationship between hours
worked and grade received, with a correlation coeﬃcient of 0.91. However, this doesn’t
actually capture the observation that increasing hours worked always increases the grade.
There’s a sense here in which we want to be able to say that the correlation is perfect
but for a somewhat diﬀerent notion of what a “relationship” is. What we’re looking
for is something that captures the fact that there is a perfect <span id="textcolor329">ordinal relationship</span>
here. That is, if student 1 works more hours than student 2, then we can guarantee that
student 1 will get the better grade. That’s not what a correlation of r   .91 says at
all.
</p><!--l. 218--><p class="indent" >   How should we address this? Actually, it’s really easy. If we’re looking for ordinal relationships
all we have to do is treat the data as if it were ordinal scale! So, instead of measuring eﬀort in
terms of “hours worked”, lets rank all 10 of our students in order of hours worked. That is, student
1 did the least work out of anyone (2 hours) so they get the lowest rank (rank = 1). Student 4
was the next laziest, putting in only 6 hours of work over the whole semester, so they
get the next lowest rank (rank = 2). Notice that I’m using “rank =1” to mean “low
rank”. Sometimes in everyday language we talk about “rank = 1” to mean “top rank”
                                                                                          

                                                                                          
rather than “bottom rank”. So be careful, you can rank “from smallest value to largest
value” (i.e., small equals rank 1) or you can rank “from largest value to smallest value”
(i.e., large equals rank 1). In this case, I’m ranking from smallest to largest, but as it’s
really easy to forget which way you set things up you have to put a bit of eﬀort into
remembering!
</p><!--l. 220--><p class="indent" >   Okay, so let’s have a look at our students when we rank them from worst to best in terms of
eﬀort and reward: </p>
<div class="center" 
>
<!--l. 221--><p class="noindent" >
</p>
<div class="tabular"> <table id="TBL-76" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-76-1g"><col 
id="TBL-76-1" /><col 
id="TBL-76-2" /><col 
id="TBL-76-3" /></colgroup><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-76-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-76-1-1"  
class="td11">            </td><td  style="white-space:nowrap; text-align:right;" id="TBL-76-1-2"  
class="td11">rank (hours worked)</td><td  style="white-space:nowrap; text-align:right;" id="TBL-76-1-3"  
class="td11">rank (grade received)</td>
</tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-76-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-76-2-1"  
class="td11">student 1  </td><td  style="white-space:nowrap; text-align:right;" id="TBL-76-2-2"  
class="td11">                1</td><td  style="white-space:nowrap; text-align:right;" id="TBL-76-2-3"  
class="td11">                 1</td></tr><tr  
 style="vertical-align:baseline;" id="TBL-76-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-76-3-1"  
class="td11">student 2 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-76-3-2"  
class="td11"> 10</td><td  style="white-space:nowrap; text-align:right;" id="TBL-76-3-3"  
class="td11"> 10</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-76-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-76-4-1"  
class="td11">student 3  </td><td  style="white-space:nowrap; text-align:right;" id="TBL-76-4-2"  
class="td11">                6</td><td  style="white-space:nowrap; text-align:right;" id="TBL-76-4-3"  
class="td11">                 6</td></tr><tr  
 style="vertical-align:baseline;" id="TBL-76-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-76-5-1"  
class="td11">student 4 </td><td  style="white-space:nowrap; text-align:right;" id="TBL-76-5-2"  
class="td11"> 2</td><td  style="white-space:nowrap; text-align:right;" id="TBL-76-5-3"  
class="td11"> 2</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-76-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-76-6-1"  
class="td11">student 5  </td><td  style="white-space:nowrap; text-align:right;" id="TBL-76-6-2"  
class="td11">                3</td><td  style="white-space:nowrap; text-align:right;" id="TBL-76-6-3"  
class="td11">                 3</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-76-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-76-7-1"  
class="td11">student 6  </td><td  style="white-space:nowrap; text-align:right;" id="TBL-76-7-2"  
class="td11">                5</td><td  style="white-space:nowrap; text-align:right;" id="TBL-76-7-3"  
class="td11">                 5</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-76-8-"><td  style="white-space:nowrap; text-align:left;" id="TBL-76-8-1"  
class="td11">student 7  </td><td  style="white-space:nowrap; text-align:right;" id="TBL-76-8-2"  
class="td11">                4</td><td  style="white-space:nowrap; text-align:right;" id="TBL-76-8-3"  
class="td11">                 4</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-76-9-"><td  style="white-space:nowrap; text-align:left;" id="TBL-76-9-1"  
class="td11">student 8  </td><td  style="white-space:nowrap; text-align:right;" id="TBL-76-9-2"  
class="td11">                8</td><td  style="white-space:nowrap; text-align:right;" id="TBL-76-9-3"  
class="td11">                 8</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-76-10-"><td  style="white-space:nowrap; text-align:left;" id="TBL-76-10-1"  
class="td11">student 9  </td><td  style="white-space:nowrap; text-align:right;" id="TBL-76-10-2"  
class="td11">                7</td><td  style="white-space:nowrap; text-align:right;" id="TBL-76-10-3"  
class="td11">                 7</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-76-11-"><td  style="white-space:nowrap; text-align:left;" id="TBL-76-11-1"  
class="td11">student 10</td><td  style="white-space:nowrap; text-align:right;" id="TBL-76-11-2"  
class="td11">                9</td><td  style="white-space:nowrap; text-align:right;" id="TBL-76-11-3"  
class="td11">                 9</td>
</tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-76-12-"><td  style="white-space:nowrap; text-align:left;" id="TBL-76-12-1"  
class="td11">         </td></tr></table></div></div>
<!--l. 240--><p class="indent" >   Hmm. These are identical. The student who put in the most eﬀort got the best grade, the
student with the least eﬀort got the worst grade, etc. As the table above shows, these two rankings
are identical, so if we now correlate them we get a perfect relationship, with a correlation of
1.0.
</p><!--l. 242--><p class="indent" >   What we’ve just re-invented is <span id="textcolor330">Spearman’s rank order correlation</span>, usually denoted ρ to
distinguish it from the Pearson correlation r. We can calculate Spearman’s ρ using jamovi simply
by clicking the ‘Spearman’ check box in the ‘Correlation Matrix’ screen.
</p>
   <h3 class="sectionHead"><span class="titlemark">12.2   </span> <a 
 id="x114-24800012.2"></a>Scatterplots</h3>
<!--l. 247--><p class="noindent" ><span id="textcolor331">Scatterplots</span> are a simple but eﬀective tool for visualising the relationship between two
variables, like we saw with the ﬁgures in the section on correlation (Section <a 
href="#x114-24100012.1">12.1<!--tex4ht:ref: sec:correl --></a>). It’s this
latter application that we usually have in mind when we use the term “scatterplot”. In
this kind of plot each observation corresponds to one dot. The horizontal location of
the dot plots the value of the observation on one variable, and the vertical location
displays its value on the other variable. In many situations you don’t really have a clear
opinions about what the causal relationship is (e.g., does A cause B, or does B cause A, or
does some other variable C control both A and B). If that’s the case, it doesn’t really
                                                                                          

                                                                                          
matter which variable you plot on the x-axis and which one you plot on the y-axis.
However, in many situations you do have a pretty strong idea which variable you think is
most likely to be causal, or at least you have some suspicions in that direction. If so,
then it’s conventional to plot the cause variable on the x-axis, and the eﬀect variable on
the y-axis. With that in mind, let’s look at how to draw scatterplots in jamovi, using
the same parenthood data set (i.e. parenthood.csv) that I used when introducing
correlations.
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x114-2480018"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 250--><p class="noindent" >

</p><!--l. 251--><p class="noindent" ><img 
src="../img/graphics/scatterplot1.png" alt="PIC"  
 />
<br /> </p><div class="caption" 
><span class="id">Figure 12.8: </span><span  
class="content">Scatterplot via the ‘Correlation Matrix’ command in jamovi</span></div><!--tex4ht:label?: x114-2480018 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 258--><p class="indent" >   Suppose my goal is to draw a scatterplot displaying the relationship between the amount of
sleep that I get (dan.sleep) and how grumpy I am the next day (dan.grump). There are two
diﬀerent ways in which we can use jamovi to get the plot that we’re after. The ﬁrst way is to use
the ‘Plot’ option under the ‘Regression’ - ‘Correlation Matrix’ button, giving us the output shown
in Figure <a 
href="#x114-2480018">12.8<!--tex4ht:ref: fig:scatterplot1 --></a>. Note that jamovi draws a line through the points, we’ll come onto this a bit later in
Section (<a 
href="#x114-25000012.3">12.3<!--tex4ht:ref: sec:introregression --></a>). Plotting a scatterplot in this way also allow you to specify ‘Densities for
variables’ and this option adds a density curve showing how the data in each variable is
distributed.
</p><!--l. 260--><p class="indent" >   The second way do to it is to use one of the jamovi add-on modules. This module is called
‘scatr’ and you can install it by clicking on the large ‘+’ icon in the top right of the jamovi screen,
opening the jamovi library, scrolling down until you ﬁnd ‘scatr’ and clicking ‘install’. When you
have done this, you will ﬁnd a new ‘Scatterplot’ command available under the ‘Exploration’ button.
This plot is a bit diﬀerent than the ﬁrst way, see Figure <a 
href="#x114-2480029">12.9<!--tex4ht:ref: fig:scatterplot2 --></a>, but the important information is the
same.
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x114-2480029"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 263--><p class="noindent" >

</p><!--l. 264--><p class="noindent" ><img 
src="../img/graphics/scatterplot2-.png" alt="PIC"  
 />
<br /> </p><div class="caption" 
><span class="id">Figure 12.9: </span><span  
class="content">Scatterplot via the ‘scatr’ add-on module in jamovi</span></div><!--tex4ht:label?: x114-2480029 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
   <h4 class="subsectionHead"><span class="titlemark">12.2.1   </span> <a 
 id="x114-24900012.2.1"></a>More elaborate options</h4>
<!--l. 273--><p class="noindent" >Often you will want to look at the relationships between several variables at once, using a
<span id="textcolor332">scatterplot matrix</span> (in jamovi via the ‘Correlation Matrix’ - ‘Plot’ command). Just add another
variable, for example baby.sleep to the list of variables to be correlated, and jamovi will create a
scatterplot matrix for you, just like the one in Figure <a 
href="#x114-24900110">12.10<!--tex4ht:ref: fig:scatterplot3 --></a>.
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x114-24900110"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 276--><p class="noindent" >

</p><!--l. 277--><p class="noindent" ><img 
src="../img/graphics/scatterplot3-.png" alt="PIC"  
 />
<br /> </p><div class="caption" 
><span class="id">Figure 12.10: </span><span  
class="content">A matrix of scatterplots produced using jamovi.</span></div><!--tex4ht:label?: x114-24900110 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 285--><p class="indent" >
                                                                                          

                                                                                          
</p>
   <h3 class="sectionHead"><span class="titlemark">12.3   </span> <a 
 id="x114-25000012.3"></a>What is a linear regression model? </h3>
<!--l. 288--><p class="noindent" >Stripped to its bare essentials, linear regression models are basically a slightly fancier version of the
Pearson correlation (Section <a 
href="#x114-24100012.1">12.1<!--tex4ht:ref: sec:correl --></a>), though as we’ll see regression models are much more powerful
tools.
</p><!--l. 290--><p class="indent" >   Since the basic ideas in regression are closely tied to correlation, we’ll return to the
<br 
class="newline" />parenthood.csv ﬁle that we were using to illustrate how correlations work. Recall that, in this
data set we were trying to ﬁnd out why Dan is so very grumpy all the time and our
working hypothesis was that I’m not getting enough sleep. We drew some scatterplots to
help us examine the relationship between the amount of sleep I get and my grumpiness
the following day, as in Figure <a 
href="#x114-2480029">12.9<!--tex4ht:ref: fig:scatterplot2 --></a>, and as we saw previously this corresponds to a
correlation of r    .90, but what we ﬁnd ourselves secretly imagining is something that
looks closer to Figure <a 
href="#x114-25000111">12.11<!--tex4ht:ref: fig:regression1 --></a>a. That is, we mentally draw a straight line through the
middle of the data. In statistics, this line that we’re drawing is called a <span id="textcolor333">regression line</span>.
Notice that, since we’re not idiots, the regression line goes through the middle of the
data. We don’t ﬁnd ourselves imagining anything like the rather silly plot shown in
Figure <a 
href="#x114-25000111">12.11<!--tex4ht:ref: fig:regression1 --></a>b.
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x114-25000111"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 293--><p class="noindent" >
</p>
<div class="tabular">
 <table id="TBL-77" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-77-1g"><col 
id="TBL-77-1" /><col 
id="TBL-77-2" /></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-77-1-"><td  style="white-space:nowrap; text-align:center;" id="TBL-77-1-1"  
class="td11"><img 
src="lsj224x.png" alt="PIC" class="graphics" width="199" height="199"  /><!--tex4ht:graphics  
name="lsj224x.png" src="../img/regression/introPicGoodLine.eps"  
--></td><td  style="white-space:nowrap; text-align:center;" id="TBL-77-1-2"  
class="td11"><img 
src="lsj225x.png" alt="PIC" class="graphics" width="199" height="199"  /><!--tex4ht:graphics  
name="lsj225x.png" src="../img/regression/introPicBadLine.eps"  
--></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-77-2-"><td  style="white-space:nowrap; text-align:center;" id="TBL-77-2-1"  
class="td11">                  (a)                            </td><td  style="white-space:nowrap; text-align:center;" id="TBL-77-2-2"  
class="td11">                 (b)                           </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-77-3-"><td  style="white-space:nowrap; text-align:center;" id="TBL-77-3-1"  
class="td11">                                      </td></tr></table></div>
<br /> <div class="caption" 
><span class="id">Figure 12.11: </span><span  
class="content">Panel a shows the sleep-grumpiness scatterplot from Figure <a 
href="#x114-2480029">12.9<!--tex4ht:ref: fig:scatterplot2 --></a> with the
best ﬁtting regression line drawn over the top. Not surprisingly, the line goes through the
middle of the data. In contrast, panel b shows the same data, but with a very poor choice of
regression line drawn over the top.</span></div><!--tex4ht:label?: x114-25000111 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 305--><p class="indent" >   This is not highly surprising. The line that I’ve drawn in Figure <a 
href="#x114-25000111">12.11<!--tex4ht:ref: fig:regression1 --></a>b doesn’t “ﬁt” the data
very well, so it doesn’t make a lot of sense to propose it as a way of summarising the data, right?
This is a very simple observation to make, but it turns out to be very powerful when we
start trying to wrap just a little bit of maths around it. To do so, let’s start with a
refresher of some high school maths. The formula for a straight line is usually written like
this
</p>
   <center class="math-display" >
<img 
src="lsj226x.png" alt="y    a    bx  " class="math-display"  /></center>
Or, at least, that’s what it was when I went to high school all those years
ago. The two variables are x and y, and we have two coeﬃcients, a and
b.<span class="footnote-mark"><a 
href="lsj119.html#fn5x13"><sup class="textsuperscript">5</sup></a></span><a 
 id="x114-250002f5"></a>  The
coeﬃcient a represents the y-intercept of the line, and coeﬃcient b represents the slope of the line.
Digging further back into our decaying memories of high school (sorry, for some of us high school
was a long time ago), we remember that the intercept is interpreted as “the value of y
that you get when x   0”. Similarly, a slope of b means that if you increase the x-value
by 1 unit, then the y-value goes up by b units, and a negative slope means that the
y-value would go down rather than up. Ah yes, it’s all coming back to me now. Now that
we’ve remembered that it should come as no surprise to discover that we use the exact
same formula for a regression line. If Y is the outcome variable (the DV) and X is the
predictor variable (the IV), then the formula that describes our regression is written like
this
                                                                                          

                                                                                          
   <center class="math-display" >
<img 
src="lsj227x.png" alt="ˆYi    b0   b1Xi  " class="math-display"  /></center>
Hmm. Looks like the same formula, but there’s some extra frilly bits in this version. Let’s make
sure we understand them. Firstly, notice that I’ve written X<sub>i</sub> and Y <sub>i</sub> rather than just plain old X
and Y . This is because we want to remember that we’re dealing with actual data. In this equation,
X<sub>i</sub> is the value of predictor variable for the ith observation (i.e., the number of hours of sleep that
I got on day i of my little study), and Y <sub>i</sub> is the corresponding value of the outcome
variable (i.e., my grumpiness on that day). And although I haven’t said so explicitly in the
equation, what we’re assuming is that this formula works for all observations in the
data set (i.e., for all i). Secondly, notice that I wrote Ŷ<sub>i</sub> and not Y <sub>i</sub>. This is because we
want to make the distinction between the actual data Y <sub>i</sub>, and the estimate Ŷ<sub>i</sub> (i.e., the
prediction that our regression line is making). Thirdly, I changed the letters used to describe
the coeﬃcients from a and b to b<sub>0</sub> and b<sub>1</sub>. That’s just the way that statisticians like to
refer to the coeﬃcients in a regression model. I’ve no idea why they chose b, but that’s
what they did. In any case b<sub>0</sub> always refers to the intercept term, and b<sub>1</sub> refers to the
slope.
<!--l. 315--><p class="indent" >   Excellent, excellent. Next, I can’t help but notice that, regardless of whether we’re talking about
the good regression line or the bad one, the data don’t fall perfectly on the line. Or, to say it
another way, the data Y <sub>i</sub> are not identical to the predictions of the regression model <img 
src="lsj228x.png" alt="ˆYi"  class="circ"  />. Since
statisticians love to attach letters, names and numbers to everything, let’s refer to the diﬀerence
between the model prediction and that actual data point as a residual, and we’ll refer to it as
𝜖<sub>i</sub>.<span class="footnote-mark"><a 
href="lsj120.html#fn6x13"><sup class="textsuperscript">6</sup></a></span><a 
 id="x114-250003f6"></a> 
Written using mathematics, the residuals are deﬁned as
</p>
   <center class="math-display" >
<img 
src="lsj229x.png" alt="𝜖i    Yi   Yˆi  " class="math-display"  /></center>
which in turn means that we can write down the complete linear regression model as
                                                                                          

                                                                                          
   <center class="math-display" >
<img 
src="lsj230x.png" alt="Yi    b0   b1Xi    𝜖i
" class="math-display"  /></center>
   <h3 class="sectionHead"><span class="titlemark">12.4   </span> <a 
 id="x114-25100012.4"></a>Estimating a linear regression model </h3>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x114-25100112"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 327--><p class="noindent" >
</p>
<div class="tabular">
 <table id="TBL-78" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-78-1g"><col 
id="TBL-78-1" /><col 
id="TBL-78-2" /></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-78-1-"><td  style="white-space:nowrap; text-align:center;" id="TBL-78-1-1"  
class="td11"><img 
src="lsj231x.png" alt="PIC" class="graphics" width="199" height="199"  /><!--tex4ht:graphics  
name="lsj231x.png" src="../img/regression/introPicGoodSSE.eps"  
--></td><td  style="white-space:nowrap; text-align:center;" id="TBL-78-1-2"  
class="td11"><img 
src="lsj232x.png" alt="PIC" class="graphics" width="199" height="199"  /><!--tex4ht:graphics  
name="lsj232x.png" src="../img/regression/introPicBadSSE.eps"  
--></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-78-2-"><td  style="white-space:nowrap; text-align:center;" id="TBL-78-2-1"  
class="td11">                  (a)                            </td><td  style="white-space:nowrap; text-align:center;" id="TBL-78-2-2"  
class="td11">                 (b)                           </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-78-3-"><td  style="white-space:nowrap; text-align:center;" id="TBL-78-3-1"  
class="td11">                                      </td></tr></table></div>
<br /> <div class="caption" 
><span class="id">Figure 12.12: </span><span  
class="content">A depiction of the residuals associated with the best ﬁtting regression line
(panel a), and the residuals associated with a poor regression line (panel b). The residuals
are much smaller for the good regression line. Again, this is no surprise given that the good
line is the one that goes right through the middle of the data.</span></div><!--tex4ht:label?: x114-25100112 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 339--><p class="indent" >   Okay, now let’s redraw our pictures but this time I’ll add some lines to show the size of the
residual for all observations. When the regression line is good, our residuals (the lengths of the solid
black lines) all look pretty small, as shown in Figure <a 
href="#x114-25100112">12.12<!--tex4ht:ref: fig:regression3 --></a>a, but when the regression line is a bad
one the residuals are a lot larger, as you can see from looking at Figure <a 
href="#x114-25100112">12.12<!--tex4ht:ref: fig:regression3 --></a>b. Hmm. Maybe what
we “want” in a regression model is small residuals. Yes, that does seem to make sense.
In fact, I think I’ll go so far as to say that the “best ﬁtting” regression line is the one
that has the smallest residuals. Or, better yet, since statisticians seem to like to take
squares of everything why not say that: The estimated regression coeﬃcients, <img 
src="lsj233x.png" alt="ˆb"  class="circ"  /> <sub>0</sub> and <img 
src="lsj234x.png" alt="ˆb"  class="circ"  /> <sub>1</sub>,
are those that minimise the sum of the squared residuals, which we could either write
as
</p>
   <center class="math-display" >
<img 
src="lsj235x.png" alt="           2
 pYi    ˆYiq
i   " class="math-display"  /></center> or
as
   <center class="math-display" >
<img 
src="lsj236x.png" alt="
  𝜖2i
i
" class="math-display"  /></center>.
<!--l. 349--><p class="indent" >   Yes, yes that sounds even better. And since I’ve indented it like that, it probably
means that this is the right answer. And since this is the right answer, it’s probably
worth making a note of the fact that our regression coeﬃcients are estimates (we’re
trying to guess the parameters that describe a population!), which is why I’ve added
the little hats, so that we get <img 
src="lsj237x.png" alt="ˆb"  class="circ"  /> <sub>0</sub> and <img 
src="lsj238x.png" alt="ˆb"  class="circ"  /> <sub>1</sub> rather than b<sub>0</sub> and b<sub>1</sub>. Finally, I should also
                                                                                          

                                                                                          
note that, since there’s actually more than one way to estimate a regression model, the
more technical name for this estimation process is <span id="textcolor336">ordinary least squares (OLS)
regression</span>.
</p><!--l. 351--><p class="indent" >   At this point, we now have a concrete deﬁnition for what counts as our “best” choice of regression
coeﬃcients, <img 
src="lsj239x.png" alt="ˆb"  class="circ"  /> <sub>0</sub> and <img 
src="lsj240x.png" alt="ˆb"  class="circ"  /> <sub>1</sub>. The natural question to ask next is, if our optimal regression coeﬃcients are
those that minimise the sum squared residuals, how do we ﬁnd these wonderful numbers? The
actual answer to this question is complicated and doesn’t help you understand the logic of
regression.<span class="footnote-mark"><a 
href="lsj121.html#fn7x13"><sup class="textsuperscript">7</sup></a></span><a 
 id="x114-251002f7"></a> 
This time I’m going to let you oﬀ the hook. Instead of showing you the long and tedious way ﬁrst
and then “revealing” the wonderful shortcut that jamovi provides, let’s cut straight to the chase
and just use jamovi to do all the heavy lifting.
</p>
   <h4 class="subsectionHead"><span class="titlemark">12.4.1   </span> <a 
 id="x114-25200012.4.1"></a>Linear regression in jamovi </h4>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x114-25200113"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 356--><p class="noindent" >

</p><!--l. 357--><p class="noindent" ><img 
src="../img/regression/reg1.png" alt="PIC"  
 />
<br /> </p><div class="caption" 
><span class="id">Figure 12.13: </span><span  
class="content">A jamovi screenshot showing a simple linear regression analysis.</span></div><!--tex4ht:label?: x114-25200113 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 364--><p class="indent" >   To run my linear regression, open up the ‘Regression’ - ‘Linear Regression’ analysis in
jamovi, using the parenthood.csv data ﬁle. Then specify dan.grump as the ‘Dependent
Variable’ and dan.sleep as the variable entered in the ‘Covariates’ box. This gives the
results shown in Figure <a 
href="#x114-25200113">12.13<!--tex4ht:ref: fig:reg1 --></a>, showing an intercept <img 
src="lsj243x.png" alt="ˆb"  class="circ"  /> <sub>0</sub>   125.96 and the slope <img 
src="lsj244x.png" alt="ˆb"  class="circ"  /> <sub>1</sub>    8.94.
In other words, the best-ﬁtting regression line that I plotted in Figure <a 
href="#x114-25000111">12.11<!--tex4ht:ref: fig:regression1 --></a> has this
formula:
</p>
   <center class="math-display" >
<img 
src="lsj245x.png" alt="ˆYi   125.96    p   8.94 Xiq
" class="math-display"  /></center>
   <h4 class="subsectionHead"><span class="titlemark">12.4.2   </span> <a 
 id="x114-25300012.4.2"></a>Interpreting the estimated model</h4>
<!--l. 371--><p class="noindent" >The most important thing to be able to understand is how to interpret these coeﬃcients. Let’s start
with <img 
src="lsj246x.png" alt="ˆb"  class="circ"  /> <sub>1</sub>, the slope. If we remember the deﬁnition of the slope, a regression coeﬃcient of <img 
src="lsj247x.png" alt="ˆb"  class="circ"  /> <sub>1</sub>    8.94
means that if I increase X<sub>i</sub> by 1, then I’m decreasing Y <sub>i</sub> by 8.94. That is, each additional hour of
sleep that I gain will improve my mood, reducing my grumpiness by 8.94 grumpiness points. What
about the intercept? Well, since <img 
src="lsj248x.png" alt="ˆb"  class="circ"  /> <sub>0</sub> corresponds to “the expected value of Y <sub>i</sub> when X<sub>i</sub> equals 0”, it’s
pretty straightforward. It implies that if I get zero hours of sleep (X<sub>i</sub>   0) then my
grumpiness will go oﬀ the scale, to an insane value of (Y <sub>i</sub>   125.96). Best to be avoided, I
think.
</p><!--l. 374--><p class="noindent" >
</p>
   <h3 class="sectionHead"><span class="titlemark">12.5   </span> <a 
 id="x114-25400012.5"></a>Multiple linear regression </h3>
<!--l. 376--><p class="noindent" >The simple linear regression model that we’ve discussed up to this point assumes that there’s a
single predictor variable that you’re interested in, in this case dan.sleep. In fact, up to this
point every statistical tool that we’ve talked about has assumed that your analysis uses
one predictor variable and one outcome variable. However, in many (perhaps most)
                                                                                          

                                                                                          
research projects you actually have multiple predictors that you want to examine. If so, it
would be nice to be able to extend the linear regression framework to be able to include
multiple predictors. Perhaps some kind of <span id="textcolor338">multiple regression</span> model would be in
order?
</p><!--l. 378--><p class="indent" >   Multiple regression is conceptually very simple. All we do is add more terms to our regression
equation. Let’s suppose that we’ve got two variables that we’re interested in; perhaps we want to
use both dan.sleep and baby.sleep to predict the dan.grump variable. As before, we let Y <sub>i</sub> refer
to my grumpiness on the i-th day. But now we have two X variables: the ﬁrst corresponding to
the amount of sleep I got and the second corresponding to the amount of sleep my son
got. So we’ll let X<sub>i1</sub>  refer to the hours I slept on the i-th day and X<sub>i2</sub>  refers to the
hours that the baby slept on that day. If so, then we can write our regression model like
this:
</p>
   <center class="math-display" >
<img 
src="lsj249x.png" alt="Yi    b0    b1Xi1    b2Xi2    𝜖i  " class="math-display"  /></center> As
before, 𝜖<sub>i</sub> is the residual associated with the i-th observation, 𝜖<sub>i</sub>   Y <sub>i</sub>   Ŷ<sub>i</sub>. In this model, we now
have three coeﬃcients that need to be estimated: b<sub>0</sub> is the intercept, b<sub>1</sub> is the coeﬃcient associated
with my sleep, and b<sub>2</sub> is the coeﬃcient associated with my son’s sleep. However, although the
number of coeﬃcients that need to be estimated has changed, the basic idea of how the estimation
works is unchanged: our estimated coeﬃcients <img 
src="lsj250x.png" alt="ˆb"  class="circ"  /> <sub>0</sub>, <img 
src="lsj251x.png" alt="ˆb"  class="circ"  /> <sub>1</sub> and <img 
src="lsj252x.png" alt="ˆb"  class="circ"  /> <sub>2</sub> are those that minimise the sum
squared residuals.
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x114-25400114"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 385--><p class="noindent" >
</p><!--l. 386--><p class="noindent" ><img 
src="lsj253x.png" alt="PIC" class="graphics" width="398" height="367"  /><!--tex4ht:graphics  
name="lsj253x.png" src="../img/regression2/scatter3d_1.eps"  
-->
<br /> </p><div class="caption" 
><span class="id">Figure 12.14: </span><span  
class="content">A 3D visualisation of a multiple regression model. There are two predictors
in the model, dan.sleep and baby.sleep and the outcome variable is dan.grump. Together,
these three variables form a 3D space. Each observation (dot) is a point in this space. In much
the same way that a simple linear regression model forms a line in 2D space, this multiple
regression model forms a plane in 3D space. When we estimate the regression coeﬃcients
what we’re trying to do is ﬁnd a plane that is as close to all the blue dots as possible.</span></div><!--tex4ht:label?: x114-25400114 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
   <h4 class="subsectionHead"><span class="titlemark">12.5.1   </span> <a 
 id="x114-25500012.5.1"></a>Doing it in jamovi</h4>
<!--l. 394--><p class="noindent" >Multiple regression in jamovi is no diﬀerent to simple regression. All we have to do is add
additional variables to the ‘Covariates’ box in jamovi. For example, if we want to use both
dan.sleep and baby.sleep as predictors in our attempt to explain why I’m so grumpy, then move
baby.sleep across into the ‘Covariates’ box alongside dan.sleep. By default, jamovi
assumes that the model should include an intercept. The coeﬃcients we get this time
are:
                                                                                          

                                                                                          
</p>
   <div class="verbatim" id="verbatim-40">
<span 
class="cmtt-12">(Intercept)</span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> dan.sleep</span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> baby.sleep</span>
<span 
class="cmtt-12"> </span><br /><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> 125.97</span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> -8.95</span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> 0.01</span>
</div>
<!--l. 399--><p class="nopar" >
</p><!--l. 401--><p class="indent" >   The coeﬃcient associated with dan.sleep is quite large, suggesting that every hour of sleep I
lose makes me a lot grumpier. However, the coeﬃcient for baby.sleep is very small, suggesting
that it doesn’t really matter how much sleep my son gets. What matters as far as my grumpiness
goes is how much sleep I get. To get a sense of what this multiple regression model looks like,
Figure <a 
href="#x114-25400114">12.14<!--tex4ht:ref: fig:multipleregression --></a> shows a 3D plot that plots all three variables, along with the regression model
itself.
</p><!--l. 405--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">12.5.2   </span> <a 
 id="x114-25600012.5.2"></a>Formula for the general case</h4>
<!--l. 407--><p class="noindent" >The equation that I gave above shows you what a multiple regression model looks like
when you include two predictors. Not surprisingly, then, if you want more than two
predictors all you have to do is add more X terms and more b coeﬃcients. In other words, if
you have K predictor variables in the model then the regression equation looks like
this
</p>
   <center class="math-display" >
<img 
src="lsj254x.png" alt="             K
Y     b          b X        𝜖
 i    0        k  ik     i
           k  1
" class="math-display"  /></center>
                                                                                          

                                                                                          
<!--l. 413--><p class="noindent" >
</p>
   <h3 class="sectionHead"><span class="titlemark">12.6   </span> <a 
 id="x114-25700012.6"></a>Quantifying the ﬁt of the regression model </h3>
<!--l. 415--><p class="noindent" >So we now know how to estimate the coeﬃcients of a linear regression model. The problem is, we
don’t yet know if this regression model is any good. For example, the regression.1
model claims that every hour of sleep will improve my mood by quite a lot, but it might
just be rubbish. Remember, the regression model only produces a prediction Ŷ<sub>i</sub> about
what my mood is like, but my actual mood is Y <sub>i</sub>. If these two are very close, then the
regression model has done a good job. If they are very diﬀerent, then it has done a bad
job.
</p><!--l. 417--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">12.6.1   </span> <a 
 id="x114-25800012.6.1"></a>The R<sup>2</sup> (R-squared) value </h4>
<!--l. 419--><p class="noindent" >Once again, let’s wrap a little bit of mathematics around this. Firstly, we’ve got the sum of the
squared residuals
</p>
   <center class="math-display" >
<img 
src="lsj255x.png" alt="                 ˆ  2
SSres      pYi    Yiq
         i   " class="math-display"  /></center>
which we would hope to be pretty small. Speciﬁcally, what we’d like is for it to be very small in
comparison to the total variability in the outcome variable
   <center class="math-display" >
<img 
src="lsj256x.png" alt="                 ¯  2
SStot      pYi    Y q
         i   " class="math-display"  /></center>
While we’re here, let’s calculate these values ourselves, not by hand though. Let’s use something
like Excel or another standard spreadsheet programme. I have done this by opening up the
parenthood.csv ﬁle in Excel and saving it as parenthood_rsquared.xls so that I can work on it.
The ﬁrst thing to do is calculate the Ŷ values, and for the simple model that uses only a single
predictor we would do the following:
<!--l. 429--><p class="noindent" >1. create a new column called Y.pred using the formula = 125.97 + (-8.94 * dan.sleep)
</p><!--l. 432--><p class="indent" >   Okay, now that we’ve got a variable which stores the regression model predictions for how
grumpy I will be on any given day, let’s calculate our sum of squared residuals. We would do that
using the following formula:
</p><!--l. 434--><p class="noindent" >2. calculate the SS(resid) by creating a new column called (Y-Y.pred)^2 using the formula
<br 
class="newline" />=(dan.grump - Y.pred)^2.
</p><!--l. 437--><p class="noindent" >3. Then, at the bottom of this column calculate the sum of these values, <br 
class="newline" />i.e. sum((Y-Y.pred)^2).
</p><!--l. 440--><p class="indent" >   This should give you a value of 1838.722. Wonderful. A big number that doesn’t mean very
much. Still, let’s forge boldly onwards anyway and calculate the total sum of squares as well. That’s
also pretty simple. Calculate the SS(tot) by:
</p><!--l. 442--><p class="noindent" >4. At the bottom of the dan.grump column, calculate the mean value for dan.grump
<br 
class="newline" />(NB Excel uses the word AVERAGE rather than ‘mean’ in its function).
</p><!--l. 445--><p class="noindent" >5. Then create a new column, called (Y - mean(Y))^2 ) using the formula <br 
class="newline" /> = (dan.grump - AVERAGE(dan.grump))^2  .
</p><!--l. 448--><p class="noindent" >6. Then, at the bottom of this column calculate the sum of these values, <br 
class="newline" />i.e. sum( (Y - mean(Y))^2 ).
</p><!--l. 451--><p class="indent" >   This should give you a value of 9998.59. Hmm. Well, it’s a much bigger number than the last
one, so this does suggest that our regression model was making good predictions. But it’s not very
interpretable.
</p><!--l. 453--><p class="indent" >   Perhaps we can ﬁx this. What we’d like to do is to convert these two fairly meaningless numbers
into one number. A nice, interpretable number, which for no particular reason we’ll call R<sup>2</sup>. What
we would like is for the value of R<sup>2</sup> to be equal to 1 if the regression model makes no errors in
predicting the data. In other words, if it turns out that the residual errors are zero. That is, if
SS<sub>res</sub>   0 then we expect R<sup>2</sup>   1. Similarly, if the model is completely useless, we would like R<sup>2</sup> to
be equal to 0. What do I mean by “useless”? Tempting as it is to demand that the regression
model move out of the house, cut its hair and get a real job, I’m probably going to have
to pick a more practical deﬁnition. In this case, all I mean is that the residual sum of
squares is no smaller than the total sum of squares, SS<sub>res</sub>   SS<sub>tot</sub>. Wait, why don’t we do
                                                                                          

                                                                                          
exactly that? The formula that provides us with our R<sup>2</sup> value is pretty simple to write
down,
</p>
   <center class="math-display" >
<img 
src="lsj257x.png" alt="          SS
R2     1    ---res
          SStot  " class="math-display"  /></center> and
equally simple to calculate in Excel:
<!--l. 459--><p class="noindent" >7. Calculate R.squared by typing into a blank cell the following: <br 
class="newline" /> = 1 - (SS(resid) / SS(tot) ) .
</p><!--l. 462--><p class="indent" >   This gives a value for R<sup>2</sup> of 0.8161018. The R<sup>2</sup> value, sometimes called the <span id="textcolor339">coeﬃcient of
determination</span><span class="footnote-mark"><a 
href="lsj122.html#fn8x13"><sup class="textsuperscript">8</sup></a></span><a 
 id="x114-258001f8"></a> 
has a simple interpretation: it is the proportion of the variance in the outcome variable that can be
accounted for by the predictor. So, in this case the fact that we have obtained R<sup>2</sup>   .816
means that the predictor (my.sleep) explains 81.6% of the variance in the outcome
(my.grump).
</p><!--l. 464--><p class="indent" >   Naturally, you don’t actually need to type all these commands into Excel yourself
if you want to obtain the R<sup>2</sup> value for your regression model. As we’ll see later on in
Section <a 
href="#x114-26400012.7.3">12.7.3<!--tex4ht:ref: sec:regressionsummary --></a>, all you need to do is specify this as an option in jamovi. However, let’s put
that to one side for the moment. There’s another property of R<sup>2</sup> that I want to point
out.
</p>
   <h4 class="subsectionHead"><span class="titlemark">12.6.2   </span> <a 
 id="x114-25900012.6.2"></a>The relationship between regression and correlation</h4>
<!--l. 468--><p class="noindent" >At this point we can revisit my earlier claim that regression, in this very simple form
that I’ve discussed so far, is basically the same thing as a correlation. Previously, we
used the symbol r to denote a Pearson correlation. Might there be some relationship
between the value of the correlation coeﬃcient r and the R<sup>2</sup> value from linear regression?
Of course there is: the squared correlation r<sup>2</sup> is identical to the R<sup>2</sup> value for a linear
                                                                                          

                                                                                          
regression with only a single predictor. In other words, running a Pearson correlation is
more or less equivalent to running a linear regression model that uses only one predictor
variable.
</p><!--l. 470--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">12.6.3   </span> <a 
 id="x114-26000012.6.3"></a>The adjusted R<sup>2</sup> (R-squared) value</h4>
<!--l. 472--><p class="noindent" >One ﬁnal thing to point out before moving on. It’s quite common for people to report a slightly
diﬀerent measure of model performance, known as “adjusted R<sup>2</sup>”. The motivation behind
calculating the adjusted R<sup>2</sup> value is the observation that adding more predictors into the model will
always cause the R<sup>2</sup> value to increase (or at least not decrease).
</p><!--l. 476--><p class="indent" >   The adjusted R<sup>2</sup> value introduces a slight change to the calculation, as follows. For a regression
model with K predictors, ﬁt to a data set containing N observations, the adjusted R<sup>2</sup>
is:
</p>
   <center class="math-display" >
<img 
src="lsj258x.png" alt="
       2         SSres    -N-----1---
adj. R      1      SStot    N    K     1
" class="math-display"  /></center>
<!--l. 482--><p class="indent" >   This adjustment is an attempt to take the degrees of freedom into account. The big advantage
of the adjusted R<sup>2</sup> value is that when you add more predictors to the model, the adjusted R<sup>2</sup> value
will only increase if the new variables improve the model performance more than you’d expect by
chance. The big disadvantage is that the adjusted R<sup>2</sup> value can’t be interpreted in the elegant way
that R<sup>2</sup> can. R<sup>2</sup> has a simple interpretation as the proportion of variance in the outcome variable
that is explained by the regression model. To my knowledge, no equivalent interpretation exists for
adjusted R<sup>2</sup>.
</p><!--l. 484--><p class="indent" >   An obvious question then is whether you should report R<sup>2</sup> or adjusted R<sup>2</sup>. This is
probably a matter of personal preference. If you care more about interpretability, then R<sup>2</sup> is
better. If you care more about correcting for bias, then adjusted R<sup>2</sup> is probably better.
Speaking just for myself, I prefer R<sup>2</sup>. My feeling is that it’s more important to be able to
                                                                                          

                                                                                          
interpret your measure of model performance. Besides, as we’ll see in Section <a 
href="#x114-26100012.7">12.7<!--tex4ht:ref: sec:regressiontests --></a>, if
you’re worried that the improvement in R<sup>2</sup> that you get by adding a predictor is just
due to chance and not because it’s a better model, well we’ve got hypothesis tests for
that.
</p><!--l. 487--><p class="noindent" >
</p>
   <h3 class="sectionHead"><span class="titlemark">12.7   </span> <a 
 id="x114-26100012.7"></a>Hypothesis tests for regression models </h3>
<!--l. 489--><p class="noindent" >So far we’ve talked about what a regression model is, how the coeﬃcients of a regression model are
estimated, and how we quantify the performance of the model (the last of these, incidentally, is
basically our measure of eﬀect size). The next thing we need to talk about is hypothesis tests.
There are two diﬀerent (but related) kinds of hypothesis tests that we need to talk about: those in
which we test whether the regression model as a whole is performing signiﬁcantly better than a null
model, and those in which we test whether a particular regression coeﬃcient is signiﬁcantly
diﬀerent from zero.
</p><!--l. 492--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">12.7.1   </span> <a 
 id="x114-26200012.7.1"></a>Testing the model as a whole</h4>
<!--l. 494--><p class="noindent" >Okay, suppose you’ve estimated your regression model. The ﬁrst hypothesis test you might try is
the null hypothesis that there is no relationship between the predictors and the outcome, and the
alternative hypothesis that the data are distributed in exactly the way that the regression model
predicts.
</p><!--l. 498--><p class="indent" >   Formally, our “null model” corresponds to the fairly trivial “regression” model in which we
include 0 predictors and only include the intercept term b<sub>0</sub>:
</p>
   <center class="math-display" >
<img 
src="lsj259x.png" alt="H0 : Yi    b0   𝜖i  " class="math-display"  /></center> If
our regression model has K predictors, the “alternative model” is described using the usual formula
for a multiple regression model:
   <center class="math-display" >
<img 
src="lsj260x.png" alt="
                 K
H1  : Yi   b0         bkXik      𝜖i
                k   1
" class="math-display"  /></center>
<!--l. 507--><p class="indent" >   How can we test these two hypotheses against each other? The trick is to understand that it’s
possible to divide up the total variance SS<sub>tot</sub> into the sum of the residual variance SS<sub>res</sub> and the
regression model variance SS<sub>mod</sub>. I’ll skip over the technicalities, since we’ll get to that later when
we look at ANOVA in Chapter <a 
href="lsjch13.html#x131-28000013">13<!--tex4ht:ref: ch:anova --></a>. But just note that
</p>
   <center class="math-display" >
<img 
src="lsj261x.png" alt="SSmod     SStot   SSres  " class="math-display"  /></center> And
we can convert the sums of squares into mean squares by dividing by the degrees of
freedom.
   <center class="math-display" >
<img 
src="lsj262x.png" alt="            SSmod
MSmod        ------
            dfmod

 MS          SSres
    res      dfres  " class="math-display"  /></center> So,
how many degrees of freedom do we have? As you might expect the df associated with the model is
closely tied to the number of predictors that we’ve included. In fact, it turns out that df<sub>mod</sub>   K.
For the residuals the total degrees of freedom is df<sub>res</sub>   N   K   1.
<!--l. 519--><p class="indent" >   Now that we’ve got our mean square values we can calculate an F-statistic like this
</p>
   <center class="math-display" >
<img 
src="lsj263x.png" alt="     MSmod--
F     MSres  " class="math-display"  /></center> and
the degrees of freedom associated with this are K and N   K   1.
<!--l. 526--><p class="indent" >   We’ll see much more of the F statistic in Chapter <a 
href="lsjch13.html#x131-28000013">13<!--tex4ht:ref: ch:anova --></a>, but for now just know that we can
interpret large F values as indicating that the null hypothesis is performing poorly in
comparison to the alternative hypothesis. In a moment I’ll show you how to do the test in
jamovi the easy way, but ﬁrst let’s have a look at the tests for the individual regression
coeﬃcients.
</p><!--l. 528--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">12.7.2   </span> <a 
 id="x114-26300012.7.2"></a>Tests for individual coeﬃcients</h4>
<!--l. 530--><p class="noindent" >The F-test that we’ve just introduced is useful for checking that the model as a whole is performing
better than chance. If your regression model doesn’t produce a signiﬁcant result for the F-test then
you probably don’t have a very good regression model (or, quite possibly, you don’t have very good
data). However, while failing this test is a pretty strong indicator that the model has problems,
passing the test (i.e., rejecting the null) doesn’t imply that the model is good! Why is that, you
might be wondering? The answer to that can be found by looking at the coeﬃcients for the
                                                                                          

                                                                                          
multiple regression model we have already looked at in section <a 
href="#x114-25400012.5">12.5<!--tex4ht:ref: sec:multipleregression --></a> above, where the coeﬃcients we
got were:
                                                                                          

                                                                                          
</p>
   <div class="verbatim" id="verbatim-41">
<span 
class="cmtt-12">(Intercept)</span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> dan.sleep</span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> baby.sleep</span>
<span 
class="cmtt-12"> </span><br /><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> 125.97</span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> -8.95</span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> 0.01</span>
</div>
<!--l. 535--><p class="nopar" >
</p><!--l. 537--><p class="indent" >   I can’t help but notice that the estimated regression coeﬃcient for the baby.sleep variable is
tiny (0.01), relative to the value that we get for dan.sleep (-8.95). Given that these two variables
are absolutely on the same scale (they’re both measured in “hours slept”), I ﬁnd this illuminating.
In fact, I’m beginning to suspect that it’s really only the amount of sleep that I get that matters in
order to predict my grumpiness.
</p><!--l. 539--><p class="indent" >   We can re-use a hypothesis test that we discussed earlier, the t-test. The test that we’re
interested in has a null hypothesis that the true regression coeﬃcient is zero (b   0), which is to be
tested against the alternative hypothesis that it isn’t (b   0). That is:
</p>
   <center class="math-display" >
<img 
src="lsj264x.png" alt="H0  : b    0
H1  : b    0  " class="math-display"  /></center> How
can we test this? Well, if the central limit theorem is kind to us we might be able to guess
that the sampling distribution of <img 
src="lsj265x.png" alt="ˆb"  class="circ"  /> , the estimated regression coeﬃcient, is a normal
distribution with mean centred on b. What that would mean is that if the null hypothesis
were true, then the sampling distribution of <img 
src="lsj266x.png" alt="ˆ
b"  class="circ"  /> has mean zero and unknown standard
deviation. Assuming that we can come up with a good estimate for the standard error of the
regression coeﬃcient, sep<img 
src="lsj267x.png" alt="ˆb"  class="circ"  /> q, then we’re in luck. That’s exactly the situation for which we
introduced the one-sample t-test way back in Chapter <a 
href="lsjch11.html#x97-20200011">11<!--tex4ht:ref: ch:ttest --></a>. So let’s deﬁne a t-statistic like
this
                                                                                          

                                                                                          
   <center class="math-display" >
<img 
src="lsj268x.png" alt="      ˆ
t    --b---
    sepˆbq  " class="math-display"  /></center> I’ll
skip over the reasons why, but our degrees of freedom in this case are df   N   K   1.
Irritatingly, the estimate of the standard error of the regression coeﬃcient, sep<img 
src="lsj269x.png" alt="ˆb"  class="circ"  /> q, is not as
easy to calculate as the standard error of the mean that we used for the simpler t-tests
in Chapter <a 
href="lsjch11.html#x97-20200011">11<!--tex4ht:ref: ch:ttest --></a>. In fact, the formula is somewhat ugly, and not terribly helpful to look
at.<span class="footnote-mark"><a 
href="lsj123.html#fn9x13"><sup class="textsuperscript">9</sup></a></span><a 
 id="x114-263001f9"></a> 
For our purposes it’s suﬃcient to point out that the standard error of the estimated
regression coeﬃcient depends on both the predictor and outcome variables, and it is
somewhat sensitive to violations of the homogeneity of variance assumption (discussed
shortly).
<!--l. 552--><p class="indent" >   In any case, this t-statistic can be interpreted in the same way as the t-statistics that we
discussed in Chapter <a 
href="lsjch11.html#x97-20200011">11<!--tex4ht:ref: ch:ttest --></a>. Assuming that you have a two-sided alternative (i.e., you don’t really care
if b   0 or b   0), then it’s the extreme values of t (i.e., a lot less than zero or a lot greater than
zero) that suggest that you should reject the null hypothesis.
</p>
   <h4 class="subsectionHead"><span class="titlemark">12.7.3   </span> <a 
 id="x114-26400012.7.3"></a>Running the hypothesis tests in jamovi </h4>
<!--l. 557--><p class="noindent" >To compute all of the statistics that we have talked about so far, all you need to do is make sure
the relevant options are checked in jamovi and then run the regression. If we do that, as in Figure
<a 
href="#x114-26400115">12.15<!--tex4ht:ref: fig:reg2 --></a>, we get a whole bunch of useful output.
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x114-26400115"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 560--><p class="noindent" >

</p><!--l. 561--><p class="noindent" ><img 
src="../img/regression/reg2.png" alt="PIC"  
 />
<br /> </p><div class="caption" 
><span class="id">Figure 12.15: </span><span  
class="content">A jamovi screenshot showing a multiple linear regression analysis, with some
useful options checked.</span></div><!--tex4ht:label?: x114-26400115 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 568--><p class="indent" >   The ‘Model Coeﬃcients’ at the bottom of the jamovi analysis results shown in <a 
href="#x114-26400115">12.15<!--tex4ht:ref: fig:reg2 --></a> provides
the coeﬃcients of the regression model. Each row in this table refers to one of the coeﬃcients in the
regression model. The ﬁrst row is the intercept term, and the later ones look at each of the
predictors. The columns give you all of the relevant information. The ﬁrst column is the actual
estimate of b (e.g., 125.97 for the intercept, and -8.95 for the dan.sleep predictor). The second
column is the standard error estimate <img 
src="lsj274x.png" alt="ˆσ"  class="circ"  /><sub>b</sub>. The third and fourth columns provide the lower
and upper values for the 95% conﬁdence interval around the b estimate (more on this
later). The ﬁfth column gives you the t-statistic, and it’s worth noticing that in this table
t   <img 
src="lsj275x.png" alt="ˆb"  class="circ"  /> {sep<img 
src="lsj276x.png" alt="ˆb"  class="circ"  /> q every time. Finally, the last column gives you the actual p-value for each of these
tests.<span class="footnote-mark"><a 
href="lsj124.html#fn10x13"><sup class="textsuperscript">10</sup></a></span><a 
 id="x114-264002f10"></a> 
</p><!--l. 570--><p class="indent" >   The only thing that the coeﬃcients table itself doesn’t list is the degrees of freedom used in the
t-test, which is always N   K   1 and is listed in the table at the top of the output, labelled ‘Model
Fit Measures’. We can see from this table that the model performs signiﬁcantly better than you’d
expect by chance (Fp2, 97q   215.24, p   .001), which isn’t all that surprising: the R<sup>2</sup>   .81 value
indicate that the regression model accounts for 81% of the variability in the outcome measure (and
82% for the adjusted R<sup>2</sup>). However, when we look back up at the t-tests for each of the
individual coeﬃcients, we have pretty strong evidence that the baby.sleep variable has no
signiﬁcant eﬀect. All the work in this model is being done by the dan.sleep variable.
Taken together, these results suggest that this regression model is actually the wrong
model for the data. You’d probably be better oﬀ dropping the baby.sleep predictor
entirely. In other words, the simple regression model that we started with is the better
model.
</p>
   <h3 class="sectionHead"><span class="titlemark">12.8   </span> <a 
 id="x114-26500012.8"></a>Regarding regression coeﬃcients </h3>
<!--l. 657--><p class="noindent" >Before moving on to discuss the assumptions underlying linear regression and what you can do to
check if they’re being met, there’s two more topics I want to brieﬂy discuss, both of which relate to
the regression coeﬃcients. The ﬁrst thing to talk about is calculating conﬁdence intervals for the
coeﬃcients. After that, I’ll discuss the somewhat murky question of how to determine which
predictor is most important.
                                                                                          

                                                                                          
</p><!--l. 659--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">12.8.1   </span> <a 
 id="x114-26600012.8.1"></a>Conﬁdence intervals for the coeﬃcients</h4>
<!--l. 661--><p class="noindent" >Like any population parameter, the regression coeﬃcients b cannot be estimated with complete
precision from a sample of data; that’s part of why we need hypothesis tests. Given this, it’s quite
useful to be able to report conﬁdence intervals that capture our uncertainty about the true value of
b. This is especially useful when the research question focuses heavily on an attempt to ﬁnd out
how strongly variable X is related to variable Y , since in those situations the interest is primarily in
the regression weight b.
</p><!--l. 665--><p class="indent" >   Fortunately, conﬁdence intervals for the regression weights can be constructed in the usual
fashion
</p>
   <center class="math-display" >
<img 
src="lsj277x.png" alt="
CIpbq    ˆb     tcrit   sepˆbq" class="math-display"  /></center>
where sep<img 
src="lsj278x.png" alt="ˆb"  class="circ"  /> q is the standard error of the regression coeﬃcient, and t<sub>crit</sub> is the relevant critical value
of the appropriate t distribution. For instance, if it’s a 95% conﬁdence interval that we want, then
the critical value is the 97.5th quantile of a t distribution with N   K   1 degrees of freedom. In
other words, this is basically the same approach to calculating conﬁdence intervals that we’ve used
throughout.
<!--l. 672--><p class="indent" >   In jamovi we had already speciﬁed the ‘95% Conﬁdence interval’ as shown if Figure <a 
href="#x114-26400115">12.15<!--tex4ht:ref: fig:reg2 --></a>,
although we could easily have chosen another value, say a ‘99% Conﬁdence interval’ if that is what
we decided on.
</p><!--l. 675--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">12.8.2   </span> <a 
 id="x114-26700012.8.2"></a>Calculating standardised regression coeﬃcients</h4>
<!--l. 677--><p class="noindent" >One more thing that you might want to do is to calculate “standardised” regression coeﬃcients,
often denoted β. The rationale behind standardised coeﬃcients goes like this. In a lot of situations,
                                                                                          

                                                                                          
your variables are on fundamentally diﬀerent scales. Suppose, for example, my regression model
aims to predict people’s IQ scores using their educational attainment (number of years of
education) and their income as predictors. Obviously, educational attainment and income are not
on the same scales. The number of years of schooling might only vary by 10s of years, whereas
income can vary by 10,000s of dollars (or more). The units of measurement have a big
inﬂuence on the regression coeﬃcients. The b coeﬃcients only make sense when interpreted
in light of the units, both of the predictor variables and the outcome variable. This
makes it very diﬃcult to compare the coeﬃcients of diﬀerent predictors. Yet there are
situations where you really do want to make comparisons between diﬀerent coeﬃcients.
Speciﬁcally, you might want some kind of standard measure of which predictors have the
strongest relationship to the outcome. This is what <span id="textcolor343">standardised coeﬃcients</span> aim to
do.
</p><!--l. 679--><p class="indent" >   The basic idea is quite simple; the standardised coeﬃcients are the coeﬃcients that you
would have obtained if you’d converted all the variables to z-scores before running the
regression.<span class="footnote-mark"><a 
href="lsj125.html#fn11x13"><sup class="textsuperscript">11</sup></a></span><a 
 id="x114-267001f11"></a> 
The idea here is that, by converting all the predictors to z-scores, they all go into the regression on
the same scale, thereby removing the problem of having variables on diﬀerent scales. Regardless of
what the original variables were, a β value of 1 means that an increase in the predictor of 1
standard deviation will produce a corresponding 1 standard deviation increase in the outcome
variable. Therefore, if variable A has a larger absolute value of β than variable B, it is deemed to
have a stronger relationship with the outcome. Or at least that’s the idea. It’s worth being a little
cautious here, since this does rely very heavily on the assumption that “a 1 standard deviation
change” is fundamentally the same kind of thing for all variables. It’s not always obvious that this
is true.
</p><!--l. 683--><p class="indent" >   Leaving aside the interpretation issues, let’s look at how it’s calculated. What you could do is
standardise all the variables yourself and then run a regression, but there’s a much simpler way to
do it. As it turns out, the β coeﬃcient for a predictor X and outcome Y has a very simple formula,
namely
                                                                                          

                                                                                          
</p>
   <center class="math-display" >
<img 
src="lsj279x.png" alt="βX    bX     σX-
           σY  " class="math-display"  /></center>
where σ<sub>X</sub> is the standard deviation of the predictor, and σ<sub>Y </sub> is the standard deviation of the
outcome variable Y . This makes matters a lot simpler.
<!--l. 690--><p class="indent" >   To make things even simpler, jamovi has an option that computes the β coeﬃcients for you
using the ‘Standardized estimate’ checkbox in the ‘Model Coeﬃcients’ options, see results in Figure
<a 
href="#x114-26700216">12.16<!--tex4ht:ref: fig:reg3 --></a>.
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x114-26700216"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 693--><p class="noindent" >

</p><!--l. 694--><p class="noindent" ><img 
src="../img/regression/reg3-.png" alt="PIC"  
 />
<br /> </p><div class="caption" 
><span class="id">Figure 12.16: </span><span  
class="content">Standardised coeﬃcients, with 95% conﬁdence intervals, for multiple linear
regression</span></div><!--tex4ht:label?: x114-26700216 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 701--><p class="indent" >   This clearly shows that the dan.sleep variable has a much stronger eﬀect than the baby.sleep
variable. However, this is a perfect example of a situation where it would probably make sense to
use the original coeﬃcients b rather than the standardised coeﬃcients β. After all, my sleep and the
baby’s sleep are already on the same scale: number of hours slept. Why complicate matters by
converting these to z-scores?
</p>
   <h3 class="sectionHead"><span class="titlemark">12.9   </span> <a 
 id="x114-26800012.9"></a>Assumptions of regression </h3>
<!--l. 706--><p class="noindent" >The linear regression model that I’ve been discussing relies on several assumptions. In
Section <a 
href="#x114-26900012.10">12.10<!--tex4ht:ref: sec:regressiondiagnostics --></a> we’ll talk a lot more about how to check that these assumptions are being met, but
ﬁrst let’s have a look at each of them.
</p>
      <ul class="itemize1">
      <li class="itemize">Normality.  Like  many  of  the  models  in  statistics,  basic  simple  or  multiple  linear
      regression  relies  on  an  assumption  of  normality.  Speciﬁcally,  it  assumes  that  the
      residuals are normally distributed. It’s actually okay if the predictors X and the outcome
      Y are non-normal, so long as the residuals 𝜖 are normal. See Section <a 
href="#x114-27200012.10.3">12.10.3<!--tex4ht:ref: sec:regressionnormality --></a>.
      </li>
      <li class="itemize">Linearity. A pretty fundamental assumption of the linear regression model is that the
      relationship between X and Y  actually is linear! Regardless of whether it’s a simple
      regression or a multiple regression, we assume that the relationships involved are linear.
      </li>
      <li class="itemize">Homogeneity of variance. Strictly speaking, the regression model assumes that each
      residual 𝜖<sub>i</sub> is generated from a normal distribution with mean 0, and (more importantly
      for  the  current  purposes)  with  a  standard  deviation  σ that  is  the  same  for  every
      single residual. In practice, it’s impossible to test the assumption that every residual is
      identically distributed. Instead, what we care about is that the standard deviation of
      the residual is the same for all values of Ŷ, and (if we’re being especially paranoid) all
      values of every predictor X in the model.
      </li>
      <li class="itemize">Uncorrelated predictors. The idea here is that, in a multiple regression model, you
      don’t want your predictors to be too strongly correlated with each other. This isn’t
      “technically”  an  assumption  of  the  regression  model,  but  in  practice  it’s  required.
                                                                                          

                                                                                          
      Predictors that are too strongly correlated with each other (referred to as “collinearity”)
      can cause problems when evaluating the model. See Section <a 
href="#x114-27300012.10.4">12.10.4<!--tex4ht:ref: sec:regressioncollinearity --></a>
      </li>
      <li class="itemize">Residuals are independent of each other. This is really just a “catch all” assumption,
      to the eﬀect that “there’s nothing else funny going on in the residuals”. If there is
      something  weird  (e.g.,  the  residuals  all  depend  heavily  on  some  other  unmeasured
      variable) going on, it might screw things up.
      </li>
      <li class="itemize">No “bad” outliers. Again, not actually a technical assumption of the model (or rather,
      it’s sort of implied by all the others), but there is an implicit assumption that your
      regression model isn’t being too strongly inﬂuenced by one or two anomalous data points
      because this raises questions about the adequacy of the model and the trustworthiness
      of the data in some cases. See Section <a 
href="#x114-27100012.10.2">12.10.2<!--tex4ht:ref: sec:regressionoutliers --></a>.</li></ul>
<!--l. 717--><p class="noindent" >
</p>
   <h3 class="sectionHead"><span class="titlemark">12.10   </span> <a 
 id="x114-26900012.10"></a>Model checking </h3>
<!--l. 719--><p class="noindent" >The main focus of this section is <span id="textcolor345">regression diagnostics</span>, a term that refers to the art of checking
that the assumptions of your regression model have been met, ﬁguring out how to ﬁx the model if
the assumptions are violated, and generally to check that nothing “funny” is going on. I refer to
this as the “art” of model checking with good reason. It’s not easy, and while there are a lot of
fairly standardised tools that you can use to diagnose and maybe even cure the problems that ail
your model (if there are any, that is!), you really do need to exercise a certain amount of judgement
when doing this. It’s easy to get lost in all the details of checking this thing or that thing,
and it’s quite exhausting to try to remember what all the diﬀerent things are. This
has the very nasty side eﬀect that a lot of people get frustrated when trying to learn
all the tools, so instead they decide not to do any model checking. This is a bit of a
worry!
</p><!--l. 721--><p class="indent" >   In this section I describe several diﬀerent things you can do to check that your regression model
is doing what it’s supposed to. It doesn’t cover the full space of things you could do, but it’s still
much more detailed than what I see a lot of people doing in practice, and even I don’t usually cover
all of this in my intro stats class either. However, I do think it’s important that you get a
sense of what tools are at your disposal, so I’ll try to introduce a bunch of them here.
Finally, I should note that this section draws quite heavily from the Fox and Weisberg
(2011) text, the book associated with the car package that is used to conduct regression
                                                                                          

                                                                                          
analysis in R. The car package is notable for providing some excellent tools for regression
diagnostics, and the book itself talks about them in an admirably clear fashion. I don’t
want to sound too gushy about it, but I do think that Fox et al. (2011) is well worth
reading, even if some of the advanced diagnostic techniques are only available in R and not
jamovi.
</p><!--l. 723--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">12.10.1   </span> <a 
 id="x114-27000012.10.1"></a>Three kinds of residuals</h4>
<!--l. 725--><p class="noindent" >The majority of regression diagnostics revolve around looking at the residuals, and by now you’ve
probably formed a suﬃciently pessimistic theory of statistics to be able to guess that,
precisely because of the fact that we care a lot about the residuals, there are several
diﬀerent kinds of residual that we might consider. In particular, the following three
kinds of residuals are referred to in this section: “ordinary residuals”, “standardised
residuals”, and “Studentised residuals”. There is a fourth kind that you’ll see referred to in
some of the Figures, and that’s the “Pearson residual”. However, for the models that
we’re talking about in this chapter the Pearson residual is identical to the ordinary
residual.
</p><!--l. 727--><p class="indent" >   The ﬁrst and simplest kind of residuals that we care about are <span id="textcolor346">ordinary residuals</span>. These are
the actual raw residuals that I’ve been talking about throughout this chapter so far. The ordinary
residual is just the diﬀerence between the ﬁtted value Ŷ<sub>i</sub> and the observed value Y <sub>i</sub>. I’ve been using
the notation 𝜖<sub>i</sub> to refer to the i-th ordinary residual, and by gum I’m going to stick to it. With this
in mind, we have the very simple equation
</p>
   <center class="math-display" >
<img 
src="lsj280x.png" alt="𝜖i    Yi   Yˆi  " class="math-display"  /></center> This
is of course what we saw earlier, and unless I speciﬁcally refer to some other kind of residual, this is
the one I’m talking about. So there’s nothing new here. I just wanted to repeat myself. One
drawback to using ordinary residuals is that they’re always on a diﬀerent scale, depending on what
the outcome variable is and how good the regression model is. That is, unless you’ve decided to run
                                                                                          

                                                                                          
a regression model without an intercept term, the ordinary residuals will have mean 0 but the
variance is diﬀerent for every regression. In a lot of contexts, especially where you’re only interested
in the pattern of the residuals and not their actual values, it’s convenient to estimate the
<span id="textcolor347">standardised residuals</span>, which are normalised in such a way as to have standard deviation
1.
<!--l. 735--><p class="indent" >   The way we calculate these is to divide the ordinary residual by an estimate of the (population)
standard deviation of these residuals. For technical reasons, mumble mumble, the formula for this
is
</p>
   <center class="math-display" >
<img 
src="lsj281x.png" alt="𝜖1    -?-𝜖i-----
 i   ˆσ  1    hi  " class="math-display"  /></center> where <img 
src="lsj282x.png" alt="ˆσ"  class="circ"  />
in this context is the estimated population standard deviation of the ordinary residuals, and h<sub>i</sub> is
the “hat value” of the ith observation. I haven’t explained hat values to you yet (but have no
fear,<span class="footnote-mark"><a 
href="lsj126.html#fn12x13"><sup class="textsuperscript">12</sup></a></span><a 
 id="x114-270001f12"></a> 
it’s coming shortly), so this won’t make a lot of sense. For now, it’s enough to interpret the
standardised residuals as if we’d converted the ordinary residuals to z-scores. In fact, that is more
or less the truth, it’s just that we’re being a bit fancier.
<!--l. 742--><p class="indent" >   The third kind of residuals are <span id="textcolor349">Studentised residuals</span> (also called “jackknifed residuals”) and
they’re even fancier than standardised residuals. Again, the idea is to take the ordinary residual
and divide it by some quantity in order to estimate some standardised notion of the
residual.
</p><!--l. 746--><p class="indent" >   The formula for doing the calculations this time is subtly diﬀerent
                                                                                          

                                                                                          
</p>
   <center class="math-display" >
<img 
src="lsj283x.png" alt="𝜖      -----?𝜖i------
 i   ˆσp  iq  1   hi
" class="math-display"  /></center> Notice that our estimate of the standard deviation here is written <img 
src="lsj284x.png" alt="ˆσ"  class="circ"  /><sub>p iq</sub>. What this
corresponds to is the estimate of the residual standard deviation that you would have
obtained if you just deleted the ith observation from the data set. This sounds like the
sort of thing that would be a nightmare to calculate, since it seems to be saying that
you have to run N new regression models (even a modern computer might grumble a
bit at that, especially if you’ve got a large data set). Fortunately, some terribly clever
person has shown that this standard deviation estimate is actually given by the following
equation:
   <center class="math-display" >
<img 
src="lsj285x.png" alt="         d  -----------------
            N     K    1    𝜖12
ˆσp  iq    ˆσ    --------------i-
              N     K     2  " class="math-display"  /></center> Isn’t
that a pip?
<!--l. 757--><p class="indent" >   Before moving on, I should point out that you don’t often need to obtain these residuals
yourself, even though they are at the heart of almost all regression diagnostics. Most of the time
the various options that provide the diagnostics, or assumption checks, will take care of these
calculations for you. Even so, it’s always nice to know how to actually get hold of these things
yourself in case you ever need to do something non-standard.
</p>
   <h4 class="subsectionHead"><span class="titlemark">12.10.2   </span> <a 
 id="x114-27100012.10.2"></a>Three kinds of anomalous data </h4>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x114-27100117"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 763--><p class="noindent" >
</p><!--l. 764--><p class="noindent" ><img 
src="lsj286x.png" alt="PIC" class="graphics" width="284" height="284"  /><!--tex4ht:graphics  
name="lsj286x.png" src="../img/regression2/unusual_outlier.eps"  
-->
<br /> </p><div class="caption" 
><span class="id">Figure 12.17: </span><span  
class="content">An illustration of outliers. The dotted lines plot the regression line that would
have been estimated without the anomalous observation included, and the corresponding
residual (i.e., the Studentised residual). The solid line shows the regression line with the
anomalous observation included. The outlier has an unusual value on the outcome (y axis
location) but not the predictor (x axis location), and lies a long way from the regression line.</span></div><!--tex4ht:label?: x114-27100117 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x114-27100218"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 772--><p class="noindent" >
</p><!--l. 773--><p class="noindent" ><img 
src="lsj287x.png" alt="PIC" class="graphics" width="284" height="284"  /><!--tex4ht:graphics  
name="lsj287x.png" src="../img/regression2/unusual_leverage.eps"  
-->
<br /> </p><div class="caption" 
><span class="id">Figure 12.18: </span><span  
class="content">An illustration of high leverage points. The anomalous observation in this
case is unusual both in terms of the predictor (x axis) and the outcome (y axis), but this
unusualness is highly consistent with the pattern of correlations that exists among the other
observations. The observation falls very close to the regression line and does not distort it.</span></div><!--tex4ht:label?: x114-27100218 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x114-27100319"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 781--><p class="noindent" >
</p><!--l. 782--><p class="noindent" ><img 
src="lsj288x.png" alt="PIC" class="graphics" width="284" height="284"  /><!--tex4ht:graphics  
name="lsj288x.png" src="../img/regression2/unusual_influence.eps"  
-->
<br /> </p><div class="caption" 
><span class="id">Figure 12.19: </span><span  
class="content">An illustration of high inﬂuence points. In this case, the anomalous observation
is highly unusual on the predictor variable (x axis), and falls a long way from the regression
line. As a consequence, the regression line is highly distorted, even though (in this case) the
anomalous observation is entirely typical in terms of the outcome variable (y axis).</span></div><!--tex4ht:label?: x114-27100319 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 789--><p class="indent" >   One danger that you can run into with linear regression models is that your analysis
might be disproportionately sensitive to a smallish number of “unusual” or “anomalous”
observations. I discussed this idea previously in Section <a 
href="lsjch5.html#x37-920005.2.3">5.2.3<!--tex4ht:ref: sec:boxplotoutliers --></a> in the context of discussing the
outliers that get automatically identiﬁed by the boxplot option under ‘Exploration’ -
‘Descriptives’, but this time we need to be much more precise. In the context of linear
regression, there are three conceptually distinct ways in which an observation might be called
“anomalous”. All three are interesting, but they have rather diﬀerent implications for your
analysis.
</p><!--l. 791--><p class="indent" >   The ﬁrst kind of unusual observation is an <span id="textcolor350">outlier</span>. The deﬁnition of an outlier (in this context)
is an observation that is very diﬀerent from what the regression model predicts. An example is
shown in Figure <a 
href="#x114-27100117">12.17<!--tex4ht:ref: fig:outlier --></a>. In practice, we operationalise this concept by saying that an
outlier is an observation that has a very large Studentised residual, 𝜖<sub>i</sub><sup> </sup>. Outliers are
interesting: a big outlier might correspond to junk data, e.g., the variables might have been
recorded incorrectly in the data set, or some other defect may be detectable. Note that you
shouldn’t throw an observation away just because it’s an outlier. But the fact that it’s an
outlier is often a cue to look more closely at that case and try to ﬁnd out why it’s so
diﬀerent.
</p><!--l. 793--><p class="indent" >   The second way in which an observation can be unusual is if it has high <span id="textcolor351">leverage</span>, which
happens when the observation is very diﬀerent from all the other observations. This doesn’t
necessarily have to correspond to a large residual. If the observation happens to be unusual on all
variables in precisely the same way, it can actually lie very close to the regression line. An
example of this is shown in Figure <a 
href="#x114-27100218">12.18<!--tex4ht:ref: fig:leverage --></a>. The leverage of an observation is operationalised
in terms of its hat value, usually written h<sub>i</sub>. The formula for the hat value is rather
complicated<span class="footnote-mark"><a 
href="lsj127.html#fn13x13"><sup class="textsuperscript">13</sup></a></span><a 
 id="x114-271004f13"></a> 
but its interpretation is not: h<sub>i</sub> is a measure of the extent to which the i-th observation is “in
control” of where the regression line ends up going.
</p><!--l. 795--><p class="indent" >   In general, if an observation lies far away from the other ones in terms of the predictor
variables, it will have a large hat value (as a rough guide, high leverage is when the hat
value is more than 2-3 times the average; and note that the sum of the hat values is
constrained to be equal to K   1). High leverage points are also worth looking at in
more detail, but they’re much less likely to be a cause for concern unless they are also
outliers.
                                                                                          

                                                                                          
</p><!--l. 797--><p class="indent" >   This brings us to our third measure of unusualness, the <span id="textcolor353">inﬂuence</span> of an observation. A high
inﬂuence observation is an outlier that has high leverage. That is, it is an observation that is very
diﬀerent to all the other ones in some respect, and also lies a long way from the regression
line. This is illustrated in Figure <a 
href="#x114-27100319">12.19<!--tex4ht:ref: fig:influence --></a>. Notice the contrast to the previous two ﬁgures.
Outliers don’t move the regression line much and neither do high leverage points. But
something that is both an outlier and has high leverage, well that has a big eﬀect on the
regression line. That’s why we call these points high inﬂuence, and it’s why they’re
the biggest worry. We operationalise inﬂuence in terms of a measure known as <span id="textcolor354">Cook’s
distance</span>.
                                                                                          

                                                                                          
</p><!--l. 801--><p class="indent" >
</p>
   <center class="math-display" >
<img 
src="lsj289x.png" alt="        𝜖  2      h
Di     ---i--    ---i--
      K     1   1    hi  " class="math-display"  /></center>
Notice that this is a multiplication of something that measures the outlier-ness of the observation
(the bit on the left), and something that measures the leverage of the observation (the bit on the
right).
<!--l. 807--><p class="indent" >   In order to have a large Cook’s distance an observation must be a fairly substantial outlier and
have high leverage. As a rough guide, Cook’s distance greater than 1 is often considered large
(that’s what I typically use as a quick and dirty rule).
</p><!--l. 809--><p class="indent" >   In jamovi, information about Cook’s distance can be calculated by clicking on the ‘Cook’s
Distance’ checkbox in the ‘Assumption Checks’ - ‘Data Summary’ options. When you do this, for
the multiple regression model we have been using as an example in this chapter, you get the results
as shown in Figure <a 
href="#x114-27100520">12.20<!--tex4ht:ref: fig:reg4 --></a>.
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x114-27100520"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 812--><p class="noindent" >

</p><!--l. 813--><p class="noindent" ><img 
src="../img/regression/reg4.png" alt="PIC"  
 />
<br /> </p><div class="caption" 
><span class="id">Figure 12.20: </span><span  
class="content">jamovi output showing the table for the Cook’s distance statistics</span></div><!--tex4ht:label?: x114-27100520 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 820--><p class="indent" >   You can see that, in this example, the mean Cook’s distance value is 0.01, and the range is from
0.00000262 to 0.11, so this is some way oﬀ the rule of thumb ﬁgure mentioned above that a Cook’s
distance greater than 1 is considered large.
</p><!--l. 822--><p class="indent" >   An obvious question to ask next is, if you do have large values of Cook’s distance
what should you do? As always, there’s no hard and fast rule. Probably the ﬁrst
thing to do is to try running the regression with the outlier with the greatest Cook’s
distance<span class="footnote-mark"><a 
href="lsj128.html#fn14x13"><sup class="textsuperscript">14</sup></a></span><a 
 id="x114-271006f14"></a> 
excluded and see what happens to the model performance and to the regression coeﬃcients. If they
really are substantially diﬀerent, it’s time to start digging into your data set and your notes that
you no doubt were scribbling as your ran your study. Try to ﬁgure out why the point is so diﬀerent.
If you start to become convinced that this one data point is badly distorting your results then you
might consider excluding it, but that’s less than ideal unless you have a solid explanation for why
this particular case is qualitatively diﬀerent from the others and therefore deserves to be handled
separately.
</p>
   <h4 class="subsectionHead"><span class="titlemark">12.10.3   </span> <a 
 id="x114-27200012.10.3"></a>Checking the normality of the residuals </h4>
<!--l. 826--><p class="noindent" >Like many of the statistical tools we’ve discussed in this book, regression models rely on a
normality assumption. In this case, we assume that the residuals are normally distributed. The ﬁrst
thing we can do is draw a QQ-plot via the ‘Assumption Checks’ - ‘Assumption Checks’ - ‘Q-Q plot
of residuals’ option.
</p><!--l. 828--><p class="indent" >   The output is shown in Figure <a 
href="#x114-27200121">12.21<!--tex4ht:ref: fig:reg5 --></a>, showing the standardised residuals plotted as a function
of their theoretical quantiles according to the regression model.
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x114-27200121"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 831--><p class="noindent" >

</p><!--l. 832--><p class="noindent" ><img 
src="../img/regression/reg5-.png" alt="PIC"  
 />
<br /> </p><div class="caption" 
><span class="id">Figure 12.21: </span><span  
class="content">Plot of the theoretical quantiles according to the model, against the quantiles
of the standardised residuals, produced in jamovi </span></div><!--tex4ht:label?: x114-27200121 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 839--><p class="indent" >   Another thing we should check is the relationship between the ﬁtted values and the residuals
themselves. We can get jamovi to do this using the ‘Residuals Plots’ option, which provides a
scatterplot for each predictor variable, the outcome variable, and the ﬁtted values against residuals,
see Figure <a 
href="#x114-27200222">12.22<!--tex4ht:ref: fig:reg6 --></a>. In these plots we are looking for a fairly uniform distribution of ‘dots’, with no
clear bunching or patterning of the ‘dots’. Looking at these plots, there is nothing particularly
worrying as the dots are fairly evenly spread across the whole plot. There may be a little bit of
non-uniformity in plot (b), but it is not a strong deviation and probably not worth worrying
about.
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x114-27200222"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 842--><p class="noindent" >
</p>
<div class="tabular"> <table id="TBL-79" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-79-1g"><col 
id="TBL-79-1" /><col 
id="TBL-79-2" /></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-79-1-"><td  style="white-space:nowrap; text-align:center;" id="TBL-79-1-1"  
class="td11"> <img 
src="../img/regression/reg6a-.png" alt="PIC"  
 /></td><td  style="white-space:nowrap; text-align:center;" id="TBL-79-1-2"  
class="td11"> <img 
src="../img/regression/reg6b-.png" alt="PIC"  
 /></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-79-2-"><td  style="white-space:nowrap; text-align:center;" id="TBL-79-2-1"  
class="td11"> (a)  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-79-2-2"  
class="td11"> (b) </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-79-3-"><td  style="white-space:nowrap; text-align:center;" id="TBL-79-3-1"  
class="td11"> <img 
src="../img/regression/reg6c-.png" alt="PIC"  
 /> </td><td  style="white-space:nowrap; text-align:center;" id="TBL-79-3-2"  
class="td11"> <img 
src="../img/regression/reg6d-.png" alt="PIC"  
 /></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-79-4-"><td  style="white-space:nowrap; text-align:center;" id="TBL-79-4-1"  
class="td11"> (c)  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-79-4-2"  
class="td11"> (d) </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-79-5-"><td  style="white-space:nowrap; text-align:center;" id="TBL-79-5-1"  
class="td11">     </td></tr></table></div>
<br /> <div class="caption" 
><span class="id">Figure 12.22: </span><span  
class="content">Residuals plots produced in jamovi</span></div><!--tex4ht:label?: x114-27200222 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 857--><p class="indent" >   If we were worried, then in a lot of cases the solution to this problem (and many others) is to
transform one or more of the variables. We discussed the basics of variable transformation in
Sections <a 
href="lsjch6.html#x40-1040006.3">6.3<!--tex4ht:ref: sec:transform --></a> and <a 
href="lsjch6.html#x40-1080006.4">6.4<!--tex4ht:ref: sec:mathfunc --></a>, but I do want to make special note of one additional possibility that I didn’t
explain fully earlier: the Box-Cox transform.  The Box-Cox function is a fairly simple one and it’s
very widely used.
</p><!--l. 861--><p class="indent" >
</p>
   <center class="math-display" >
<img 
src="lsj290x.png" alt="           λ
          x-----1-
fpx,λq       λ  " class="math-display"  /></center>
for all values of λ except λ   0. When λ   0 we just take the natural logarithm (i.e.,
lnpxq).
<!--l. 867--><p class="indent" >   You can calculate it using the BOXCOX function in the ‘Compute’ variables screen in
jamovi.
</p>
   <h4 class="subsectionHead"><span class="titlemark">12.10.4   </span> <a 
 id="x114-27300012.10.4"></a>Checking for collinearity </h4>
<!--l. 872--><p class="noindent" >The last kind of regression diagnostic that I’m going to discuss in this chapter is the use of
<span id="textcolor356">variance inﬂation factors</span> (VIFs), which are useful for determining whether or not the predictors
in your regression model are too highly correlated with each other. There is a variance inﬂation
factor associated with each predictor X<sub>k</sub> in the model.
</p><!--l. 876--><p class="indent" >   The formula for the k-th VIF is:
                                                                                          

                                                                                          
</p>
   <center class="math-display" >
<img 
src="lsj291x.png" alt="VIF      ----1-----
    k   1    R2p  kq   " class="math-display"  /></center>
where R<sub>p kq</sub><sup>2</sup> refers to R-squared value you would get if you ran a regression using X<sub>
k</sub> as the
outcome variable, and all the other X variables as the predictors. The idea here is that R<sub>p kq</sub><sup>2</sup> is a
very good measure of the extent to which X<sub>k</sub> is correlated with all the other variables in the
model.
<!--l. 884--><p class="indent" >   The square root of the VIF is pretty interpretable. It tells you how much wider the conﬁdence
interval for the corresponding coeﬃcient b<sub>k</sub> is, relative to what you would have expected if
the predictors are all nice and uncorrelated with one another. If you’ve only got two
predictors, the VIF values are always going to be the same, as we can see if we click on
the ‘Collinearity’ checkbox in the ‘Regression’ - ‘Assumptions’ options in jamovi. For
both dan.sleep and baby.sleep the VIF is 1.65. And since the square root of 1.65 is
1.28, we see that the correlation between our two predictors isn’t causing much of a
problem.
</p><!--l. 886--><p class="indent" >   To give a sense of how we could end up with a model that has bigger collinearity problems,
suppose I were to run a much less interesting regression model, in which I tried to predict the day
on which the data were collected, as a function of all the other variables in the data set. To see why
this would be a bit of a problem, let’s have a look at the correlation matrix for all four
variables:
                                                                                          

                                                                                          
</p>
   <div class="verbatim" id="verbatim-42">
<span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> dan.sleep</span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> baby.sleep</span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> dan.grump</span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> day</span>
<span 
class="cmtt-12"> </span><br /><span 
class="cmtt-12">dan.sleep</span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> 1.00000000</span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> 0.62794934</span><span 
class="cmtt-12"> -0.90338404</span><span 
class="cmtt-12"> -0.09840768</span>
<span 
class="cmtt-12"> </span><br /><span 
class="cmtt-12">baby.sleep</span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> 0.62794934</span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> 1.00000000</span><span 
class="cmtt-12"> -0.56596373</span><span 
class="cmtt-12"> -0.01043394</span>
<span 
class="cmtt-12"> </span><br /><span 
class="cmtt-12">dan.grump</span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> -0.90338404</span><span 
class="cmtt-12"> -0.56596373</span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> 1.00000000</span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> 0.07647926</span>
<span 
class="cmtt-12"> </span><br /><span 
class="cmtt-12">day</span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> -0.09840768</span><span 
class="cmtt-12"> -0.01043394</span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> 0.07647926</span><span 
class="cmtt-12"> </span><span 
class="cmtt-12"> 1.00000000</span>
</div>
<!--l. 894--><p class="nopar" >
</p><!--l. 896--><p class="indent" >   We have some fairly large correlations between some of our predictor variables! When we run
the regression model and look at the VIF values, we see that the collinearity is causing a
lot of uncertainty about the coeﬃcients. First, run the regression, as in Figure <a 
href="#x114-27300123">12.23<!--tex4ht:ref: fig:reg7 --></a>
and you can see from the VIF values that, yep, that’s some mighty ﬁne collinearity
there.
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x114-27300123"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 899--><p class="noindent" >

</p><!--l. 900--><p class="noindent" ><img 
src="../img/regression/reg7.png" alt="PIC"  
 />
<br /> </p><div class="caption" 
><span class="id">Figure 12.23: </span><span  
class="content">Collinearity statistics for multiple regression, produced in jamovi </span></div><!--tex4ht:label?: x114-27300123 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
   <h3 class="sectionHead"><span class="titlemark">12.11   </span> <a 
 id="x114-27400012.11"></a>Model selection</h3>
<!--l. 910--><p class="noindent" >One fairly major problem that remains is the problem of “model selection”. That is, if we have a
data set that contains several variables, which ones should we include as predictors,
and which ones should we not include? In other words, we have a problem of <span id="textcolor357">variable
selection</span>. In general, model selection is a complex business but it’s made somewhat
simpler if we restrict ourselves to the problem of choosing a subset of the variables that
ought to be included in the model. Nevertheless, I’m not going to try covering even
this reduced topic in a lot of detail. Instead, I’ll talk about two broad principles that
you need to think about, and then discuss one concrete tool that jamovi provides to
help you select a subset of variables to include in your model. First, the two principles:
</p>
      <ul class="itemize1">
      <li class="itemize">It’s nice to have an actual substantive basis for your choices. That is, in a lot of situations
      you the researcher have good reasons to pick out a smallish number of possible regression
      models that are of theoretical interest. These models will have a sensible interpretation
      in the context of your ﬁeld. Never discount the importance of this. Statistics serves the
      scientiﬁc process, not the other way around.
      </li>
      <li class="itemize">To the extent that your choices rely on statistical inference, there is a trade oﬀ between
      simplicity and goodness of ﬁt. As you add more predictors to the model you make
      it more complex. Each predictor adds a new free parameter (i.e., a new regression
      coeﬃcient), and each new parameter increases the model’s capacity to “absorb” random
      variations. So the goodness of ﬁt (e.g., R<sup>2</sup>) continues to rise, sometimes trivially or
      by chance, as you add more predictors no matter what. If you want your model to be
      able to generalise well to new observations you need to avoid throwing in too many
      variables.</li></ul>
<!--l. 915--><p class="noindent" >This latter principle is often referred to as <span id="textcolor358">Ockham’s razor</span> and is often summarised in terms of the
following pithy saying: do not multiply entities beyond necessity. In this context, it means don’t
chuck in a bunch of largely irrelevant predictors just to boost your R<sup>2</sup>. Hmm. Yeah, the original
was better.
</p><!--l. 917--><p class="indent" >   In any case, what we need is an actual mathematical criterion that will implement the
qualitative principle behind Ockham’s razor in the context of selecting a regression model. As
it turns out there are several possibilities. The one that I’ll talk about is the <span id="textcolor359">Akaike
                                                                                          

                                                                                          
information criterion</span> (AIC;  Akaike 1974) simply because it’s available as an option in
jamovi.
</p><!--l. 921--><p class="indent" >   In the context of a linear regression model (and ignoring terms that don’t depend on the
model in any way!), the AIC for a model that has K predictor variables plus an intercept
is
</p>
   <center class="math-display" >
<img 
src="lsj292x.png" alt="       SSres
AIC     ---2-    2K
        ˆσ
" class="math-display"  /></center>
<!--l. 928--><p class="indent" >   The smaller the AIC value, the better the model performance. If we ignore the low level details
it’s fairly obvious what the AIC does. On the left we have a term that increases as the model
predictions get worse; on the right we have a term that increases as the model complexity increases.
The best model is the one that ﬁts the data well (low residuals, left hand side) using as few
predictors as possible (low K, right hand side). In short, this is a simple implementation of
Ockham’s razor.
</p><!--l. 930--><p class="indent" >   AIC can be added to the ‘Model Fit Measures’ output Table when the ‘AIC’ checkbox is
clicked, and a rather clunky way of assessing diﬀerent models is seeing if the ‘AIC’ value is lower
if you remove one or more of the predictors in the regression model. This is the only
way currently implemented in jamovi, but there are alternatives in other more powerful
programmes, such as R. These alternative methods can automate the process of selectively
removing (or adding) predictor variables to ﬁnd the best AIC. Although these methods are
not implemented in jamovi, I will mention them brieﬂy below just so you know about
them.
</p><!--l. 932--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">12.11.1   </span> <a 
 id="x114-27500012.11.1"></a>Backward elimination</h4>
<!--l. 934--><p class="noindent" >In backward elimination you start with the complete regression model, including all possible
predictors. Then, at each “step” we try all possible ways of removing one of the variables, and
                                                                                          

                                                                                          
whichever of these is best (in terms of lowest AIC value) is accepted. This becomes our new
regression model, and we then try all possible deletions from the new model, again choosing the
option with lowest AIC. This process continues until we end up with a model that has a lower AIC
value than any of the other possible models that you could produce by deleting one of its
predictors.
</p><!--l. 936--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">12.11.2   </span> <a 
 id="x114-27600012.11.2"></a>Forward selection</h4>
<!--l. 938--><p class="noindent" >As an alternative, you can also try <span id="textcolor360">forward selection</span>. This time around we start with the
smallest possible model as our start point, and only consider the possible additions to the model.
However, there’s one complication. You also need to specify what the largest possible model you’re
willing to entertain is.
</p><!--l. 940--><p class="indent" >   Although backward and forward selection can lead to the same conclusion, they don’t
always.
</p><!--l. 942--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">12.11.3   </span> <a 
 id="x114-27700012.11.3"></a>A caveat</h4>
<!--l. 944--><p class="noindent" >Automated variable selection methods are seductive things, especially when they’re bundled up in
(fairly) simple functions in powerful statistical programmes. They provide an element of objectivity
to your model selection, and that’s kind of nice. Unfortunately, they’re sometimes used as an excuse
for thoughtlessness. No longer do you have to think carefully about which predictors to add to the
model and what the theoretical basis for their inclusion might be. Everything is solved by the
magic of AIC. And if we start throwing around phrases like Ockham’s razor, well it
sounds like everything is wrapped up in a nice neat little package that no-one can argue
with.
</p><!--l. 946--><p class="indent" >   Or, perhaps not. Firstly, there’s very little agreement on what counts as an appropriate model
selection criterion. When I was taught backward elimination as an undergraduate, we used F-tests
to do it, because that was the default method used by the software. I’ve described using AIC, and
since this is an introductory text that’s the only method I’ve described, but the AIC is hardly the
Word of the Gods of Statistics. It’s an approximation, derived under certain assumptions,
and it’s guaranteed to work only for large samples when those assumptions are met.
Alter those assumptions and you get a diﬀerent criterion, like the BIC for instance (also
available in jamovi). Take a diﬀerent approach again and you get the NML criterion.
Decide that you’re a Bayesian and you get model selection based on posterior odds ratios.
                                                                                          

                                                                                          
Then there are a bunch of regression speciﬁc tools that I haven’t mentioned. And so on.
All of these diﬀerent methods have strengths and weaknesses, and some are easier to
calculate than others (AIC is probably the easiest of the lot, which might account for its
popularity). Almost all of them produce the same answers when the answer is “obvious”
but there’s a fair amount of disagreement when the model selection problem becomes
hard.
</p><!--l. 948--><p class="indent" >   What does this mean in practice? Well, you could go and spend several years teaching yourself
the theory of model selection, learning all the ins and outs of it so that you could ﬁnally
decide on what you personally think the right thing to do is. Speaking as someone who
actually did that, I wouldn’t recommend it. You’ll probably come out the other side even
more confused than when you started. A better strategy is to show a bit of common
sense. If you’re staring at the results of an automated backwards or forwards selection
procedure, and the model that makes sense is close to having the smallest AIC but is
narrowly defeated by a model that doesn’t make any sense, then trust your instincts.
Statistical model selection is an inexact tool, and as I said at the beginning, interpretability
matters.
</p><!--l. 950--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">12.11.4   </span> <a 
 id="x114-27800012.11.4"></a>Comparing two regression models</h4>
<!--l. 952--><p class="noindent" >An alternative to using automated model selection procedures is for the researcher to explicitly
select two or more regression models to compare to each other. You can do this in a few diﬀerent
ways, depending on what research question you’re trying to answer. Suppose we want to know
whether or not the amount of sleep that my son got has any relationship to my grumpiness,
over and above what we might expect from the amount of sleep that I got. We also
want to make sure that the day on which we took the measurement has no inﬂuence on
the relationship. That is, we’re interested in the relationship between baby.sleep and
dan.grump, and from that perspective dan.sleep and day are nuisance variable or <span id="textcolor361">covariates</span>
that we want to control for. In this situation, what we would like to know is whether
<span class="obeylines-h"><span class="verb">dan.grump ~ dan.sleep + day + baby.sleep</span></span> (which I’ll call Model 2, or M2) is a better
regression model for these data than <span class="obeylines-h"><span class="verb">dan.grump ~ dan.sleep + day</span></span> (which I’ll call Model 1, or
M1). There are two diﬀerent ways we can compare these two models, one based on a model selection
criterion like AIC, and the other based on an explicit hypothesis test. I’ll show you the AIC based
approach ﬁrst because it’s simpler, and follows naturally from discussion in the last section.
The ﬁrst thing I need to do is actually run the two regressions, note the AIC for each
one, and then select the model with the smaller AIC value as it is judged to be the
better model for these data. Actually, don’t do this just yet. Read on because there
                                                                                          

                                                                                          
is an easy way in jamovi to get the AIC values for diﬀerent models included in one
table.<span class="footnote-mark"><a 
href="lsj129.html#fn15x13"><sup class="textsuperscript">15</sup></a></span><a 
 id="x114-278001f15"></a> 
</p><!--l. 954--><p class="indent" >   A somewhat diﬀerent approach to the problem comes out of the hypothesis testing framework.
Suppose you have two regression models, where one of them (Model 1) contains a subset of the
predictors from the other one (Model 2). That is, Model 2 contains all of the predictors included in
Model 1, plus one or more additional predictors. When this happens we say that Model 1 is <span id="textcolor363">nested</span>
within Model 2, or possibly that Model 1 is a <span id="textcolor364">submodel</span> of Model 2. Regardless of the terminology,
what this means is that we can think of Model 1 as a null hypothesis and Model 2 as an alternative
hypothesis. And in fact we can construct an F test for this in a fairly straightforward
fashion.
</p><!--l. 958--><p class="indent" >   We can ﬁt both models to the data and obtain a residual sum of squares for both models. I’ll
denote these as SS<sub>res</sub><sup>p1q</sup> and SS<sub>
res</sub><sup>p2q</sup> respectively. The superscripting here just indicates which
model we’re talking about. Then our F statistic is
</p>
   <center class="math-display" >
<img 
src="lsj293x.png" alt="         p1q     p1q
F      pSSres---SS-resq{k---
     pSSpr2qesq{pN     p    1q  " class="math-display"  /></center>
where N is the number of observations, p is the number of predictors in the full model (not
including the intercept), and k is the diﬀerence in the number of parameters between the two
                                                                                          

                                                                                          
models.<span class="footnote-mark"><a 
href="lsj130.html#fn16x13"><sup class="textsuperscript">16</sup></a></span><a 
 id="x114-278002f16"></a> 
The degrees of freedom here are k and N   p   1. Note that it’s often more convenient to think
about the diﬀerence between those two SS values as a sum of squares in its own right. That
is
   <center class="math-display" >
<img 
src="lsj294x.png" alt="SS Δ    SSp1reqs    SSpr2eqs  " class="math-display"  /></center>
The reason why this is helpful is that we can express SS<sub>Δ</sub> as a measure of the extent
to which the two models make diﬀerent predictions about the the outcome variable.
Speciﬁcally,
   <center class="math-display" >
<img 
src="lsj295x.png" alt="                         2
SS Δ         ˆyp2iq    ˆyp1iq
        i   " class="math-display"  /></center>
where ŷ<sub>i</sub><sup>p1q</sup> is the ﬁtted value for y<sub>
i</sub> according to model M<sub>1</sub> and ŷ<sub>i</sub><sup>p2q</sup> is the ﬁtted value for y<sub>
i</sub>
according to model M<sub>2</sub>.
                                                                                          

                                                                                          
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x114-27800324"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 975--><p class="noindent" >

</p><!--l. 976--><p class="noindent" ><img 
src="../img/regression/reg8.png" alt="PIC"  
 />
<br /> </p><div class="caption" 
><span class="id">Figure 12.24: </span><span  
class="content">Model comparison in jamovi using the ‘Model Builder’ option</span></div><!--tex4ht:label?: x114-27800324 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 983--><p class="indent" >   Okay, so that’s the hypothesis test that we use to compare two regression models to one
another. Now, how do we do it in jamovi? The answer is to use the ‘Model Builder’
option and specify the Model 1 predictors dan.sleep and day in ‘Block 1’ and then add
the additional predictor from Model 2 (baby.sleep) in ‘Block 2’, as in Figure <a 
href="#x114-27800324">12.24<!--tex4ht:ref: fig:reg8 --></a>.
This shows, in the ‘Model Comparisons’ Table, that for the comparisons between Model
1 and Model 2, F(1,96) = 0.00, p = 0.954. Since we have p   .05 we retain the null
hypothesis (M1). This approach to regression, in which we add all of our covariates into a null
model, then add the variables of interest into an alternative model, and then compare
the two models in a hypothesis testing framework, is often referred to as <span id="textcolor366">hierarchical
regression</span>.
</p><!--l. 985--><p class="indent" >   We can also use this ‘Model Comparison’ option to display a table that shows the AIC and BIC
for each model, making it easy to compare and identify which model has the lowest value, as in
Figure <a 
href="#x114-27800324">12.24<!--tex4ht:ref: fig:reg8 --></a>.
</p>
   <h3 class="sectionHead"><span class="titlemark">12.12   </span> <a 
 id="x114-27900012.12"></a>Summary</h3>
      <ul class="itemize1">
      <li class="itemize">Want  to  know  how  strong  the  relationship  is  between  two  variables?  Calculate  a
      correlation (Section <a 
href="#x114-24100012.1">12.1<!--tex4ht:ref: sec:correl --></a>).
      </li>
      <li class="itemize">Drawing scatterplots (Section <a 
href="#x114-24800012.2">12.2<!--tex4ht:ref: sec:scatterplots --></a>).
      </li>
      <li class="itemize">Basic ideas in linear regression and how regression models are estimated (Sections <a 
href="#x114-25000012.3">12.3<!--tex4ht:ref: sec:introregression --></a>
      and <a 
href="#x114-25100012.4">12.4<!--tex4ht:ref: sec:regressionestimation --></a>).
      </li>
      <li class="itemize">Multiple linear regression (Section <a 
href="#x114-25400012.5">12.5<!--tex4ht:ref: sec:multipleregression --></a>).
      </li>
      <li class="itemize">Measuring the overall performance of a regression model using R<sup>2</sup> (Section <a 
href="#x114-25700012.6">12.6<!--tex4ht:ref: sec:r2 --></a>).
      </li>
      <li class="itemize">Hypothesis tests for regression models (Section <a 
href="#x114-26100012.7">12.7<!--tex4ht:ref: sec:regressiontests --></a>)
      </li>
      <li class="itemize">Calculating conﬁdence intervals for regression coeﬃcients and standardised coeﬃcients
      (Section <a 
href="#x114-26500012.8">12.8<!--tex4ht:ref: sec:regressioncoefs --></a>).
                                                                                          

                                                                                          
      </li>
      <li class="itemize">The assumptions of regression (Section <a 
href="#x114-26800012.9">12.9<!--tex4ht:ref: sec:regressionassumptions --></a>) and how to check them (Section <a 
href="#x114-26900012.10">12.10<!--tex4ht:ref: sec:regressiondiagnostics --></a>).
      </li>
      <li class="itemize">Selecting a regression model (Section <a 
href="#x114-27400012.11">12.11<!--tex4ht:ref: sec:modelselreg --></a>).</li></ul>
                                                                                          

                                                                                          
   <!--l. 6--><div class="crosslinks"><p class="noindent">[<a 
href="lsjch13.html" >next</a>] [<a 
href="lsjch11.html" >prev</a>] [<a 
href="lsjch11.html#taillsjch11.html" >prev-tail</a>] [<a 
href="lsjch12.html" >front</a>] [<a 
href="lsjpa5.html#lsjch12.html" >up</a>] </p></div>
<!--l. 6--><p class="indent" >   <a 
 id="taillsjch12.html"></a>  </p> 
</body></html> 
