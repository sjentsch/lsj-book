<?xml version="1.0" encoding=""utf-8"" ?> 
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" 
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">  
<!--http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd-->  
<html xmlns="http://www.w3.org/1999/xhtml"  
> 
<head><title>7 Introduction to probability</title> 
<meta http-equiv="Content-Type" content="text/html; charset="utf-8"" /> 
<meta name="generator" content="TeX4ht (http://www.tug.org/tex4ht/)" /> 
<meta name="originator" content="TeX4ht (http://www.tug.org/tex4ht/)" /> 
<!-- 2,html,xhtml,NoFonts,ext=htm,charset="utf-8" --> 
<meta name="src" content="lsj.tex" /> 
<link rel="stylesheet" type="text/css" href="lsj.css" /> 
</head><body 
>
   <!--l. 6--><div class="crosslinks"><p class="noindent">[<a 
href="lsjch8.html" >next</a>] [<a 
href="lsjli2.html" >prev</a>] [<a 
href="lsjli2.html#taillsjli2.html" >prev-tail</a>] [<a 
href="#taillsjch7.html">tail</a>] [<a 
href="lsjpa4.html#lsjch7.html" >up</a>] </p></div>
   <h2 class="chapterHead"><span class="titlemark">Chapter 7</span><br /><a 
 id="x53-1160007"></a>Introduction to probability</h2>
      <div class="quote">
      <!--l. 9--><p class="noindent" >[God] has aﬀorded us only the twilight …of Probability. <br 
class="newline" />                    – John Locke</p></div>
<!--l. 15--><p class="noindent" >Up to this point in the book we’ve discussed some of the key ideas in experimental design, and
we’ve talked a little about how you can summarise a data set. To a lot of people this is all there
is to statistics: collecting all the numbers, calculating averages, drawing pictures, and
putting them all in a report somewhere. Kind of like stamp collecting but with numbers.
However, statistics covers much more than that. In fact, descriptive statistics is one of the
smallest parts of statistics and one of the least powerful. The bigger and more useful
part of statistics is that it provides information that lets you make inferences about
data.
</p><!--l. 17--><p class="indent" >   Once you start thinking about statistics in these terms, that statistics is there to help us
draw inferences from data, you start seeing examples of it everywhere. For instance,
here’s a tiny extract from a newspaper article in the Sydney Morning Herald (30 Oct
2010):
      </p><div class="quote">
      <!--l. 20--><p class="noindent" >“I have a tough job,” the Premier said in response to a poll which found her
      government is now the most unpopular Labor administration in polling history,
      with a primary vote of just 23 per cent.</p></div>
<!--l. 23--><p class="indent" >   This kind of remark is entirely unremarkable in the papers or in everyday life, but let’s
have a think about what it entails. A polling company has conducted a survey, usually
a pretty big one because they can aﬀord it. I’m too lazy to track down the original
survey so let’s just imagine that they called 1000 New South Wales (NSW) voters at
random, and 230 (23%) of those claimed that they intended to vote for the Australian
Labor Party (ALP). For the 2010 Federal election the Australian Electoral Commission
reported 4,610,795 enrolled voters in NSW, so the opinions of the remaining 4,609,795
voters (about 99.98% of voters) remain unknown to us. Even assuming that no-one
lied to the polling company the only thing we can say with 100% conﬁdence is that
the true ALP primary vote is somewhere between 230/4610795 (about 0.005%) and
4610025/4610795 (about 99.83%). So, on what basis is it legitimate for the polling company, the
newspaper, and the readership to conclude that the ALP primary vote is only about
                                                                                          

                                                                                          
23%?
</p><!--l. 25--><p class="indent" >   The answer to the question is pretty obvious. If I call 1000 people at random, and 230 of them
say they intend to vote for the ALP, then it seems very unlikely that these are the only 230 people
out of the entire voting public who actually intend to vote ALP. In other words, we assume that the
data collected by the polling company is pretty representative of the population at large. But how
representative? Would we be surprised to discover that the true ALP primary vote is actually 24%?
29%? 37%? At this point everyday intuition starts to break down a bit. No-one would be surprised
by 24%, and everybody would be surprised by 37%, but it’s a bit hard to say whether 29% is
plausible. We need some more powerful tools than just looking at the numbers and
guessing.
</p><!--l. 27--><p class="indent" >   <span id="textcolor173">Inferential statistics</span> provides the tools that we need to answer these sorts of questions, and
since these kinds of questions lie at the heart of the scientiﬁc enterprise, they take up the lions
share of every introductory course on statistics and research methods. However, the theory of
statistical inference is built on top of <span id="textcolor174">probability theory</span>. And it is to probability theory that we
must now turn. This discussion of probability theory is basically background detail. There’s not a
lot of statistics per se in this chapter, and you don’t need to understand this material in
as much depth as the other chapters in this part of the book. Nevertheless, because
probability theory does underpin so much of statistics, it’s worth covering some of the
basics.
</p>
   <h3 class="sectionHead"><span class="titlemark">7.1   </span> <a 
 id="x53-1170007.1"></a>How are probability and statistics diﬀerent? </h3>
<!--l. 32--><p class="noindent" >Before we start talking about probability theory, it’s helpful to spend a moment thinking about the
relationship between probability and statistics. The two disciplines are closely related but they’re
not identical. Probability theory is “the doctrine of chances”. It’s a branch of mathematics that
tells you how often diﬀerent kinds of events will happen. For example, all of these questions are
things you can answer using probability theory:
</p>
      <ul class="itemize1">
      <li class="itemize">What are the chances of a fair coin coming up heads 10 times in a row?
      </li>
      <li class="itemize">If I roll a six sided dice twice, how likely is it that I’ll roll two sixes?
      </li>
      <li class="itemize">How likely is it that ﬁve cards drawn from a perfectly shuﬄed deck will all be hearts?
      </li>
      <li class="itemize">What are the chances that I’ll win the lottery?</li></ul>
                                                                                          

                                                                                          
<!--l. 42--><p class="indent" >   Notice that all of these questions have something in common. In each case the “truth of the
world” is known and my question relates to the “what kind of events” will happen. In the ﬁrst
question I know that the coin is fair so there’s a 50% chance that any individual coin ﬂip will come
up heads. In the second question I know that the chance of rolling a 6 on a single die
is 1 in 6. In the third question I know that the deck is shuﬄed properly. And in the
fourth question I know that the lottery follows speciﬁc rules. You get the idea. The
critical point is that probabilistic questions start with a known <span id="textcolor175">model</span> of the world,
and we use that model to do some calculations. The underlying model can be quite
simple. For instance, in the coin ﬂipping example we can write down the model like
this:
</p>
   <center class="math-display" >
<img 
src="lsj33x.png" alt="P pheadsq    0.5  " class="math-display"  /></center>
which you can read as “the probability of heads is 0.5”. As we’ll see later, in the same way that
percentages are numbers that range from 0% to 100%, probabilities are just numbers that range
from 0 to 1. When using this probability model to answer the ﬁrst question I don’t actually know
exactly what’s going to happen. Maybe I’ll get 10 heads, like the question says. But maybe I’ll get
three heads. That’s the key thing. In probability theory the model is known but the data are
not.
<!--l. 48--><p class="indent" >   So that’s probability. What about statistics? Statistical questions work the other way around. In
statistics we <span class="underline">do not</span> know the truth about the world. All we have is the data and it is from the data
that we want to learn the truth about the world. Statistical questions tend to look more like these:
</p>
      <ul class="itemize1">
      <li class="itemize">If my friend ﬂips a coin 10 times and gets 10 heads are they playing a trick on me?
      </li>
      <li class="itemize">If ﬁve cards oﬀ the top of the deck are all hearts how likely is it that the deck was
      shuﬄed?
      </li>
      <li class="itemize">If the lottery commissioner’s spouse wins the lottery how likely is it that the lottery
      was rigged?</li></ul>
                                                                                          

                                                                                          
<!--l. 56--><p class="indent" >   This time around the only thing we have are data. What I know is that I saw my friend ﬂip the
coin 10 times and it came up heads every time. And what I want to <span id="textcolor176">infer</span> is whether or not I
should conclude that what I just saw was actually a fair coin being ﬂipped 10 times in a row, or
whether I should suspect that my friend is playing a trick on me. The data I have look like
this:
                                                                                          

                                                                                          
</p>
   <div class="verbatim" id="verbatim-24">
<span 
class="cmtt-12">H</span><span 
class="cmtt-12"> H</span><span 
class="cmtt-12"> H</span><span 
class="cmtt-12"> H</span><span 
class="cmtt-12"> H</span><span 
class="cmtt-12"> H</span><span 
class="cmtt-12"> H</span><span 
class="cmtt-12"> H</span><span 
class="cmtt-12"> H</span><span 
class="cmtt-12"> H</span><span 
class="cmtt-12"> H</span>
</div>
<!--l. 59--><p class="nopar" >and what I’m trying to do is work out which “model of the world” I should put my trust in. If the
coin is fair then the model I should adopt is one that says that the probability of heads is 0.5, that
is Ppheadsq   0.5. If the coin is not fair then I should conclude that the probability of heads is not
0.5, which we would write as Ppheadsq   0.5. In other words, the statistical inference problem is to
ﬁgure out which of these probability models is right. Clearly, the statistical question isn’t the same
as the probability question, but they’re deeply connected to one another. Because of this, a good
introduction to statistical theory will start with a discussion of what probability is and how it
works.
</p><!--l. 63--><p class="noindent" >
</p>
   <h3 class="sectionHead"><span class="titlemark">7.2   </span> <a 
 id="x53-1180007.2"></a>What does probability mean?</h3>
<!--l. 65--><p class="noindent" >Let’s start with the ﬁrst of these questions. What is “probability”? It might seem surprising to you
but while statisticians and mathematicians (mostly) agree on what the rules of probability are,
there’s much less of a consensus on what the word really means. It seems weird because we’re all
very comfortable using words like “chance”, “likely”, “possible” and “probable”, and it doesn’t
seem like it should be a very diﬃcult question to answer. But if you’ve ever had that experience in
real life you might walk away from the conversation feeling like you didn’t quite get it right, and
that (like many everyday concepts) it turns out that you don’t really know what it’s all
about.
</p><!--l. 67--><p class="indent" >   So I’ll have a go at it. Let’s suppose I want to bet on a soccer game between two teams of
robots, Arduino Arsenal and C Milan. After thinking about it, I decide that there is an 80%
probability of Arduino Arsenal winning. What do I mean by that? Here are three possibilities:
</p>
      <ul class="itemize1">
      <li class="itemize">They’re robot teams so I can make them play over and over again, and if I did that
      Arduino Arsenal would win 8 out of every 10 games on average.
      </li>
      <li class="itemize">For any given game, I would agree that betting on this game is only “fair” if a $1 bet
      on C Milan gives a $5 payoﬀ (i.e. I get my $1 back plus a $4 reward for being correct),
      as would a $4 bet on Arduino Arsenal (i.e., my $4 bet plus a $1 reward).
                                                                                          

                                                                                          
      </li>
      <li class="itemize">My subjective “belief” or “conﬁdence” in an Arduino Arsenal victory is four times as
      strong as my belief in a C Milan victory.</li></ul>
<!--l. 73--><p class="noindent" >Each of these seems sensible. However, they’re not identical and not every statistician would endorse
all of them. The reason is that there are diﬀerent statistical ideologies (yes, really!) and depending
on which one you subscribe to, you might say that some of those statements are meaningless or
irrelevant. In this section I give a brief introduction the two main approaches that exist
in the literature. These are by no means the only approaches, but they’re the two big
ones.
</p><!--l. 75--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">7.2.1   </span> <a 
 id="x53-1190007.2.1"></a>The frequentist view</h4>
<!--l. 77--><p class="noindent" >The ﬁrst of the two major approaches to probability, and the more dominant one in statistics, is
referred to as the <span id="textcolor177">frequentist view</span> and it deﬁnes probability as a <span id="textcolor178">long-run frequency</span>. Suppose
we were to try ﬂipping a fair coin over and over again. By deﬁnition this is a coin that has
PpHq   0.5. What might we observe? One possibility is that the ﬁrst 20 ﬂips might look like
this:
                                                                                          

                                                                                          
</p>
   <div class="verbatim" id="verbatim-25">
<span 
class="cmtt-12">T,H,H,H,H,T,T,H,H,H,H,T,H,H,T,T,T,T,T,H</span>
</div>
<!--l. 80--><p class="nopar" >In this case 11 of these 20 coin ﬂips (55%) came up heads. Now suppose that I’d been keeping a
running tally of the number of heads (which I’ll call N<sub>H</sub>) that I’ve seen, across the ﬁrst N ﬂips, and
calculate the proportion of heads N<sub>H</sub>{N every time. Here’s what I’d get (I did literally ﬂip coins to
produce this!): </p>
<div class="center" 
>
<!--l. 82--><p class="noindent" >
</p>
<div class="tabular"> <table id="TBL-20" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-20-1g"><col 
id="TBL-20-1" /></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-20-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-20-1-1"  
class="td11"><!--tex4ht:inline--><div class="tabular"> <table id="TBL-21" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-21-1g"><col 
id="TBL-21-1" /><col 
id="TBL-21-2" /><col 
id="TBL-21-3" /><col 
id="TBL-21-4" /><col 
id="TBL-21-5" /><col 
id="TBL-21-6" /><col 
id="TBL-21-7" /><col 
id="TBL-21-8" /><col 
id="TBL-21-9" /><col 
id="TBL-21-10" /><col 
id="TBL-21-11" /><col 
id="TBL-21-12" /></colgroup><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-21-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-21-1-1"  
class="td11">number of ﬂips </td><td  style="white-space:nowrap; text-align:right;" id="TBL-21-1-2"  
class="td11"> 1</td><td  style="white-space:nowrap; text-align:right;" id="TBL-21-1-3"  
class="td11"> 2</td><td  style="white-space:nowrap; text-align:right;" id="TBL-21-1-4"  
class="td11"> 3</td><td  style="white-space:nowrap; text-align:right;" id="TBL-21-1-5"  
class="td11"> 4</td><td  style="white-space:nowrap; text-align:right;" id="TBL-21-1-6"  
class="td11"> 5</td><td  style="white-space:nowrap; text-align:right;" id="TBL-21-1-7"  
class="td11"> 6</td><td  style="white-space:nowrap; text-align:right;" id="TBL-21-1-8"  
class="td11"> 7</td><td  style="white-space:nowrap; text-align:right;" id="TBL-21-1-9"  
class="td11"> 8</td><td  style="white-space:nowrap; text-align:right;" id="TBL-21-1-10"  
class="td11"> 9</td><td  style="white-space:nowrap; text-align:right;" id="TBL-21-1-11"  
class="td11"> 10</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-21-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-21-2-1"  
class="td11">number of heads</td><td  style="white-space:nowrap; text-align:right;" id="TBL-21-2-2"  
class="td11"> 0</td><td  style="white-space:nowrap; text-align:right;" id="TBL-21-2-3"  
class="td11"> 1</td><td  style="white-space:nowrap; text-align:right;" id="TBL-21-2-4"  
class="td11"> 2</td><td  style="white-space:nowrap; text-align:right;" id="TBL-21-2-5"  
class="td11"> 3</td><td  style="white-space:nowrap; text-align:right;" id="TBL-21-2-6"  
class="td11"> 4</td><td  style="white-space:nowrap; text-align:right;" id="TBL-21-2-7"  
class="td11"> 4</td><td  style="white-space:nowrap; text-align:right;" id="TBL-21-2-8"  
class="td11"> 4</td><td  style="white-space:nowrap; text-align:right;" id="TBL-21-2-9"  
class="td11"> 5</td><td  style="white-space:nowrap; text-align:right;" id="TBL-21-2-10"  
class="td11"> 6</td><td  style="white-space:nowrap; text-align:right;" id="TBL-21-2-11"  
class="td11"> 7</td></tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-21-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-21-3-1"  
class="td11">proportion </td> <td  style="white-space:nowrap; text-align:right;" id="TBL-21-3-2"  
class="td11">.00</td> <td  style="white-space:nowrap; text-align:right;" id="TBL-21-3-3"  
class="td11">.50</td> <td  style="white-space:nowrap; text-align:right;" id="TBL-21-3-4"  
class="td11">.67</td> <td  style="white-space:nowrap; text-align:right;" id="TBL-21-3-5"  
class="td11">.75</td> <td  style="white-space:nowrap; text-align:right;" id="TBL-21-3-6"  
class="td11">.80</td> <td  style="white-space:nowrap; text-align:right;" id="TBL-21-3-7"  
class="td11">.67</td> <td  style="white-space:nowrap; text-align:right;" id="TBL-21-3-8"  
class="td11">.57</td> <td  style="white-space:nowrap; text-align:right;" id="TBL-21-3-9"  
class="td11">.63</td> <td  style="white-space:nowrap; text-align:right;" id="TBL-21-3-10"  
class="td11">.67</td> <td  style="white-space:nowrap; text-align:right;" id="TBL-21-3-11"  
class="td11">.70</td>
</tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-21-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-21-4-1"  
class="td11">              </td></tr></table>                                                             </div></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-20-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-20-2-1"  
class="td11">                                                                             </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-20-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-20-3-1"  
class="td11"><!--tex4ht:inline--><div class="tabular"> <table id="TBL-22" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-22-1g"><col 
id="TBL-22-1" /><col 
id="TBL-22-2" /><col 
id="TBL-22-3" /><col 
id="TBL-22-4" /><col 
id="TBL-22-5" /><col 
id="TBL-22-6" /><col 
id="TBL-22-7" /><col 
id="TBL-22-8" /><col 
id="TBL-22-9" /><col 
id="TBL-22-10" /><col 
id="TBL-22-11" /><col 
id="TBL-22-12" /></colgroup><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-22-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-22-1-1"  
class="td11">number of ﬂips </td><td  style="white-space:nowrap; text-align:right;" id="TBL-22-1-2"  
class="td11"> 11</td><td  style="white-space:nowrap; text-align:right;" id="TBL-22-1-3"  
class="td11"> 12</td><td  style="white-space:nowrap; text-align:right;" id="TBL-22-1-4"  
class="td11"> 13</td><td  style="white-space:nowrap; text-align:right;" id="TBL-22-1-5"  
class="td11"> 14</td><td  style="white-space:nowrap; text-align:right;" id="TBL-22-1-6"  
class="td11"> 15</td><td  style="white-space:nowrap; text-align:right;" id="TBL-22-1-7"  
class="td11"> 16</td><td  style="white-space:nowrap; text-align:right;" id="TBL-22-1-8"  
class="td11"> 17</td><td  style="white-space:nowrap; text-align:right;" id="TBL-22-1-9"  
class="td11"> 18</td><td  style="white-space:nowrap; text-align:right;" id="TBL-22-1-10"  
class="td11"> 19</td><td  style="white-space:nowrap; text-align:right;" id="TBL-22-1-11"  
class="td11"> 20</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-22-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-22-2-1"  
class="td11">number of heads</td><td  style="white-space:nowrap; text-align:right;" id="TBL-22-2-2"  
class="td11"> 8</td><td  style="white-space:nowrap; text-align:right;" id="TBL-22-2-3"  
class="td11"> 8</td><td  style="white-space:nowrap; text-align:right;" id="TBL-22-2-4"  
class="td11"> 9</td><td  style="white-space:nowrap; text-align:right;" id="TBL-22-2-5"  
class="td11"> 10</td><td  style="white-space:nowrap; text-align:right;" id="TBL-22-2-6"  
class="td11"> 10</td><td  style="white-space:nowrap; text-align:right;" id="TBL-22-2-7"  
class="td11"> 10</td><td  style="white-space:nowrap; text-align:right;" id="TBL-22-2-8"  
class="td11"> 10</td><td  style="white-space:nowrap; text-align:right;" id="TBL-22-2-9"  
class="td11"> 10</td><td  style="white-space:nowrap; text-align:right;" id="TBL-22-2-10"  
class="td11"> 10</td><td  style="white-space:nowrap; text-align:right;" id="TBL-22-2-11"  
class="td11"> 11</td></tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-22-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-22-3-1"  
class="td11">proportion </td> <td  style="white-space:nowrap; text-align:right;" id="TBL-22-3-2"  
class="td11">.73</td> <td  style="white-space:nowrap; text-align:right;" id="TBL-22-3-3"  
class="td11">.67</td> <td  style="white-space:nowrap; text-align:right;" id="TBL-22-3-4"  
class="td11">.69</td> <td  style="white-space:nowrap; text-align:right;" id="TBL-22-3-5"  
class="td11">.71</td> <td  style="white-space:nowrap; text-align:right;" id="TBL-22-3-6"  
class="td11">.67</td> <td  style="white-space:nowrap; text-align:right;" id="TBL-22-3-7"  
class="td11">.63</td> <td  style="white-space:nowrap; text-align:right;" id="TBL-22-3-8"  
class="td11">.59</td> <td  style="white-space:nowrap; text-align:right;" id="TBL-22-3-9"  
class="td11">.56</td> <td  style="white-space:nowrap; text-align:right;" id="TBL-22-3-10"  
class="td11">.53</td> <td  style="white-space:nowrap; text-align:right;" id="TBL-22-3-11"  
class="td11">.55</td>
</tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-22-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-22-4-1"  
class="td11">              </td></tr></table>                                                             </div></td>
</tr></table></div></div>
<!--l. 104--><p class="indent" >   Notice that at the start of the sequence the proportion of heads ﬂuctuates wildly, starting at .00
and rising as high as .80. Later on, one gets the impression that it dampens out a bit, with more
and more of the values actually being pretty close to the “right” answer of .50. This is the
frequentist deﬁnition of probability in a nutshell. Flip a fair coin over and over again, and as N
grows large (approaches inﬁnity, denoted N   8) the proportion of heads will converge to 50%.
There are some subtle technicalities that the mathematicians care about, but qualitatively
speaking that’s how the frequentists deﬁne probability. Unfortunately, I don’t have an
inﬁnite number of coins or the inﬁnite patience required to ﬂip a coin an inﬁnite number
of times. However, I do have a computer and computers excel at mindless repetitive
tasks. So I asked my computer to simulate ﬂipping a coin 1000 times and then drew a
picture of what happens to the proportion N<sub>H</sub>{N as N increases. Actually, I did it
four times just to make sure it wasn’t a ﬂuke. The results are shown in Figure <a 
href="#x53-1190011">7.1<!--tex4ht:ref: fig:frequentistprobability --></a>. As
you can see, the proportion of observed heads eventually stops ﬂuctuating and settles
down. When it does, the number at which it ﬁnally settles is the true probability of
heads.
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x53-1190011"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 107--><p class="noindent" >
</p><!--l. 108--><p class="noindent" ><img 
src="lsj34x.png" alt="PIC" class="graphics" width="398" height="410"  /><!--tex4ht:graphics  
name="lsj34x.png" src="../img/probability/frequentistProb.eps"  
-->
<br /> </p><div class="caption" 
><span class="id">Figure 7.1: </span><span  
class="content">An illustration of how frequentist probability works. If you ﬂip a fair coin over
and over again the proportion of heads that you’ve seen eventually settles down and converges
to the true probability of 0.5. Each panel shows four diﬀerent simulated experiments. In each
case we pretend we ﬂipped a coin 1000 times and kept track of the proportion of ﬂips that
were heads as we went along. Although none of these sequences actually ended up with an
exact value of .5, if we’d extended the experiment for an inﬁnite number of coin ﬂips they
would have.</span></div><!--tex4ht:label?: x53-1190011 -->
                                                                                          

                                                                                          
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 115--><p class="indent" >   The frequentist deﬁnition of probability has some desirable characteristics. First, it is objective.
The probability of an event is necessarily grounded in the world. The only way that probability
statements can make sense is if they refer to (a sequence of) events that occur in the physical
universe.<span class="footnote-mark"><a 
href="lsj54.html#fn1x8"><sup class="textsuperscript">1</sup></a></span><a 
 id="x53-119002f1"></a> 
Secondly, it is unambiguous. Any two people watching the same sequence of events unfold,
trying to calculate the probability of an event, must inevitably come up with the same
answer.
</p><!--l. 117--><p class="indent" >   However, it also has undesirable characteristics. First, inﬁnite sequences don’t exist in the
physical world. Suppose you picked up a coin from your pocket and started to ﬂip it. Every time it
lands it impacts on the ground. Each impact wears the coin down a bit. Eventually the coin will be
destroyed. So, one might ask whether it really makes sense to pretend that an “inﬁnite” sequence of
coin ﬂips is even a meaningful concept, or an objective one. We can’t say that an “inﬁnite
sequence” of events is a real thing in the physical universe, because the physical universe doesn’t
allow inﬁnite anything. More seriously, the frequentist deﬁnition has a narrow scope. There
are lots of things out there that human beings are happy to assign probability to in
everyday language, but cannot (even in theory) be mapped onto a hypothetical sequence of
events. For instance, if a meteorologist comes on TV and says “the probability of rain in
Adelaide on 2 November 2048 is 60%” we humans are happy to accept this. But it’s not
clear how to deﬁne this in frequentist terms. There’s only one city of Adelaide, and
only one 2 November 2048. There’s no inﬁnite sequence of events here, just a one-oﬀ
thing. Frequentist probability genuinely forbids us from making probability statements
about a single event. From the frequentist perspective it will either rain tomorrow or
it will not. There is no “probability” that attaches to a single non-repeatable event.
Now, it should be said that there are some very clever tricks that frequentists can use
to get around this. One possibility is that what the meteorologist means is something
like “There is a category of days for which I predict a 60% chance of rain, and if we
look only across those days for which I make this prediction, then on 60% of those days
it will actually rain”. It’s very weird and counterintuitive to think of it this way, but
you do see frequentists do this sometimes. And it will come up later in this book (see
Section <a 
href="lsjch8.html#x58-1450008.5">8.5<!--tex4ht:ref: sec:ci --></a>).
</p>
                                                                                          

                                                                                          
   <h4 class="subsectionHead"><span class="titlemark">7.2.2   </span> <a 
 id="x53-1200007.2.2"></a>The Bayesian view</h4>
<!--l. 121--><p class="noindent" >The <span id="textcolor180">Bayesian view</span> of probability is often called the subjectivist view, and although it has been a
minority view among statisticians it has been steadily gaining traction for the last several decades.
There are many ﬂavours of Bayesianism, making it hard to say exactly what “the” Bayesian
view is. The most common way of thinking about subjective probability is to deﬁne the
probability of an event as the <span id="textcolor181">degree of belief</span> that an intelligent and rational agent
assigns to that truth of that event. From that perspective, probabilities don’t exist in
the world but rather in the thoughts and assumptions of people and other intelligent
beings.
</p><!--l. 123--><p class="indent" >   However, in order for this approach to work we need some way of operationalising “degree of
belief”. One way that you can do this is to formalise it in terms of “rational gambling”, though
there are many other ways. Suppose that I believe that there’s a 60% probability of rain tomorrow.
If someone oﬀers me a bet that if it rains tomorrow then I win $5, but if it doesn’t rain I
lose $5. Clearly, from my perspective, this is a pretty good bet. On the other hand, if I
think that the probability of rain is only 40% then it’s a bad bet to take. So we can
operationalise the notion of a “subjective probability” in terms of what bets I’m willing to
accept.
</p><!--l. 125--><p class="indent" >   What are the advantages and disadvantages to the Bayesian approach? The main advantage is
that it allows you to assign probabilities to any event you want to. You don’t need to be limited to
those events that are repeatable. The main disadvantage (to many people) is that we can’t be
purely objective. Specifying a probability requires us to specify an entity that has the relevant
degree of belief. This entity might be a human, an alien, a robot, or even a statistician. But there
has to be an intelligent agent out there that believes in things. To many people this is
uncomfortable, it seems to make probability arbitrary. Whilst the Bayesian approach requires
that the agent in question be rational (i.e., obey the rules of probability), it does allow
everyone to have their own beliefs. I can believe the coin is fair and you don’t have to, even
though we’re both rational. The frequentist view doesn’t allow any two observers to
attribute diﬀerent probabilities to the same event. When that happens then at least one of
them must be wrong. The Bayesian view does not prevent this from occurring. Two
observers with diﬀerent background knowledge can legitimately hold diﬀerent beliefs
about the same event. In short, where the frequentist view is sometimes considered to
be too narrow (forbids lots of things that that we want to assign probabilities to), the
Bayesian view is sometimes thought to be too broad (allows too many diﬀerences between
observers).
</p><!--l. 127--><p class="noindent" >
</p>
                                                                                          

                                                                                          
   <h4 class="subsectionHead"><span class="titlemark">7.2.3   </span> <a 
 id="x53-1210007.2.3"></a>What’s the diﬀerence? And who is right?</h4>
<!--l. 129--><p class="noindent" >Now that you’ve seen each of these two views independently it’s useful to make sure you can
compare the two. Go back to the hypothetical robot soccer game at the start of the section. What
do you think a frequentist and a Bayesian would say about these three statements? Which
statement would a frequentist say is the correct deﬁnition of probability? Which one would a
Bayesian opt for? Would some of these statements be meaningless to a frequentist or a Bayesian? If
you’ve understood the two perspectives you should have some sense of how to answer those
questions.
</p><!--l. 131--><p class="indent" >   Okay, assuming you understand the diﬀerence then you might be wondering which of them is
right? Honestly, I don’t know that there is a right answer. As far as I can tell there’s nothing
mathematically incorrect about the way frequentists think about sequences of events, and there’s
nothing mathematically incorrect about the way that Bayesians deﬁne the beliefs of a rational
agent. In fact, when you dig down into the details Bayesians and frequentists actually
agree about a lot of things. Many frequentist methods lead to decisions that Bayesians
agree a rational agent would make. Many Bayesian methods have very good frequentist
properties.
</p><!--l. 133--><p class="indent" >   For the most part, I’m a pragmatist so I’ll use any statistical method that I trust. As it turns
out, that makes me prefer Bayesian methods for reasons I’ll explain towards the end of
the book. But I’m not fundamentally opposed to frequentist methods. Not everyone is
quite so relaxed. For instance, consider Sir Ronald Fisher, one of the towering ﬁgures of
20th century statistics and a vehement opponent to all things Bayesian, whose paper
on the mathematical foundations of statistics referred to Bayesian probability as “an
impenetrable jungle [that] arrests progress towards precision of statistical concepts”
(Fisher 1922b, p. 311). Or the psychologist Paul Meehl, who suggests that relying on
frequentist methods could turn you into “a potent but sterile intellectual rake who leaves
in his merry path a long train of ravished maidens but no viable scientiﬁc oﬀspring”
(Meehl 1967, p. 114). The history of statistics, as you might gather, is not devoid of
entertainment.
</p><!--l. 135--><p class="indent" >   In any case, whilst I personally prefer the Bayesian view, the majority of statistical
analyses are based on the frequentist approach. My reasoning is pragmatic. The goal of this
book is to cover roughly the same territory as a typical undergraduate stats class in
psychology, and if you want to understand the statistical tools used by most psychologists
you’ll need a good grasp of frequentist methods. I promise you that this isn’t wasted
eﬀort. Even if you end up wanting to switch to the Bayesian perspective, you really
should read through at least one book on the “orthodox” frequentist view. Besides, I
won’t completely ignore the Bayesian perspective. Every now and then I’ll add some
commentary from a Bayesian point of view, and I’ll revisit the topic in more depth in
Chapter <a 
href="lsjch16.html#x167-37000016">16<!--tex4ht:ref: ch:bayes --></a>.
                                                                                          

                                                                                          
</p><!--l. 138--><p class="noindent" >
</p>
   <h3 class="sectionHead"><span class="titlemark">7.3   </span> <a 
 id="x53-1220007.3"></a>Basic probability theory </h3>
<!--l. 140--><p class="noindent" >Ideological arguments between Bayesians and frequentists notwithstanding, it turns out that people
mostly agree on the rules that probabilities should obey. There are lots of diﬀerent ways of arriving
at these rules. The most commonly used approach is based on the work of Andrey Kolmogorov, one
of the great Soviet mathematicians of the 20th century. I won’t go into a lot of detail, but I’ll try to
give you a bit of a sense of how it works. And in order to do so I’m going to have to talk about my
trousers.
</p><!--l. 142--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">7.3.1   </span> <a 
 id="x53-1230007.3.1"></a>Introducing probability distributions</h4>
<!--l. 144--><p class="noindent" >One of the disturbing truths about my life is that I only own 5 pairs of trousers. Three pairs of
jeans, the bottom half of a suit, and a pair of tracksuit pants. Even sadder, I’ve given them names:
I call them X<sub>1</sub>, X<sub>2</sub>, X<sub>3</sub>, X<sub>4</sub> and X<sub>5</sub>. I really have, that’s why they call me Mister Imaginative.
Now, on any given day, I pick out exactly one of pair of trousers to wear. Not even I’m so
stupid as to try to wear two pairs of trousers, and thanks to years of training I never go
outside without wearing trousers anymore. If I were to describe this situation using the
language of probability theory, I would refer to each pair of trousers (i.e., each X) as an
<span id="textcolor182">elementary event</span>. The key characteristic of elementary events is that every time we
make an observation (e.g., every time I put on a pair of trousers) then the outcome will
be one and only one of these events. Like I said, these days I always wear exactly one
pair of trousers so my trousers satisfy this constraint. Similarly, the set of all possible
events is called a <span id="textcolor183">sample space</span>. Granted, some people would call it a “wardrobe”,
but that’s because they’re refusing to think about my trousers in probabilistic terms.
Sad.
</p><!--l. 146--><p class="indent" >   Okay, now that we have a sample space (a wardrobe), which is built from lots of possible
elementary events (trousers), what we want to do is assign a <span id="textcolor184">probability</span> of one of these
elementary events. For an event X, the probability of that event PpXq is a number that lies
between 0 and 1. The bigger the value of PpXq, the more likely the event is to occur. So, for
example, if PpXq   0 it means the event X is impossible (i.e., I never wear those trousers). On the
other hand, if PpXq   1 it means that event X is certain to occur (i.e., I always wear those
trousers). For probability values in the middle it means that I sometimes wear those
trousers. For instance, if PpXq   0.5 it means that I wear those trousers half of the
time.
</p><!--l. 148--><p class="indent" >   At this point, we’re almost done. The last thing we need to recognise is that “something always
                                                                                          

                                                                                          
happens”. Every time I put on trousers, I really do end up wearing trousers (crazy, right?). What
this somewhat trite statement means, in probabilistic terms, is that the probabilities of the
elementary events need to add up to 1. This is known as the <span id="textcolor185">law of total probability</span>, not that
any of us really care. More importantly, if these requirements are satisﬁed then what we have is a
<span id="textcolor186">probability distribution</span>. For example, this is an example of a probability distribution:
</p>
<div class="center" 
>
<!--l. 149--><p class="noindent" >
</p>
<div class="tabular"> <table id="TBL-23" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-23-1g"><col 
id="TBL-23-1" /><col 
id="TBL-23-2" /><col 
id="TBL-23-3" /></colgroup><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-23-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-23-1-1"  
class="td11">Which trousers?</td><td  style="white-space:nowrap; text-align:center;" id="TBL-23-1-2"  
class="td11">Label</td><td  style="white-space:nowrap; text-align:left;" id="TBL-23-1-3"  
class="td11">Probability</td>
</tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-23-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-23-2-1"  
class="td11">Blue jeans         </td><td  style="white-space:nowrap; text-align:center;" id="TBL-23-2-2"  
class="td11"> X<sub>1</sub>  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-23-2-3"  
class="td11">PpX<sub>1</sub>q   .5</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-23-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-23-3-1"  
class="td11">Grey jeans        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-23-3-2"  
class="td11"> X<sub>2</sub>  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-23-3-3"  
class="td11">PpX<sub>2</sub>q   .3</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-23-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-23-4-1"  
class="td11">Black jeans       </td><td  style="white-space:nowrap; text-align:center;" id="TBL-23-4-2"  
class="td11"> X<sub>3</sub>  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-23-4-3"  
class="td11">PpX<sub>3</sub>q   .1</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-23-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-23-5-1"  
class="td11">Black suit         </td><td  style="white-space:nowrap; text-align:center;" id="TBL-23-5-2"  
class="td11"> X<sub>4</sub>  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-23-5-3"  
class="td11">PpX<sub>4</sub>q   0 </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-23-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-23-6-1"  
class="td11">Blue tracksuit    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-23-6-2"  
class="td11"> X<sub>5</sub>  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-23-6-3"  
class="td11">PpX<sub>5</sub>q   .1</td>
</tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-23-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-23-7-1"  
class="td11">              </td></tr></table></div></div>
<!--l. 162--><p class="noindent" >Each of the events has a probability that lies between 0 and 1, and if we add up the probability of all
events they sum to 1. Awesome. We can even draw a nice bar graph (see Section <a 
href="lsjch5.html#x37-930005.3">5.3<!--tex4ht:ref: sec:bargraph --></a>) to visualise
this distribution, as shown in Figure <a 
href="#x53-1230012">7.2<!--tex4ht:ref: fig:pantsprob --></a>. And, at this point, we’ve all achieved something. You’ve
learned what a probability distribution is, and I’ve ﬁnally managed to ﬁnd a way to create a graph
that focuses entirely on my trousers. Everyone wins!
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x53-1230012"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 165--><p class="noindent" >
</p><!--l. 166--><p class="noindent" ><img 
src="lsj35x.png" alt="PIC" class="graphics" width="341" height="263"  /><!--tex4ht:graphics  
name="lsj35x.png" src="../img/probability/pantsDistribution.eps"  
-->
<br /> </p><div class="caption" 
><span class="id">Figure 7.2: </span><span  
class="content">A visual depiction of the “trousers” probability distribution. There are ﬁve
“elementary events”, corresponding to the ﬁve pairs of trousers that I own. Each event has
some probability of occurring: this probability is a number between 0 to 1. The sum of these
probabilities is 1.</span></div><!--tex4ht:label?: x53-1230012 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 173--><p class="indent" >   The only other thing that I need to point out is that probability theory allows you to talk about
<span id="textcolor187">non elementary events</span> as well as elementary ones. The easiest way to illustrate the
concept is with an example. In the trousers example it’s perfectly legitimate to refer to the
probability that I wear jeans. In this scenario, the “Dan wears jeans” event is said to
have happened as long as the elementary event that actually did occur is one of the
appropriate ones. In this case “blue jeans”, “black jeans” or “grey jeans”. In mathematical
terms we deﬁned the “jeans” event E to correspond to the set of elementary events
pX<sub>1</sub>,X<sub>2</sub>,X<sub>3</sub>q. If any of these elementary events occurs then E is also said to have occurred.
Having decided to write down the deﬁnition of the E this way, it’s pretty straightforward
to state what the probability PpEq is: we just add everything up. In this particular
case
</p>
   <center class="math-display" >
<img 
src="lsj36x.png" alt="PpEq     P pX1q     P pX2q     P pX3q  " class="math-display"  /></center> and,
since the probabilities of blue, grey and black jeans respectively are .5, .3 and .1, the probability
that I wear jeans is equal to .9.
<!--l. 179--><p class="indent" >   At this point you might be thinking that this is all terribly obvious and simple and
you’d be right. All we’ve really done is wrap some basic mathematics around a few
common sense intuitions. However, from these simple beginnings it’s possible to construct
some extremely powerful mathematical tools. I’m deﬁnitely not going to go into the
details in this book, but what I will do is list, in Table <a 
href="#x53-1230021">7.1<!--tex4ht:ref: tab:probrules --></a>, some of the other rules that
probabilities satisfy. These rules can be derived from the simple assumptions that I’ve outlined
above, but since we don’t actually use these rules for anything in this book I won’t do so
here.
</p>
   <div class="table">
                                                                                          

                                                                                          
<!--l. 182--><p class="indent" >   <a 
 id="x53-1230021"></a></p><hr class="float" /><div class="float" 
>
                                                                                          

                                                                                          
 <div class="caption" 
><span class="id">Table 7.1: </span><span  
class="content">Some basic rules that probabilities must satisfy. You don’t really need to know
these rules in order to understand the analyses that we’ll talk about later in the book, but
they are important if you want to understand probability theory a bit more deeply.</span></div><!--tex4ht:label?: x53-1230021 -->
<div class="center" 
>
<!--l. 184--><p class="noindent" >
</p>
<div class="tabular"> <table id="TBL-24" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-24-1g"><col 
id="TBL-24-1" /><col 
id="TBL-24-2" /><col 
id="TBL-24-3" /><col 
id="TBL-24-4" /></colgroup><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-24-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-1-1"  
class="td11">English </td><td  style="white-space:nowrap; text-align:right;" id="TBL-24-1-2"  
class="td11"> Notation</td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-1-3"  
class="td11"> </td><td  style="white-space:nowrap; text-align:left;" id="TBL-24-1-4"  
class="td11">Formula                        </td>
</tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-24-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-2-1"  
class="td11">not A   </td><td  style="white-space:nowrap; text-align:right;" id="TBL-24-2-2"  
class="td11">  Pp Aq</td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-2-3"  
class="td11"> </td><td  style="white-space:nowrap; text-align:left;" id="TBL-24-2-4"  
class="td11">1   PpAq                      </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-3-1"  
class="td11">A or B  </td><td  style="white-space:nowrap; text-align:right;" id="TBL-24-3-2"  
class="td11">PpA Y Bq</td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-3-3"  
class="td11"> </td><td  style="white-space:nowrap; text-align:left;" id="TBL-24-3-4"  
class="td11">PpAq   PpBq   PpA X Bq</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-24-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-4-1"  
class="td11">A and B</td><td  style="white-space:nowrap; text-align:right;" id="TBL-24-4-2"  
class="td11">PpA X Bq</td><td  style="white-space:nowrap; text-align:center;" id="TBL-24-4-3"  
class="td11"> </td><td  style="white-space:nowrap; text-align:left;" id="TBL-24-4-4"  
class="td11">PpA|BqPpBq                 </td>
</tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-24-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-24-5-1"  
class="td11">       </td></tr></table></div></div>
                                                                                          

                                                                                          
   </div><hr class="endfloat" />
   </div>
   <h3 class="sectionHead"><span class="titlemark">7.4   </span> <a 
 id="x53-1240007.4"></a>The binomial distribution</h3>
<!--l. 378--><p class="noindent" >As you might imagine, probability distributions vary enormously and there’s an enormous range of
distributions out there. However, they aren’t all equally important. In fact, the vast majority of the
content in this book relies on one of ﬁve distributions: the binomial distribution, the normal
distribution, the t distribution, the χ<sup>2</sup> (“chi-square”) distribution and the F distribution. Given
this, what I’ll do over the next few sections is provide a brief introduction to all ﬁve of these,
paying special attention to the binomial and the normal. I’ll start with the binomial distribution
since it’s the simplest of the ﬁve.
</p><!--l. 380--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">7.4.1   </span> <a 
 id="x53-1250007.4.1"></a>Introducing the binomial</h4>
<!--l. 382--><p class="noindent" >The theory of probability originated in the attempt to describe how games of chance work, so it
seems ﬁtting that our discussion of the <span id="textcolor188">binomial distribution</span> should involve a discussion of
rolling dice and ﬂipping coins. Let’s imagine a simple “experiment”. In my hot little hand I’m
holding 20 identical six-sided dice. On one face of each die there’s a picture of a skull, the other ﬁve
faces are all blank. If I proceed to roll all 20 dice, what’s the probability that I’ll get exactly 4
skulls? Assuming that the dice are fair, we know that the chance of any one die coming up skulls is
1 in 6. To say this another way, the skull probability for a single die is approximately
.167. This is enough information to answer our question, so let’s have a look at how it’s
done.
</p>
   <div class="table">
                                                                                          

                                                                                          
<!--l. 385--><p class="indent" >   <a 
 id="x53-1250012"></a></p><hr class="float" /><div class="float" 
>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 386--><p class="noindent" >
<br /> </p><div class="caption" 
><span class="id">Table 7.2: </span><span  
class="content">Formulas for the binomial and normal distributions. We don’t really use these
formulas for anything in this book, but they’re pretty important for more advanced work,
so I thought it might be best to put them here in a table, where they can’t get in the way
of the text. In the equation for the binomial, X! is the factorial function (i.e., multiply all
whole numbers from 1 to X), and for the normal distribution “exp” refers to the exponential
function, which we discussed in Chapter <a 
href="lsjch6.html#x40-960006">6<!--tex4ht:ref: ch:datahandling --></a>. If these equations don’t make a lot of sense to
you, don’t worry too much about them. </span></div><!--tex4ht:label?: x53-1250012 -->
<div class="tabular"> <table id="TBL-25" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-25-1g"><col 
id="TBL-25-1" /><col 
id="TBL-25-2" /><col 
id="TBL-25-3" /></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-25-1-"><td  style="white-space:nowrap; text-align:center;" id="TBL-25-1-1"  
class="td11">              <span class="underline">Binomial</span>                      </td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-1-2"  
class="td11">     </td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-1-3"  
class="td11">              <span class="underline">Normal</span>                      </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-2-"><td  style="white-space:nowrap; text-align:center;" id="TBL-25-2-1"  
class="td11">PpX | 𝜃,Nq   <img 
src="lsj37x.png" alt="----N-!-----
X!pN     Xq!"  class="frac" align="middle" />𝜃<sup>X</sup>p1   𝜃q<sup>N X</sup></td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-2-2"  
class="td11">   </td><td  style="white-space:nowrap; text-align:center;" id="TBL-25-2-3"  
class="td11">ppX | μ,σq   <img 
src="lsj38x.png" alt="?-1---
  2πσ"  class="frac" align="middle" /> exp <img 
src="lsj39x.png" alt="        2
pX-----μq-
  2σ2"  class="left" align="middle" /></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-25-3-"><td  style="white-space:nowrap; text-align:center;" id="TBL-25-3-1"  
class="td11">                                    </td></tr></table></div></div>
                                                                                          

                                                                                          
   </div><hr class="endfloat" />
   </div>
<!--l. 399--><p class="indent" >   As usual, we’ll want to introduce some names and some notation. We’ll let N denote the
number of dice rolls in our experiment, which is often referred to as the <span id="textcolor189">size parameter</span> of
our binomial distribution. We’ll also use 𝜃 to refer to the the probability that a single
die comes up skulls, a quantity that is usually called the <span id="textcolor190">success probability</span> of the
binomial.<span class="footnote-mark"><a 
href="lsj55.html#fn2x8"><sup class="textsuperscript">2</sup></a></span><a 
 id="x53-125002f2"></a> 
Finally, we’ll use X to refer to the results of our experiment, namely the number of
skulls I get when I roll the dice. Since the actual value of X is due to chance we refer
to it as a <span id="textcolor192">random variable</span>. In any case, now that we have all this terminology and
notation we can use it to state the problem a little more precisely. The quantity that we
want to calculate is the probability that X   4 given that we know that 𝜃   .167 and
N   20. The general “form” of the thing I’m interested in calculating could be written
as
</p>
   <center class="math-display" >
<img 
src="lsj40x.png" alt="P pX | 𝜃,N q  " class="math-display"  /></center> and
we’re interested in the special case where X   4, 𝜃   .167 and N   20. There’s only one more piece
of notation I want to refer to before moving on to discuss the solution to the problem. If I want to
say that X is generated randomly from a binomial distribution with parameters 𝜃 and N, the
notation I would use is as follows:
                                                                                          

                                                                                          
   <center class="math-display" >
<img 
src="lsj41x.png" alt="X     Binomialp 𝜃,N q  " class="math-display"  /></center>
Yeah, yeah. I know what you’re thinking: notation, notation, notation. Really, who cares? Very few
readers of this book are here for the notation, so I should probably move on and talk about how to
use the binomial distribution. I’ve included the formula for the binomial distribution in Table <a 
href="#x53-1250012">7.2<!--tex4ht:ref: tab:distformulas --></a>,
since some readers may want to play with it themselves, but since most people probably don’t care
that much and because we don’t need the formula in this book, I won’t talk about it
in any detail. Instead, I just want to show you what the binomial distribution looks
like.
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x53-1250033"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 411--><p class="noindent" >
</p><!--l. 412--><p class="noindent" ><img 
src="lsj42x.png" alt="PIC" class="graphics" width="341" height="263"  /><!--tex4ht:graphics  
name="lsj42x.png" src="../img/probability/binomSkulls20.eps"  
-->
<br /> </p><div class="caption" 
><span class="id">Figure 7.3: </span><span  
class="content">The binomial distribution with size parameter of N   20 and an underlying
success probability of 𝜃    1{6. Each vertical bar depicts the probability of one speciﬁc
outcome (i.e., one possible value of X). Because this is a probability distribution, each of the
probabilities must be a number between 0 and 1, and the heights of the bars must sum to 1
as well.</span></div><!--tex4ht:label?: x53-1250033 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 419--><p class="indent" >   To that end, Figure <a 
href="#x53-1250033">7.3<!--tex4ht:ref: fig:binomial1 --></a> plots the binomial probabilities for all possible values of X for our dice
rolling experiment, from X   0 (no skulls) all the way up to X   20 (all skulls). Note that this is
basically a bar chart, and is no diﬀerent to the “trousers probability” plot I drew in Figure <a 
href="#x53-1230012">7.2<!--tex4ht:ref: fig:pantsprob --></a>.
On the horizontal axis we have all the possible events, and on the vertical axis we can
read oﬀ the probability of each of those events. So, the probability of rolling 4 skulls
out of 20 is about 0.20 (the actual answer is 0.2022036, as we’ll see in a moment). In
other words, you’d expect that to happen about 20% of the times you repeated this
experiment.
</p><!--l. 426--><p class="indent" >   To give you a feel for how the binomial distribution changes when we alter the values of 𝜃 and
N, let’s suppose that instead of rolling dice I’m actually ﬂipping coins. This time around, my
experiment involves ﬂipping a fair coin repeatedly and the outcome that I’m interested in is the
number of heads that I observe. In this scenario, the success probability is now 𝜃   1{2. Suppose I
were to ﬂip the coin N   20 times. In this example, I’ve changed the success probability but kept
the size of the experiment the same. What does this do to our binomial distribution? Well, as
Figure <a 
href="#x53-1250044">7.4<!--tex4ht:ref: fig:binomial2 --></a>a shows, the main eﬀect of this is to shift the whole distribution, as you’d expect. Okay,
what if we ﬂipped a coin N   100 times? Well, in that case we get Figure <a 
href="#x53-1250044">7.4<!--tex4ht:ref: fig:binomial2 --></a>b. The
distribution stays roughly in the middle but there’s a bit more variability in the possible
outcomes.
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x53-1250044"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 429--><p class="noindent" >
</p>
                                                                                          

                                                                                          
<div class="tabular"> <table id="TBL-26" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-26-1g"><col 
id="TBL-26-1" /><col 
id="TBL-26-2" /></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-26-1-"><td  style="white-space:nowrap; text-align:center;" id="TBL-26-1-1"  
class="td11">(a)
    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-1-2"  
class="td11"><img 
src="lsj43x.png" alt="PIC" class="graphics" width="341" height="263"  /><!--tex4ht:graphics  
name="lsj43x.png" src="../img/probability/binomHeads20.eps"  
--></td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-26-2-"><td  style="white-space:nowrap; text-align:center;" id="TBL-26-2-1"  
class="td11">(b)
     </td><td  style="white-space:nowrap; text-align:center;" id="TBL-26-2-2"  
class="td11"><img 
src="lsj44x.png" alt="PIC" class="graphics" width="341" height="263"  /><!--tex4ht:graphics  
name="lsj44x.png" src="../img/probability/binomHeads100.eps"  
--></td></tr></table></div>
<br /> <div class="caption" 
><span class="id">Figure 7.4: </span><span  
class="content">Two binomial distributions, involving a scenario in which I’m ﬂipping a fair coin,
so the underlying success probability is 𝜃   1{2. In panel (a), we assume I’m ﬂipping the
                                                                                          

                                                                                          
coin N   20 times. In panel (b) we assume that the coin is ﬂipped N   100 times.</span></div><!--tex4ht:label?: x53-1250044 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
   <h3 class="sectionHead"><span class="titlemark">7.5   </span> <a 
 id="x53-1260007.5"></a>The normal distribution</h3>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x53-1260015"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 444--><p class="noindent" >
</p><!--l. 445--><p class="noindent" ><img 
src="lsj45x.png" alt="PIC" class="graphics" width="341" height="263"  /><!--tex4ht:graphics  
name="lsj45x.png" src="../img/probability/standardNormal.eps"  
-->
<br /> </p><div class="caption" 
><span class="id">Figure 7.5: </span><span  
class="content">The normal distribution with mean μ   0 and standard deviation σ   1. The
x-axis corresponds to the value of some variable, and the y-axis tells us something about how
likely we are to observe that value. However, notice that the y-axis is labelled “Probability
Density” and not “Probability”. There is a subtle and somewhat frustrating characteristic
of continuous distributions that makes the y axis behave a bit oddly: the height of the curve
here isn’t actually the probability of observing a particular x value. On the other hand, it is
true that the heights of the curve tells you which x values are more likely (the higher ones!).
(see Section <a 
href="#x53-1270007.5.1">7.5.1<!--tex4ht:ref: sec:density --></a> for all the annoying details)</span></div><!--tex4ht:label?: x53-1260015 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 452--><p class="indent" >   While the binomial distribution is conceptually the simplest distribution to understand, it’s not
the most important one. That particular honour goes to the <span id="textcolor193">normal distribution</span>, also referred to
as “the bell curve” or a “Gaussian distribution”. A normal distribution is described using two
parameters: the mean of the distribution μ and the standard deviation of the distribution
σ.
</p><!--l. 454--><p class="indent" >   The notation that we sometimes use to say that a variable X is normally distributed is as
follows:
</p>
   <center class="math-display" >
<img 
src="lsj46x.png" alt="X     Normalp μ,σq
" class="math-display"  /></center>
<!--l. 459--><p class="indent" >   Of course, that’s just notation. It doesn’t tell us anything interesting about the normal
distribution itself. As was the case with the binomial distribution, I have included the formula for
the normal distribution in this book, because I think it’s important enough that everyone who
learns statistics should at least look at it, but since this is an introductory text I don’t want to
focus on it, so I’ve tucked it away in Table <a 
href="#x53-1250012">7.2<!--tex4ht:ref: tab:distformulas --></a>.
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x53-1260026"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 462--><p class="noindent" >
</p><!--l. 463--><p class="noindent" ><img 
src="lsj47x.png" alt="PIC" class="graphics" width="341" height="263"  /><!--tex4ht:graphics  
name="lsj47x.png" src="../img/probability/meanShiftNormal.eps"  
-->
<br /> </p><div class="caption" 
><span class="id">Figure 7.6:  </span><span  
class="content">An  illustration  of  what  happens  when  you  change  the  mean  of  a  normal
distribution. The solid line depicts a normal distribution with a mean of μ   4. The dashed
line shows a normal distribution with a mean of μ   7. In both cases, the standard deviation
is σ   1. Not surprisingly, the two distributions have the same shape, but the dashed line is
shifted to the right.</span></div><!--tex4ht:label?: x53-1260026 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x53-1260037"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 471--><p class="noindent" >
</p><!--l. 472--><p class="noindent" ><img 
src="lsj48x.png" alt="PIC" class="graphics" width="341" height="263"  /><!--tex4ht:graphics  
name="lsj48x.png" src="../img/probability/scaleShiftNormal.eps"  
-->
<br /> </p><div class="caption" 
><span class="id">Figure 7.7: </span><span  
class="content">An illustration of what happens when you change the the standard deviation
of a normal distribution. Both distributions plotted in this ﬁgure have a mean of μ   5,
but they have diﬀerent standard deviations. The solid line plots a distribution with standard
deviation σ   1, and the dashed line shows a distribution with standard deviation σ   2.
As a consequence, both distributions are “centred” on the same spot, but the dashed line is
wider than the solid one.</span></div><!--tex4ht:label?: x53-1260037 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 479--><p class="indent" >   Instead of focusing on the maths, let’s try to get a sense for what it means for a variable to be
normally distributed. To that end, have a look at Figure <a 
href="#x53-1260015">7.5<!--tex4ht:ref: fig:normdist --></a> which plots a normal distribution with
mean μ   0 and standard deviation σ   1. You can see where the name “bell curve” comes from; it
looks a bit like a bell. Notice that, unlike the plots that I drew to illustrate the binomial
distribution, the picture of the normal distribution in Figure <a 
href="#x53-1260015">7.5<!--tex4ht:ref: fig:normdist --></a> shows a smooth curve
instead of “histogram-like” bars. This isn’t an arbitrary choice, the normal distribution is
continuous whereas the binomial is discrete. For instance, in the die rolling example from the
last section it was possible to get 3 skulls or 4 skulls, but impossible to get 3.9 skulls.
The ﬁgures that I drew in the previous section reﬂected this fact. In Figure <a 
href="#x53-1250033">7.3<!--tex4ht:ref: fig:binomial1 --></a>, for
instance, there’s a bar located at X   3 and another one at X   4 but there’s nothing
in between. Continuous quantities don’t have this constraint. For instance, suppose
we’re talking about the weather. The temperature on a pleasant Spring day could be 23
degrees, 24 degrees, 23.9 degrees, or anything in between since temperature is a continuous
variable. And so a normal distribution might be quite appropriate for describing Spring
temperatures.<span class="footnote-mark"><a 
href="lsj56.html#fn3x8"><sup class="textsuperscript">3</sup></a></span><a 
 id="x53-126004f3"></a> 
</p><!--l. 481--><p class="indent" >   With this in mind, let’s see if we can’t get an intuition for how the normal distribution works.
First, let’s have a look at what happens when we play around with the parameters of the
distribution. To that end, Figure <a 
href="#x53-1260026">7.6<!--tex4ht:ref: fig:normmean --></a> plots normal distributions that have diﬀerent means but have
the same standard deviation. As you might expect, all of these distributions have the same
“width”. The only diﬀerence between them is that they’ve been shifted to the left or to the right.
In every other respect they’re identical. In contrast, if we increase the standard deviation while
keeping the mean constant, the peak of the distribution stays in the same place but the distribution
gets wider, as you can see in Figure <a 
href="#x53-1260037">7.7<!--tex4ht:ref: fig:normsd --></a>. Notice, though, that when we widen the distribution the
height of the peak shrinks. This has to happen, in the same way that the heights of the bars that
we used to draw a discrete binomial distribution have to sum to 1, the total area under the curve
for the normal distribution must equal 1. Before moving on, I want to point out one
important characteristic of the normal distribution. Irrespective of what the actual mean and
standard deviation are, 68.3% of the area falls within 1 standard deviation of the mean.
Similarly, 95.4% of the distribution falls within 2 standard deviations of the mean, and
99.7% of the distribution is within 3 standard deviations. This idea is illustrated in
Figure <a 
href="#x53-1260058">7.8<!--tex4ht:ref: fig:sdnorm --></a>.
</p><!--l. 483--><p class="noindent" ></p><hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x53-1260058"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 485--><p class="noindent" >
</p>
<div class="tabular">
 <table id="TBL-27" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-27-1g"><col 
id="TBL-27-1" /><col 
id="TBL-27-2" /></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-27-1-"><td  style="white-space:nowrap; text-align:center;" id="TBL-27-1-1"  
class="td11"><img 
src="lsj49x.png" alt="PIC" class="graphics" width="199" height="132"  /><!--tex4ht:graphics  
name="lsj49x.png" src="../img/probability/normArea1SD.eps"  
--></td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-1-2"  
class="td11"><img 
src="lsj50x.png" alt="PIC" class="graphics" width="199" height="132"  /><!--tex4ht:graphics  
name="lsj50x.png" src="../img/probability/normArea2SD.eps"  
--></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-27-2-"><td  style="white-space:nowrap; text-align:center;" id="TBL-27-2-1"  
class="td11"> (a) </td><td  style="white-space:nowrap; text-align:center;" id="TBL-27-2-2"  
class="td11"> (b)</td>
</tr></table></div>
<br /> <div class="caption" 
><span class="id">Figure 7.8: </span><span  
class="content">The area under the curve tells you the probability that an observation falls within
a particular range. The solid lines plot normal distributions with mean μ   0 and standard
deviation σ   1. The shaded areas illustrate “areas under the curve” for two important cases.
In panel a, we can see that there is a 68.3% chance that an observation will fall within one
standard deviation of the mean. In panel b, we see that there is a 95.4% chance that an
observation will fall within two standard deviations of the mean.</span></div><!--tex4ht:label?: x53-1260058 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 496--><p class="noindent" ></p><hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x53-1260069"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 498--><p class="noindent" >
</p>
<div class="tabular">
 <table id="TBL-28" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-28-1g"><col 
id="TBL-28-1" /><col 
id="TBL-28-2" /></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-28-1-"><td  style="white-space:nowrap; text-align:center;" id="TBL-28-1-1"  
class="td11"><img 
src="lsj51x.png" alt="PIC" class="graphics" width="199" height="132"  /><!--tex4ht:graphics  
name="lsj51x.png" src="../img/probability/normAreaOther1.eps"  
--></td><td  style="white-space:nowrap; text-align:center;" id="TBL-28-1-2"  
class="td11"><img 
src="lsj52x.png" alt="PIC" class="graphics" width="199" height="132"  /><!--tex4ht:graphics  
name="lsj52x.png" src="../img/probability/normAreaOther2.eps"  
--></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-28-2-"><td  style="white-space:nowrap; text-align:center;" id="TBL-28-2-1"  
class="td11"> (a) </td><td  style="white-space:nowrap; text-align:center;" id="TBL-28-2-2"  
class="td11"> (b)</td>
</tr></table></div>
<br /> <div class="caption" 
><span class="id">Figure 7.9: </span><span  
class="content">Two more examples of the “area under the curve idea”. There is a 15.9% chance
that an observation is one standard deviation below the mean or smaller (panel a), and
a 34.1% chance that the observation is somewhere between one standard deviation below
the mean and the mean (panel b). Notice that if you add these two numbers together you
get 15.9%   34.1%   50%. For normally distributed data, there is a 50% chance that an
observation falls below the mean. And of course that also implies that there is a 50% chance
that it falls above the mean.</span></div><!--tex4ht:label?: x53-1260069 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
   <h4 class="subsectionHead"><span class="titlemark">7.5.1   </span> <a 
 id="x53-1270007.5.1"></a>Probability density  </h4>
<!--l. 512--><p class="noindent" >There’s something I’ve been trying to hide throughout my discussion of the normal distribution,
something that some introductory textbooks omit completely. They might be right to do
so. This “thing” that I’m hiding is weird and counter-intuitive even by the admittedly
distorted standards that apply in statistics. Fortunately, it’s not something that you need to
understand at a deep level in order to do basic statistics. Rather, it’s something that starts to
become important later on when you move beyond the basics. So, if it doesn’t make
complete sense, don’t worry too much, but try to make sure that you follow the gist of
it.
</p><!--l. 514--><p class="indent" >   Throughout my discussion of the normal distribution there’s been one or two things that don’t
quite make sense. Perhaps you noticed that the y-axis in these ﬁgures is labelled “Probability
Density” rather than density. Maybe you noticed that I used ppXq instead of PpXq when giving the
formula for the normal distribution.
</p><!--l. 516--><p class="indent" >   As it turns out, what is presented here isn’t actually a probability, it’s something else. To
understand what that something is you have to spend a little time thinking about what it really
means to say that X is a continuous variable. Let’s say we’re talking about the temperature
outside. The thermometer tells me it’s 23 degrees, but I know that’s not really true. It’s not exactly
23 degrees. Maybe it’s 23.1 degrees, I think to myself. But I know that that’s not really true either
because it might actually be 23.09 degrees. But I know that... well, you get the idea. The tricky
thing with genuinely continuous quantities is that you never really know exactly what they
are.
</p><!--l. 518--><p class="indent" >   Now think about what this implies when we talk about probabilities. Suppose that tomorrow’s
maximum temperature is sampled from a normal distribution with mean 23 and standard deviation
1. What’s the probability that the temperature will be exactly 23 degrees? The answer is
“zero”, or possibly “a number so close to zero that it might as well be zero”. Why is
this? It’s like trying to throw a dart at an inﬁnitely small dart board. No matter how
good your aim, you’ll never hit it. In real life you’ll never get a value of exactly 23. It’ll
always be something like 23.1 or 22.99998 or suchlike. In other words, it’s completely
meaningless to talk about the probability that the temperature is exactly 23 degrees.
However, in everyday language if I told you that it was 23 degrees outside and it turned
out to be 22.9998 degrees you probably wouldn’t call me a liar. Because in everyday
language “23 degrees” usually means something like “somewhere between 22.5 and 23.5
degrees”. And while it doesn’t feel very meaningful to ask about the probability that the
temperature is exactly 23 degrees, it does seem sensible to ask about the probability that the
temperature lies between 22.5 and 23.5, or between 20 and 30, or any other range of
                                                                                          

                                                                                          
temperatures.
</p><!--l. 520--><p class="indent" >   The point of this discussion is to make clear that when we’re talking about continuous
distributions it’s not meaningful to talk about the probability of a speciﬁc value. However, what we
can talk about is the probability that the value lies within a particular range of values. To ﬁnd out
the probability associated with a particular range what you need to do is calculate the “area under
the curve”. We’ve seen this concept already, in Figure <a 
href="#x53-1260058">7.8<!--tex4ht:ref: fig:sdnorm --></a> the shaded areas shown depict genuine
probabilities (e.g., in Figure <a 
href="#x53-1260058">7.8<!--tex4ht:ref: fig:sdnorm --></a>a it shows the probability of observing a value that falls within 1
standard deviation of the mean).
</p><!--l. 522--><p class="indent" >   Okay, so that explains part of the story. I’ve explained a little bit about how continuous
probability distributions should be interpreted (i.e., area under the curve is the key thing).
But what does the formula for ppxq that I described earlier actually mean? Obviously,
ppxq doesn’t describe a probability, but what is it? The name for this quantity ppxq is a
<span id="textcolor195">probability density</span>, and in terms of the plots we’ve been drawing it corresponds to the
height of the curve. The densities themselves aren’t meaningful in and of themselves,
but they’re “rigged” to ensure that the area under the curve is always interpretable as
genuine probabilities. To be honest, that’s about as much as you really need to know for
now.<span class="footnote-mark"><a 
href="lsj57.html#fn4x8"><sup class="textsuperscript">4</sup></a></span><a 
 id="x53-127001f4"></a> 
</p>
   <h3 class="sectionHead"><span class="titlemark">7.6   </span> <a 
 id="x53-1280007.6"></a>Other useful distributions </h3>
<!--l. 527--><p class="noindent" >The normal distribution is the distribution that statistics makes most use of (for reasons to be
discussed shortly), and the binomial distribution is a very useful one for lots of purposes. But the
world of statistics is ﬁlled with probability distributions, some of which we’ll run into in passing. In
particular, the three that will appear in this book are the t distribution, the χ<sup>2</sup> distribution and the
F distribution. I won’t give formulas for any of these, or talk about them in too much detail, but I
will show you some pictures.
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x53-12800110"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 530--><p class="noindent" >
</p><!--l. 531--><p class="noindent" ><img 
src="lsj53x.png" alt="PIC" class="graphics" width="312" height="199"  /><!--tex4ht:graphics  
name="lsj53x.png" src="../img/probability/tDist.eps"  
-->
<br /> </p><div class="caption" 
><span class="id">Figure 7.10: </span><span  
class="content">A t distribution with 3 degrees of freedom (solid line). It looks similar to a
normal distribution, but it’s not quite the same. For comparison purposes I’ve plotted a
standard normal distribution as the dashed line.</span></div><!--tex4ht:label?: x53-12800110 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x53-12800211"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 539--><p class="noindent" >
</p><!--l. 540--><p class="noindent" ><img 
src="lsj54x.png" alt="PIC" class="graphics" width="284" height="219"  /><!--tex4ht:graphics  
name="lsj54x.png" src="../img/probability/chiSqDist.eps"  
-->
<br /> </p><div class="caption" 
><span class="id">Figure 7.11: </span><span  
class="content">A χ<sup>2</sup>  distribution with 3 degrees of freedom. Notice that the observed values
must always be greater than zero, and that the distribution is pretty skewed. These are the
key features of a chi-square distribution.</span></div><!--tex4ht:label?: x53-12800211 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x53-12800312"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 548--><p class="noindent" >
</p><!--l. 549--><p class="noindent" ><img 
src="lsj55x.png" alt="PIC" class="graphics" width="284" height="219"  /><!--tex4ht:graphics  
name="lsj55x.png" src="../img/probability/FDist.eps"  
-->
<br /> </p><div class="caption" 
><span class="id">Figure 7.12: </span><span  
class="content">An F distribution with 3 and 5 degrees of freedom. Qualitatively speaking, it
looks pretty similar to a chi-square distribution, but they’re not quite the same in general.</span></div><!--tex4ht:label?: x53-12800312 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 556--><p class="indent" >
                                                                                          

                                                                                          
</p>
      <ul class="itemize1">
      <li class="itemize">The <span id="textcolor197">t distribution</span> is a continuous distribution that looks very similar to a normal
      distribution, see Figure <a 
href="#x53-12800110">7.10<!--tex4ht:ref: fig:tdist --></a>. Note that the “tails” of the t distribution are “heavier”
      (i.e., extend further outwards) than the tails of the normal distribution). That’s the
      important diﬀerence between the two. This distribution tends to arise in situations
      where you think that the data actually follow a normal distribution, but you don’t know
      the mean or standard deviation. We’ll run into this distribution again in Chapter <a 
href="lsjch11.html#x97-20200011">11<!--tex4ht:ref: ch:ttest --></a>.
      </li>
      <li class="itemize">The <span id="textcolor198">χ<sup>2</sup>  distribution</span> is another distribution that turns up in lots of diﬀerent places.
      The situation in which we’ll see it is when doing categorical data analysis (Chapter <a 
href="lsjch10.html#x83-17800010">10<!--tex4ht:ref: ch:chisquare --></a>),
      but it’s one of those things that actually pops up all over the place. When you dig into
      the maths (and who doesn’t love doing that?), it turns out that the main reason why
      the χ<sup>2</sup> distribution turns up all over the place is that if you have a bunch of variables
      that are normally distributed, square their values and then add them up (a procedure
      referred to as taking a “sum of squares”), this sum has a χ<sup>2</sup>  distribution. You’d be
      amazed how often this fact turns out to be useful. Anyway, here’s what a χ<sup>2</sup> distribution
      looks like: Figure <a 
href="#x53-12800211">7.11<!--tex4ht:ref: fig:chisqdist --></a>.
      </li>
      <li class="itemize">The <span id="textcolor199">F distribution</span> looks a bit like a χ<sup>2</sup> distribution, and it arises whenever you need
      to compare two χ<sup>2</sup> distributions to one another. Admittedly, this doesn’t exactly sound
      like something that any sane person would want to do, but it turns out to be very
      important in real world data analysis. Remember when I said that χ<sup>2</sup> turns out to be
      the key distribution when we’re taking a “sum of squares”? Well, what that means is
      if you want to compare two diﬀerent “sums of squares”, you’re probably talking about
      something that has an F distribution. Of course, as yet I still haven’t given you an
      example of anything that involves a sum of squares, but I will in Chapter <a 
href="lsjch13.html#x131-28000013">13<!--tex4ht:ref: ch:anova --></a>. And
      that’s where we’ll run into the F distribution. Oh, and there’s a picture in Figure <a 
href="#x53-12800312">7.12<!--tex4ht:ref: fig:Fdist --></a>.</li></ul>
<!--l. 565--><p class="indent" >   Okay, time to wrap this section up. We’ve seen three new distributions: χ<sup>2</sup>, t and F. They’re all
continuous distributions, and they’re all closely related to the normal distribution. The main
thing for our purposes is that you grasp the basic idea that these distributions are all
deeply related to one another, and to the normal distribution. Later on in this book we’re
going to run into data that are normally distributed, or at least assumed to be normally
distributed. What I want you to understand right now is that, if you make the assumption
that your data are normally distributed, you shouldn’t be surprised to see χ<sup>2</sup>, t and
F distributions popping up all over the place when you start trying to do your data
analysis.
                                                                                          

                                                                                          
</p>
   <h3 class="sectionHead"><span class="titlemark">7.7   </span> <a 
 id="x53-1290007.7"></a>Summary</h3>
<!--l. 570--><p class="noindent" >In this chapter we’ve talked about probability. We’ve talked about what probability means
and why statisticians can’t agree on what it means. We talked about the rules that
probabilities have to obey. And we introduced the idea of a probability distribution and
spent a good chunk of the chapter talking about some of the more important probability
distributions that statisticians work with. The section by section breakdown looks like
this:
</p>
      <ul class="itemize1">
      <li class="itemize">Probability theory versus statistics (Section <a 
href="#x53-1170007.1">7.1<!--tex4ht:ref: sec:probstats --></a>)
      </li>
      <li class="itemize">Frequentist versus Bayesian views of probability (Section <a 
href="#x53-1180007.2">7.2<!--tex4ht:ref: sec:probmeaning --></a>)
      </li>
      <li class="itemize">Basics of probability theory (Section <a 
href="#x53-1220007.3">7.3<!--tex4ht:ref: sec:basicprobability --></a>)
      </li>
      <li class="itemize">Binomial  distribution  (Section <a 
href="#x53-1240007.4">7.4<!--tex4ht:ref: sec:binomial --></a>),  normal  distribution  (Section <a 
href="#x53-1260007.5">7.5<!--tex4ht:ref: sec:normal --></a>),  and  others
      (Section <a 
href="#x53-1280007.6">7.6<!--tex4ht:ref: sec:otherdists --></a>)</li></ul>
<!--l. 579--><p class="indent" >   As you’d expect, my coverage is by no means exhaustive. Probability theory is a large branch of
mathematics in its own right, entirely separate from its application to statistics and data analysis.
As such, there are thousands of books written on the subject and universities generally oﬀer
multiple classes devoted entirely to probability theory. Even the “simpler” task of documenting
standard probability distributions is a big topic. I’ve described ﬁve standard probability
distributions in this chapter, but sitting on my bookshelf I have a 45-chapter book called
“Statistical Distributions” (Evans, Hastings, and Peacock 2011) that lists a lot more than that.
Fortunately for you, very little of this is necessary. You’re unlikely to need to know dozens of
statistical distributions when you go out and do real world data analysis, and you deﬁnitely won’t
need them for this book, but it never hurts to know that there’s other possibilities out
there.
</p><!--l. 581--><p class="indent" >   Picking up on that last point, there’s a sense in which this whole chapter is something of a
digression. Many undergraduate psychology classes on statistics skim over this content very quickly
(I know mine did), and even the more advanced classes will often “forget” to revisit the basic
foundations of the ﬁeld. Most academic psychologists would not know the diﬀerence between
probability and density, and until recently very few would have been aware of the diﬀerence
between Bayesian and frequentist probability. However, I think it’s important to understand these
                                                                                          

                                                                                          
things before moving onto the applications. For example, there are a lot of rules about what you’re
“allowed” to say when doing statistical inference and many of these can seem arbitrary and weird.
However, they start to make sense if you understand that there is this Bayesian/frequentist
distinction. Similarly, in Chapter <a 
href="lsjch11.html#x97-20200011">11<!--tex4ht:ref: ch:ttest --></a> we’re going to talk about something called the
t-test, and if you really want to have a grasp of the mechanics of the t-test it really
helps to have a sense of what a t-distribution actually looks like. You get the idea, I
hope.
                                                                                          

                                                                                          
</p>
   <!--l. 4--><div class="crosslinks"><p class="noindent">[<a 
href="lsjch8.html" >next</a>] [<a 
href="lsjli2.html" >prev</a>] [<a 
href="lsjli2.html#taillsjli2.html" >prev-tail</a>] [<a 
href="lsjch7.html" >front</a>] [<a 
href="lsjpa4.html#lsjch7.html" >up</a>] </p></div>
<!--l. 4--><p class="indent" >   <a 
 id="taillsjch7.html"></a>  </p> 
</body></html> 
