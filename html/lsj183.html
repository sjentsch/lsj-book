<?xml version="1.0" encoding=""utf-8"" ?> 
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" 
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">  
<!--http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd-->  
<html xmlns="http://www.w3.org/1999/xhtml"  
> 
<head><title></title> 
<meta http-equiv="Content-Type" content="text/html; charset="utf-8"" /> 
<meta name="generator" content="TeX4ht (http://www.tug.org/tex4ht/)" /> 
<meta name="originator" content="TeX4ht (http://www.tug.org/tex4ht/)" /> 
<!-- 2,html,xhtml,NoFonts,ext=htm,charset="utf-8" --> 
<meta name="src" content="lsj.tex" /> 
<link rel="stylesheet" type="text/css" href="lsj.css" /> 
</head><body 
>
        <div class="footnote-text">
   <!--l. 375--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn16x17">  <sup class="textsuperscript">16</sup></a></span><span id="textcolor479">Okay, I just know that some knowledgeable frequentists will read this and start complaining about this
   section. Look, I’m not dumb. I absolutely know that if you adopt a sequential analysis perspective you can avoid
   these errors within the orthodox framework. I also know that you can explictly design studies with interim analyses
   in mind. So yes, in one sense I’m attacking a “straw man” version of orthodox methods. However, the straw man
   that I’m attacking is the one that is used by almost every single practitioner. If it ever reaches the point where
   sequential methods become the norm among experimental psychologists and I’m no longer forced to read 20
   extremely dubious ANOVAs a day, I promise I’ll rewrite this section and dial down the vitriol. But until that day
   arrives, I stand by my claim that default Bayes factor methods are much more robust in the face of data
   analysis practices as they exist in the real world. Default orthodox methods suck, and we all know
   it.</span></p></div>
       
</body></html> 
