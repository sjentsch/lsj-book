<?xml version="1.0" encoding=""utf-8"" ?> 
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" 
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">  
<!--http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd-->  
<html xmlns="http://www.w3.org/1999/xhtml"  
> 
<head><title>4 Descriptive statistics</title> 
<meta http-equiv="Content-Type" content="text/html; charset="utf-8"" /> 
<meta name="generator" content="TeX4ht (http://www.tug.org/tex4ht/)" /> 
<meta name="originator" content="TeX4ht (http://www.tug.org/tex4ht/)" /> 
<!-- 2,html,xhtml,NoFonts,ext=htm,charset="utf-8" --> 
<meta name="src" content="lsj.tex" /> 
<link rel="stylesheet" type="text/css" href="lsj.css" /> 
</head><body 
>
   <!--l. 5--><div class="crosslinks"><p class="noindent">[<a 
href="lsjch5.html" >next</a>] [<a 
href="#taillsjch4.html">tail</a>] [<a 
href="lsjpa3.html#lsjch4.html" >up</a>] </p></div>
   <h2 class="chapterHead"><span class="titlemark">Chapter 4</span><br /><a 
 id="x27-670004"></a>Descriptive statistics</h2>
<!--l. 7--><p class="noindent" >Any time that you get a new data set to look at one of the ﬁrst tasks that
you have to do is ﬁnd ways of summarising the data in a compact, easily
understood fashion. This is what <span id="textcolor80">descriptive statistics</span> (as opposed
to inferential statistics) is all about. In fact, to many people the term
“statistics” is synonymous with descriptive statistics. It is this topic that we’ll
                                                                                          

                                                                                          
consider in this chapter, but before going into any details, let’s take a
moment to get a sense of why we need descriptive statistics. To do this, let’s
open the aflsmall_margins ﬁle and see what variables are stored in the
ﬁle.
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x27-670011"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 11--><p class="noindent" >

</p><!--l. 12--><p class="noindent" ><img 
src="../img/descriptives/aflsmall_margins.png" alt="PIC"  
 />
<br />   </p><div class="caption" 
><span class="id">Figure 4.1:   </span><span  
class="content">A   screenshot   of   jamovi   showing   the   variables   stored   in   the
aflsmall_margins.csv ﬁle</span></div><!--tex4ht:label?: x27-670011 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 19--><p class="indent" >   In fact, there is just one variable here, afl.margins. We’ll focus a bit on this
variable in this chapter, so I’d better tell you what it is. Unlike most of the data sets
in this book, this is actually real data, relating to the Australian Football League
(AFL).<span class="footnote-mark"><a 
href="lsj28.html#fn1x5"><sup class="textsuperscript">1</sup></a></span><a 
 id="x27-67002f1"></a> 
The afl.margins variable contains the winning margin (number of points) for all
176 home and away games played during the 2010 season.
</p><!--l. 21--><p class="indent" >   This output doesn’t make it easy to get a sense of what the data are
actually saying. Just “looking at the data” isn’t a terribly eﬀective way
of understanding data. In order to get some idea about what the data
are actually saying we need to calculate some descriptive statistics (this
chapter) and draw some nice pictures (Chapter <a 
href="lsjch5.html#x37-870005">5<!--tex4ht:ref: ch:graphics --></a>). Since the descriptive
statistics are the easier of the two topics I’ll start with those, but nevertheless
I’ll show you a histogram of the afl.margins data since it should help
you get a sense of what the data we’re trying to describe actually look
like, see Figure <a 
href="#x27-670032">4.2<!--tex4ht:ref: fig:histogram1 --></a>. We’ll talk a lot more about how to draw histograms
in Section <a 
href="lsjch5.html#x37-880005.1">5.1<!--tex4ht:ref: sec:hist --></a>. For now, it’s enough to look at the histogram and note
that it provides a fairly interpretable representation of the afl.margins
data.
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x27-670032"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 24--><p class="noindent" >
</p><!--l. 25--><p class="noindent" ><img 
src="lsj3x.png" alt="PIC" class="graphics" width="341" height="263"  /><!--tex4ht:graphics  
name="lsj3x.png" src="../img/descriptives/aflMargins.eps"  
-->
<br /> </p><div class="caption" 
><span class="id">Figure 4.2: </span><span  
class="content">A histogram of the AFL 2010 winning margin data (the afl.margins variable).
As you might expect, the larger the winning margin the less frequently you tend to see it.</span></div><!--tex4ht:label?: x27-670032 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
   <h3 class="sectionHead"><span class="titlemark">4.1   </span> <a 
 id="x27-680004.1"></a>Measures of central tendency </h3>
<!--l. 34--><p class="noindent" >Drawing pictures of the data, as I did in Figure <a 
href="#x27-670032">4.2<!--tex4ht:ref: fig:histogram1 --></a>, is an excellent way to convey
the “gist” of what the data is trying to tell you. It’s often extremely useful to try
to condense the data into a few simple “summary” statistics. In most situations,
the ﬁrst thing that you’ll want to calculate is a measure of <span id="textcolor82">central tendency</span>.
That is, you’d like to know something about where the “average” or “middle” of
your data lies. The three most commonly used measures are the mean, median and
mode. I’ll explain each of these in turn, and then discuss when each of them is
useful.
</p><!--l. 36--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">4.1.1   </span> <a 
 id="x27-690004.1.1"></a>The mean</h4>
<!--l. 38--><p class="noindent" >The <span id="textcolor83">mean</span> of a set of observations is just a normal, old-fashioned average. Add all
of the values up, and then divide by the total number of values. The ﬁrst ﬁve AFL
winning margins were 56, 31, 56, 8 and 32, so the mean of these observations is
just:
</p>
   <center class="math-display" >
<img 
src="lsj4x.png" alt="56  ---31-----56-----8-----32-     183--    36.60
            5                  5  " class="math-display"  /></center> Of
                                                                                          

                                                                                          
course, this deﬁnition of the mean isn’t news to anyone. Averages (i.e., means) are
used so often in everyday life that this is pretty familiar stuﬀ. However, since the
concept of a mean is something that everyone already understands, I’ll use this as
an excuse to start introducing some of the mathematical notation that statisticians
use to describe this calculation, and talk about how the calculations would be done
in jamovi.
<!--l. 44--><p class="indent" >   The ﬁrst piece of notation to introduce is N, which we’ll use to refer to the
number of observations that we’re averaging (in this case N   5). Next, we need to
attach a label to the observations themselves. It’s traditional to use X for this, and
to use subscripts to indicate which observation we’re actually talking about. That
is, we’ll use X<sub>1</sub> to refer to the ﬁrst observation, X<sub>2</sub> to refer to the second
observation, and so on all the way up to X<sub>N</sub> for the last one. Or, to say the same
thing in a slightly more abstract way, we use X<sub>i</sub> to refer to the i-th observation.
Just to make sure we’re clear on the notation, the following table lists the 5
observations in the afl.margins variable, along with the mathematical symbol
used to refer to it and the actual value that the observation corresponds
to:
</p>
<div class="center" 
>
<!--l. 46--><p class="noindent" >
</p>
<div class="tabular"> <table id="TBL-13" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-13-1g"><col 
id="TBL-13-1" /><col 
id="TBL-13-2" /><col 
id="TBL-13-3" /></colgroup><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-13-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-13-1-1"  
class="td11">the observation           </td><td  style="white-space:nowrap; text-align:right;" id="TBL-13-1-2"  
class="td11">its symbol</td><td  style="white-space:nowrap; text-align:right;" id="TBL-13-1-3"  
class="td11">the observed value</td>
</tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-13-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-13-2-1"  
class="td11">winning margin, game 1</td><td  style="white-space:nowrap; text-align:right;" id="TBL-13-2-2"  
class="td11">      X<sub>1</sub></td><td  style="white-space:nowrap; text-align:right;" id="TBL-13-2-3"  
class="td11">        56 points</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-13-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-13-3-1"  
class="td11">winning margin, game 2</td><td  style="white-space:nowrap; text-align:right;" id="TBL-13-3-2"  
class="td11">      X<sub>2</sub></td><td  style="white-space:nowrap; text-align:right;" id="TBL-13-3-3"  
class="td11">        31 points</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-13-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-13-4-1"  
class="td11">winning margin, game 3</td><td  style="white-space:nowrap; text-align:right;" id="TBL-13-4-2"  
class="td11">      X<sub>3</sub></td><td  style="white-space:nowrap; text-align:right;" id="TBL-13-4-3"  
class="td11">        56 points</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-13-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-13-5-1"  
class="td11">winning margin, game 4</td><td  style="white-space:nowrap; text-align:right;" id="TBL-13-5-2"  
class="td11">      X<sub>4</sub></td><td  style="white-space:nowrap; text-align:right;" id="TBL-13-5-3"  
class="td11">         8 points</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-13-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-13-6-1"  
class="td11">winning margin, game 5</td><td  style="white-space:nowrap; text-align:right;" id="TBL-13-6-2"  
class="td11">      X<sub>5</sub></td><td  style="white-space:nowrap; text-align:right;" id="TBL-13-6-3"  
class="td11">        32 points</td>
</tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-13-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-13-7-1"  
class="td11">                    </td></tr></table></div></div>
<!--l. 63--><p class="indent" >   Okay, now let’s try to write a formula for the mean. By tradition, we use <span class="bar-css">X</span> as
the notation for the mean. So the calculation for the mean could be expressed
                                                                                          

                                                                                          
using the following formula:
</p>
   <center class="math-display" >
<img 
src="lsj5x.png" alt=" ¯    X1   ---X2-----...-----XN----1-----XN--
X
                      N " class="math-display"  /></center> This formula
is entirely correct but it’s terribly long, so we make use of the <span id="textcolor84">summation symbol</span>  
 to
shorten it.<span class="footnote-mark"><a 
href="lsj29.html#fn2x5"><sup class="textsuperscript">2</sup></a></span><a 
 id="x27-69001f2"></a> 
If I want to add up the ﬁrst ﬁve observations I could write out the sum the long
way, X<sub>1</sub>   X<sub>2</sub>   X<sub>3</sub>   X<sub>4</sub>   X<sub>5</sub> or I could use the summation symbol to shorten it
to this:
   <center class="math-display" >
<img 
src="lsj6x.png" alt=" 5

   Xi
i  1  " class="math-display"  /></center>
Taken literally, this could be read as “the sum, taken over all i values from 1 to 5,
of the value X<sub>i</sub>”. But basically what it means is “add up the ﬁrst ﬁve
                                                                                          

                                                                                          
observations”. In any case, we can use this notation to write out the formula for
the mean, which looks like this:
   <center class="math-display" >
<img 
src="lsj7x.png" alt="       1   N
X¯     ---    Xi
      N
         i   1
" class="math-display"  /></center>
<!--l. 76--><p class="indent" >   In all honesty, I can’t imagine that all this mathematical notation helps
clarify the concept of the mean at all. In fact, it’s really just a fancy way of
writing out the same thing I said in words: add all the values up and then
divide by the total number of items. However, that’s not really the reason I
went into all that detail. My goal was to try to make sure that everyone
reading this book is clear on the notation that we’ll be using throughout
the book: <span class="bar-css">X</span> for the mean,  
 for the idea of summation, X<sub>i</sub> for the ith
observation, and N for the total number of observations. We’re going to be
re-using these symbols a fair bit so it’s important that you understand them
well enough to be able to “read” the equations, and to be able to see
that it’s just saying “add up lots of things and then divide by another
thing”.
</p>
   <h4 class="subsectionHead"><span class="titlemark">4.1.2   </span> <a 
 id="x27-700004.1.2"></a>Calculating the mean in jamovi</h4>
<!--l. 81--><p class="noindent" >Okay, that’s the maths. So how do we get the magic computing box to do the work
for us? When the number of observations starts to become large it’s much
easier to do these sorts of calculations using a computer. To calculate the
                                                                                          

                                                                                          
mean using all the data we can use jamovi. The ﬁrst step is to click on the
‘Exploration’ button and then click ‘Descriptives’. Then you can highlight the
afl.margins variable and click the ‘right arrow’ to move it across into the
‘Variables box’. As soon as you do that a Table appears on the right hand side
of the screen containing default ‘Descriptives’ information; see Figure
<a 
href="#x27-700013">4.3<!--tex4ht:ref: fig:descriptives_default --></a>.
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x27-700013"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 85--><p class="noindent" >

</p><!--l. 86--><p class="noindent" ><img 
src="../img/descriptives/descriptives_default.png" alt="PIC"  
 />
<br /> </p><div class="caption" 
><span class="id">Figure 4.3: </span><span  
class="content">Default descriptives for the AFL 2010 winning margin data (the afl.margins
variable). </span></div><!--tex4ht:label?: x27-700013 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 93--><p class="indent" >   As you can see in Figure <a 
href="#x27-700013">4.3<!--tex4ht:ref: fig:descriptives_default --></a>, the mean value for the afl.margins variable is
35.30. Other information presented includes the total number of observations
(N=176), the number of missing values (none), and the Median, Minimum and
Maximum values for the variable.
</p>
   <h4 class="subsectionHead"><span class="titlemark">4.1.3   </span> <a 
 id="x27-710004.1.3"></a>The median</h4>
<!--l. 97--><p class="noindent" >The second measure of central tendency that people use a lot is the <span id="textcolor86">median</span>, and
it’s even easier to describe than the mean. The median of a set of observations is
just the middle value. As before let’s imagine we were interested only in the ﬁrst 5
AFL winning margins: 56, 31, 56, 8 and 32. To ﬁgure out the median we sort these
numbers into ascending order:
</p>
   <center class="math-display" >
<img 
src="lsj8x.png" alt="8, 31, 32, 56, 56  " class="math-display"  /></center>
From inspection, it’s obvious that the median value of these 5 observations is
32 since that’s the middle one in the sorted list (I’ve put it in bold to
make it even more obvious). Easy stuﬀ. But what should we do if we are
interested in the ﬁrst 6 games rather than the ﬁrst 5? Since the sixth
game in the season had a winning margin of 14 points, our sorted list is
now
                                                                                          

                                                                                          
   <center class="math-display" >
<img 
src="lsj9x.png" alt="8, 14, 31, 32, 56, 56  " class="math-display"  /></center> and
there are two middle numbers, 31 and 32. The median is deﬁned as the average of
those two numbers, which is of course 31.5. As before, it’s very tedious to do this
by hand when you’ve got lots of numbers. In real life, of course, no-one actually
calculates the median by sorting the data and then looking for the middle value. In
real life we use a computer to do the heavy lifting for us, and jamovi has
provided us with a Median value of 30.50 for the afl.margins variable
(Figure <a 
href="#x27-700013">4.3<!--tex4ht:ref: fig:descriptives_default --></a>).
<!--l. 107--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">4.1.4   </span> <a 
 id="x27-720004.1.4"></a>Mean or median? What’s the diﬀerence?</h4>
<!--l. 109--><p class="noindent" >Knowing how to calculate means and medians is only a part of the story.
You also need to understand what each one is saying about the data, and
what that implies for when you should use each one. This is illustrated in
Figure <a 
href="#x27-720014">4.4<!--tex4ht:ref: fig:meanmedian --></a>. The mean is kind of like the “centre of gravity” of the data
set, whereas the median is the “middle value” in the data. What this
implies, as far as which one you should use, depends a little on what type
of data you’ve got and what you’re trying to achieve. As a rough guide:
</p>
      <ul class="itemize1">
      <li class="itemize">If your data are nominal scale you probably shouldn’t be using either the
      mean or the median. Both the mean and the median rely on the idea that
      the numbers assigned to values are meaningful. If the numbering scheme
                                                                                          

                                                                                          
      is  arbitrary  then  it’s  probably  best  to  use  the  mode  (Section <a 
href="#x27-740004.1.6">4.1.6<!--tex4ht:ref: sec:mode --></a>)
      instead.
      </li>
      <li class="itemize">If your data are ordinal scale you’re more likely to want to use the median
      than the mean. The median only makes use of the order information in
      your data (i.e., which numbers are bigger) but doesn’t depend on the
      precise numbers involved. That’s exactly the situation that applies when
      your data are ordinal scale. The mean, on the other hand, makes use of
      the precise numeric values assigned to the observations, so it’s not really
      appropriate for ordinal data.
      </li>
      <li class="itemize">For interval and ratio scale data either one is generally acceptable. Which
      one you pick depends a bit on what you’re trying to achieve. The mean
      has the advantage that it uses all the information in the data (which
      is useful when you don’t have a lot of data). But it’s very sensitive to
      extreme, outlying values.</li></ul>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x27-720014"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 118--><p class="noindent" >
</p><!--l. 119--><p class="noindent" ><img 
src="lsj10x.png" alt="PIC" class="graphics" width="170" height="147"  /><!--tex4ht:graphics  
name="lsj10x.png" src="../img/descriptives2/mean.eps"  
--> <img 
src="lsj11x.png" alt="PIC" class="graphics" width="182" height="146"  /><!--tex4ht:graphics  
name="lsj11x.png" src="./../img/descriptives2/median.eps"  
-->
<br /> </p><div class="caption" 
><span class="id">Figure 4.4: </span><span  
class="content">An illustration of the diﬀerence between how the mean and the median should
be interpreted. The mean is basically the “centre of gravity” of the data set. If you imagine
that the histogram of the data is a solid object, then the point on which you could balance
it (as if on a see-saw) is the mean. In contrast, the median is the middle observation, with
half of the observations smaller and half of the observations larger.</span></div><!--tex4ht:label?: x27-720014 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 127--><p class="indent" >   Let’s expand on that last part a little. One consequence is that there are
systematic diﬀerences between the mean and the median when the histogram is
asymmetric (skewed; see Section <a 
href="#x27-820004.3">4.3<!--tex4ht:ref: sec:skewkurt --></a>). This is illustrated in Figure <a 
href="#x27-720014">4.4<!--tex4ht:ref: fig:meanmedian --></a>. Notice that
the median (right hand side) is located closer to the “body” of the histogram,
whereas the mean (left hand side) gets dragged towards the “tail” (where the
extreme values are). To give a concrete example, suppose Bob (income
$50,000), Kate (income $60,000) and Jane (income $65,000) are sitting at a
table. The average income at the table is $58,333 and the median income
is $60,000. Then Bill sits down with them (income $100,000,000). The
average income has now jumped to $25,043,750 but the median rises only
to $62,500. If you’re interested in looking at the overall income at the
table the mean might be the right answer. But if you’re interested in what
counts as a typical income at the table the median would be a better choice
here.
</p>
   <h4 class="subsectionHead"><span class="titlemark">4.1.5   </span> <a 
 id="x27-730004.1.5"></a>A real life example </h4>
<!--l. 131--><p class="noindent" >To try to get a sense of why you need to pay attention to the diﬀerences between
the mean and the median let’s consider a real life example. Since I tend to mock
journalists for their poor scientiﬁc and statistical knowledge, I should give
credit where credit is due. This is an excellent article on the ABC news
website<span class="footnote-mark"><a 
href="lsj30.html#fn3x5"><sup class="textsuperscript">3</sup></a></span><a 
 id="x27-73001f3"></a> 
from 24 September, 2010:
      </p><div class="quote">
      <!--l. 134--><p class="noindent" >Senior Commonwealth Bank executives have travelled the world in the past couple of
      weeks with a presentation showing how Australian house prices, and the key price to
      income ratios, compare favourably with similar countries. “Housing aﬀordability has
      actually been going sideways for the last ﬁve to six years,” said Craig James, the chief
      economist of the bank’s trading arm, CommSec.</p></div>
                                                                                          

                                                                                          
<!--l. 137--><p class="noindent" >This probably comes as a huge surprise to anyone with a mortgage, or who wants a mortgage, or pays
rent, or isn’t completely oblivious to what’s been going on in the Australian housing market over
the last several years. Back to the article:
      </p><div class="quote">
      <!--l. 140--><p class="noindent" >CBA has waged its war against what it believes are housing doomsayers with graphs,
      numbers and international comparisons. In its presentation, the bank rejects arguments
      that Australia’s housing is relatively expensive compared to incomes. It says Australia’s
      house price to household income ratio of 5.6 in the major cities, and 4.3 nationwide,
      is comparable to many other developed nations. It says San Francisco and New York
      have ratios of 7, Auckland’s is 6.7, and Vancouver comes in at 9.3.</p></div>
<!--l. 143--><p class="noindent" >More excellent news! Except, the article goes on to make the observation that:
      </p><div class="quote">
      <!--l. 146--><p class="noindent" >Many analysts say that has led the bank to use misleading ﬁgures and comparisons.
      If you go to page four of CBA’s presentation and read the source information at the
      bottom of the graph and table, you would notice there is an additional source on the
      international comparison – Demographia. However, if the Commonwealth Bank had
      also used Demographia’s analysis of Australia’s house price to income ratio, it would
      have come up with a ﬁgure closer to 9 rather than 5.6 or 4.3</p></div>
<!--l. 149--><p class="noindent" >That’s, um, a rather serious discrepancy. One group of people say 9, another says 4-5. Should we just
split the diﬀerence and say the truth lies somewhere in between? Absolutely not! This is a situation
where there is a right answer and a wrong answer. Demographia is correct, and the Commonwealth
Bank is wrong. As the article points out:
      </p><div class="quote">
      <!--l. 152--><p class="noindent" >[An] obvious problem with the Commonwealth Bank’s domestic price to income ﬁgures
      is they compare average incomes with median house prices (unlike the Demographia
      ﬁgures that compare median incomes to median prices). The median is the mid-point,
      eﬀectively cutting out the highs and lows, and that means the average is generally
      higher when it comes to incomes and asset prices, because it includes the earnings of
      Australia’s wealthiest people. To put it another way: the Commonwealth Bank’s ﬁgures
      count Ralph Norris’ multi-million dollar pay packet on the income side, but not his (no
      doubt) very expensive house in the property price ﬁgures, thus understating the house
      price to income ratio for middle-income Australians.</p></div>
<!--l. 155--><p class="noindent" >Couldn’t have put it better myself. The way that Demographia calculated the ratio is the
right thing to do. The way that the Bank did it is incorrect. As for why an extremely
                                                                                          

                                                                                          
quantitatively sophisticated organisation such as a major bank made such an elementary
mistake, well... I can’t say for sure since I have no special insight into their thinking. But
the article itself does happen to mention the following facts, which may or may not be
relevant:
      </p><div class="quote">
      <!--l. 158--><p class="noindent" >[As] Australia’s largest home lender, the Commonwealth Bank has one of the biggest
      vested interests in house prices rising. It eﬀectively owns a massive swathe of Australian
      housing as security for its home loans as well as many small business loans.</p></div>
<!--l. 161--><p class="noindent" >My, my.
</p>
   <h4 class="subsectionHead"><span class="titlemark">4.1.6   </span> <a 
 id="x27-740004.1.6"></a>Mode</h4>
<!--l. 165--><p class="noindent" >The mode of a sample is very simple. It is the value that occurs most frequently. We can illustrate
the mode using a diﬀerent AFL variable: who has played in the most ﬁnals? Open the
aflsmall_finalists ﬁle and take a look at the afl.finalists variable, see Figure <a 
href="#x27-740015">4.5<!--tex4ht:ref: fig:aflsmall_finalists --></a>. This
variable contains the names of all 400 teams that played in all 200 ﬁnals matches played during the
period 1987 to 2010.
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x27-740015"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 169--><p class="noindent" >

</p><!--l. 170--><p class="noindent" ><img 
src="../img/descriptives/aflsmall_finalists.png" alt="PIC"  
 />
<br />   </p><div class="caption" 
><span class="id">Figure 4.5:   </span><span  
class="content">A   screenshot   of   jamovi   showing   the   variables   stored   in   the
aflsmall_finalists.csv ﬁle</span></div><!--tex4ht:label?: x27-740015 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 177--><p class="indent" >   What we could do is read through all 400 entries and count the number of occasions on which
each team name appears in our list of ﬁnalists, thereby producing a <span id="textcolor88">frequency table</span>. However,
that would be mindless and boring: exactly the sort of task that computers are great
at. So let’s use jamovi to do this for us. Under ‘Exploration’ - ‘Descriptives’ click the
small check box labelled ‘Frequency tables’ and you should get something like Figure
<a 
href="#x27-740026">4.6<!--tex4ht:ref: fig:aflsmall_finalists_mode --></a>.
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x27-740026"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 181--><p class="noindent" >

</p><!--l. 182--><p class="noindent" ><img 
src="../img/descriptives/aflsmall_finalists_mode.png" alt="PIC"  
 />
<br /> </p><div class="caption" 
><span class="id">Figure 4.6: </span><span  
class="content">A screenshot of jamovi showing the frequency table for the afl.finalists
variable </span></div><!--tex4ht:label?: x27-740026 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 189--><p class="indent" >   Now that we have our frequency table we can just look at it and see that, over the 24 years for
which we have data, Geelong has played in more ﬁnals than any other team. Thus, the mode of the
afl.finalists data is &#x0022;Geelong&#x0022;. We can see that Geelong (39 ﬁnals) played in more ﬁnals than
any other team during the 1987-2010 period. It’s also worth noting that in the ‘Descriptives’ Table
no results are calculated for Mean, Median, Minimum or Maximum. This is because the
afl.finalists variable is a nominal text variable so it makes no sense to calculate these
values.
</p><!--l. 191--><p class="indent" >   One last point to make regarding the mode. Whilst the mode is most often calculated when you
have nominal data, because means and medians are useless for those sorts of variables, there are
some situations in which you really do want to know the mode of an ordinal, interval or ratio scale
variable. For instance, let’s go back to our afl.margins variable. This variable is clearly ratio scale
(if it’s not clear to you, it may help to re-read Section <a 
href="lsjch2.html#x10-140002.2">2.2<!--tex4ht:ref: sec:scales --></a>), and so in most situations the mean or
the median is the measure of central tendency that you want. But consider this scenario: a friend of
yours is oﬀering a bet and they pick a football game at random. Without knowing who is
playing you have to guess the exact winning margin. If you guess correctly you win $50. If
you don’t you lose $1. There are no consolation prizes for “almost” getting the right
answer. You have to guess exactly the right margin. For this bet, the mean and the
median are completely useless to you. It is the mode that you should bet on. To calculate
the mode for the afl.margins variable in jamovi, go back to that data set and on the
‘Exploration’ - ‘Descriptives’ screen you will see you can expand the section marked ‘Statistics’.
Click on the checkbox marked ‘Mode’ and you will see the modal value presented in the
‘Descriptives’ Table, as in Figure <a 
href="#x27-740037">4.7<!--tex4ht:ref: fig:aflsmall_margins_mode --></a>. So the 2010 data suggest you should bet on a 3 point
margin.
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x27-740037"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 195--><p class="noindent" >

</p><!--l. 196--><p class="noindent" ><img 
src="../img/descriptives/aflsmall_margins_mode.png" alt="PIC"  
 />
<br /> </p><div class="caption" 
><span class="id">Figure 4.7: </span><span  
class="content">A screenshot of jamovi showing the modal value for the afl.margins variable </span></div><!--tex4ht:label?: x27-740037 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
   <h3 class="sectionHead"><span class="titlemark">4.2   </span> <a 
 id="x27-750004.2"></a>Measures of variability</h3>
<!--l. 206--><p class="noindent" >The statistics that we’ve discussed so far all relate to central tendency. That is, they all talk about
which values are “in the middle” or “popular” in the data. However, central tendency is not the
only type of summary statistic that we want to calculate. The second thing that we really want is a
measure of the <span id="textcolor89">variability</span> of the data. That is, how “spread out” are the data? How “far” away
from the mean or median do the observed values tend to be? For now, let’s assume that the data
are interval or ratio scale, and we’ll continue to use the afl.margins data. We’ll use this
data to discuss several diﬀerent measures of spread, each with diﬀerent strengths and
weaknesses.
</p><!--l. 208--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">4.2.1   </span> <a 
 id="x27-760004.2.1"></a>Range</h4>
<!--l. 210--><p class="noindent" >The <span id="textcolor90">range</span> of a variable is very simple. It’s the biggest value minus the smallest value. For the AFL
winning margins data the maximum value is 116 and the minimum value is 0. Although the range
is the simplest way to quantify the notion of “variability”, it’s one of the worst. Recall from
our discussion of the mean that we want our summary measure to be robust. If the
data set has one or two extremely bad values in it we’d like our statistics to not be
unduly inﬂuenced by these cases. For example, in a variable containing very extreme
outliers
</p>
   <center class="math-display" >
<img 
src="lsj12x.png" alt="100,2,3, 4,5,6,7,8,9,10  " class="math-display"  /></center> it is
clear that the range is not robust. This variable has a range of 110 but if the outlier were removed
we would have a range of only 8.
                                                                                          

                                                                                          
<!--l. 216--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">4.2.2   </span> <a 
 id="x27-770004.2.2"></a>Interquartile range</h4>
<!--l. 218--><p class="noindent" >The <span id="textcolor91">interquartile range</span> (IQR) is like the range, but instead of the diﬀerence between the biggest
and smallest value the diﬀerence between the 25th percentile and the 75th percentile is taken. If
you don’t already know what a <span id="textcolor92">percentile</span> is, the 10th percentile of a data set is the smallest
number x such that 10% of the data is less than x. In fact, we’ve already come across the idea. The
median of a data set is its 50th percentile! In jamovi you can easily specify the 25th, 50th and 75th
percentiles by clicking the checkbox ‘Quartiles’ in the ‘Exploration’ - ‘Descriptives’ - ‘Statistics’
screen.
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x27-770018"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 222--><p class="noindent" >

</p><!--l. 223--><p class="noindent" ><img 
src="../img/descriptives/aflsmall_margins_iqr.png" alt="PIC"  
 />
<br /> </p><div class="caption" 
><span class="id">Figure 4.8: </span><span  
class="content">A screenshot of jamovi showing the Quartiles for the afl.margins variable </span></div><!--tex4ht:label?: x27-770018 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 230--><p class="indent" >   And not surprisingly, in Figure <a 
href="#x27-770018">4.8<!--tex4ht:ref: fig:aflsmall_margins_iqr --></a> the 50th percentile is the same as the median value. And, by
noting that 50.50   12.75   37.75, we can see that the interquartile range for the 2010 AFL winning
margins data is 37.75. While it’s obvious how to interpret the range it’s a little less obvious how to
interpret the IQR. The simplest way to think about it is like this: the interquartile range is the
range spanned by the “middle half” of the data. That is, one quarter of the data falls below the
25th percentile and one quarter of the data is above the 75th percentile, leaving the “middle half”
of the data lying in between the two. And the IQR is the range covered by that middle
half.
</p>
   <h4 class="subsectionHead"><span class="titlemark">4.2.3   </span> <a 
 id="x27-780004.2.3"></a>Mean absolute deviation </h4>
<!--l. 234--><p class="noindent" >The two measures we’ve looked at so far, the range and the interquartile range, both rely
on the idea that we can measure the spread of the data by looking at the percentiles
of the data. However, this isn’t the only way to think about the problem. A diﬀerent
approach is to select a meaningful reference point (usually the mean or the median) and
then report the “typical” deviations from that reference point. What do we mean by
“typical” deviation? Usually, this is the mean or median value of these deviations. In
practice, this leads to two diﬀerent measures: the “mean absolute deviation” (from the
mean) and the “median absolute deviation” (from the median). From what I’ve read, the
measure based on the median seems to be used in statistics and does seem to be the better
of the two. But to be honest I don’t think I’ve seen it used much in psychology. The
measure based on the mean does occasionally show up in psychology though. In this
section I’ll talk about the ﬁrst one, and I’ll come back to talk about the second one
later.
</p><!--l. 236--><p class="indent" >   Since the previous paragraph might sound a little abstract, let’s go through the <span id="textcolor93">mean
absolute deviation</span> from the mean a little more slowly. One useful thing about this measure is
that the name actually tells you exactly how to calculate it. Let’s think about our AFL winning
margins data, and once again we’ll start by pretending that there are only 5 games in
total, with winning margins of 56, 31, 56, 8 and 32. Since our calculations rely on an
examination of the deviation from some reference point (in this case the mean), the
ﬁrst thing we need to calculate is the mean, <span class="bar-css">X</span>. For these ﬁve observations, our mean
is <span class="bar-css">X</span>   36.6. The next step is to convert each of our observations X<sub>i</sub> into a deviation
score. We do this by calculating the diﬀerence between the observation X<sub>i</sub> and the mean
<span class="bar-css">X</span>. That is, the deviation score is deﬁned to be X<sub>i</sub>   <span class="bar-css">X</span>. For the ﬁrst observation in
our sample, this is equal to 56   36.6   19.4. Okay, that’s simple enough. The next
step in the process is to convert these deviations to absolute deviations, and we do this
                                                                                          

                                                                                          
by converting any negative values to positive ones. Mathematically, we would denote
the absolute value of  3 as |   3|, and so we say that |   3|   3. We use the absolute
value here because we don’t really care whether the value is higher than the mean or
lower than the mean, we’re just interested in how close it is to the mean. To help make
this process as obvious as possible, the table below shows these calculations for all ﬁve
observations:
</p>
<div class="center" 
>
<!--l. 239--><p class="noindent" >
</p>
<div class="tabular"> <table id="TBL-14" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-14-1g"><col 
id="TBL-14-1" /><col 
id="TBL-14-2" /><col 
id="TBL-14-3" /><col 
id="TBL-14-4" /><col 
id="TBL-14-5" /></colgroup><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-14-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-1-1"  
class="td11">English:</td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-1-2"  
class="td11">which game</td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-1-3"  
class="td11">value</td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-1-4"  
class="td11">deviation from mean</td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-1-5"  
class="td11">absolute deviation</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-2-1"  
class="td11">notation:</td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-2-2"  
class="td11">         i</td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-2-3"  
class="td11">  X<sub>i</sub></td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-2-4"  
class="td11">           X<sub>i</sub>   <span class="bar-css">X</span></td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-2-5"  
class="td11">        |X<sub>i</sub>   <span class="bar-css">X</span>|</td>
</tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-14-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-3-1"  
class="td11">           </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-3-2"  
class="td11">         1</td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-3-3"  
class="td11">  56</td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-3-4"  
class="td11">              19.4</td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-3-5"  
class="td11">            19.4</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-4-1"  
class="td11">           </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-4-2"  
class="td11">         2</td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-4-3"  
class="td11">  31</td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-4-4"  
class="td11">              -5.6</td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-4-5"  
class="td11">             5.6</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-5-1"  
class="td11">           </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-5-2"  
class="td11">         3</td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-5-3"  
class="td11">  56</td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-5-4"  
class="td11">              19.4</td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-5-5"  
class="td11">            19.4</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-6-1"  
class="td11">           </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-6-2"  
class="td11">         4</td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-6-3"  
class="td11">   8</td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-6-4"  
class="td11">             -28.6</td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-6-5"  
class="td11">            28.6</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-14-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-7-1"  
class="td11">           </td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-7-2"  
class="td11">         5</td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-7-3"  
class="td11">  32</td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-7-4"  
class="td11">              -4.6</td><td  style="white-space:nowrap; text-align:right;" id="TBL-14-7-5"  
class="td11">             4.6</td>
</tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-14-8-"><td  style="white-space:nowrap; text-align:left;" id="TBL-14-8-1"  
class="td11">        </td></tr></table></div></div>
<!--l. 254--><p class="noindent" >Now that we have calculated the absolute deviation score for every observation in the data set, all
that we have to do to calculate the mean of these scores. Let’s do that:
</p><!--l. 257--><p class="indent" >
</p>
   <center class="math-display" >
<img 
src="lsj13x.png" alt="19.4----5.6----19.4----28.6----4.6
              5                  15.52
" class="math-display"  /></center>
<!--l. 261--><p class="noindent" >And we’re done. The mean absolute deviation for these ﬁve scores is 15.52.
</p><!--l. 266--><p class="indent" >   However, whilst our calculations for this little example are at an end, we do have a
couple of things left to talk about. First, we should really try to write down a proper
mathematical formula. But in order do to this I need some mathematical notation to refer
                                                                                          

                                                                                          
to the mean absolute deviation. Irritatingly, “mean absolute deviation” and “median
absolute deviation” have the same acronym (MAD), which leads to a certain amount of
ambiguity so I’d better come up with something diﬀerent for the mean absolute deviation.
Sigh. What I’ll do is use AAD instead, short for average absolute deviation. Now that
we have some unambiguous notation, here’s the formula that describes what we just
calculated:
</p>
   <center class="math-display" >
<img 
src="lsj14x.png" alt="                N
aadpXq      -1-   |X     X¯|
           N  i  1  i
" class="math-display"  /></center>
<!--l. 272--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">4.2.4   </span> <a 
 id="x27-790004.2.4"></a>Variance</h4>
<!--l. 274--><p class="noindent" >Although the average absolute deviation measure has its uses, it’s not the best measure of
variability to use. From a purely mathematical perspective there are some solid reasons to prefer
squared deviations rather than absolute deviations. If we do that we obtain a measure
called the <span id="textcolor94">variance</span>, which has a lot of really nice statistical properties that I’m going to
ignore,<span class="footnote-mark"><a 
href="lsj31.html#fn4x5"><sup class="textsuperscript">4</sup></a></span><a 
 id="x27-79001f4"></a> 
and one massive psychological ﬂaw that I’m going to make a big deal out of in a moment. The
variance of a data set X is sometimes written as VarpXq, but it’s more commonly denoted s<sup>2</sup> (the
reason for this will become clearer shortly).
                                                                                          

                                                                                          
</p><!--l. 278--><p class="indent" >   The formula that we use to calculate the variance of a set of observations is as follows:
</p>
   <center class="math-display" >
<img 
src="lsj15x.png" alt="             N
VarpXq     -1-     Xi    X¯  2
          N  i  1   " class="math-display"  /></center>
As you can see, it’s basically the same formula that we used to calculate the average
absolute deviation, except that instead of using “absolute deviations” we use “squared
deviations”. It is for this reason that the variance is sometimes referred to as the “mean square
deviation”.
<!--l. 286--><p class="indent" >   Now that we’ve got the basic idea, let’s have a look at a concrete example. Once again, let’s use
the ﬁrst ﬁve AFL games as our data. If we follow the same approach that we took last time, we end
up with the following table:
</p>
<div class="center" 
>
<!--l. 289--><p class="noindent" >
</p>
<div class="tabular"> <table id="TBL-15" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-15-1g"><col 
id="TBL-15-1" /><col 
id="TBL-15-2" /><col 
id="TBL-15-3" /><col 
id="TBL-15-4" /><col 
id="TBL-15-5" /></colgroup><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-15-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-1-1"  
class="td11">English:</td><td  style="white-space:nowrap; text-align:right;" id="TBL-15-1-2"  
class="td11">which game</td><td  style="white-space:nowrap; text-align:right;" id="TBL-15-1-3"  
class="td11">value</td><td  style="white-space:nowrap; text-align:right;" id="TBL-15-1-4"  
class="td11">deviation from mean</td><td  style="white-space:nowrap; text-align:right;" id="TBL-15-1-5"  
class="td11">squared deviation</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-15-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-2-1"  
class="td11">maths:   </td><td  style="white-space:nowrap; text-align:right;" id="TBL-15-2-2"  
class="td11">         i</td><td  style="white-space:nowrap; text-align:right;" id="TBL-15-2-3"  
class="td11">  X<sub>i</sub></td><td  style="white-space:nowrap; text-align:right;" id="TBL-15-2-4"  
class="td11">           X<sub>i</sub>   <span class="bar-css">X</span></td><td  style="white-space:nowrap; text-align:right;" id="TBL-15-2-5"  
class="td11">      pX<sub>i</sub>   <span class="bar-css">X</span>q<sup>2</sup></td>
</tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-15-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-3-1"  
class="td11">           </td><td  style="white-space:nowrap; text-align:right;" id="TBL-15-3-2"  
class="td11">         1</td><td  style="white-space:nowrap; text-align:right;" id="TBL-15-3-3"  
class="td11">  56</td><td  style="white-space:nowrap; text-align:right;" id="TBL-15-3-4"  
class="td11">              19.4</td><td  style="white-space:nowrap; text-align:right;" id="TBL-15-3-5"  
class="td11">         376.36</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-15-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-4-1"  
class="td11">           </td><td  style="white-space:nowrap; text-align:right;" id="TBL-15-4-2"  
class="td11">         2</td><td  style="white-space:nowrap; text-align:right;" id="TBL-15-4-3"  
class="td11">  31</td><td  style="white-space:nowrap; text-align:right;" id="TBL-15-4-4"  
class="td11">              -5.6</td><td  style="white-space:nowrap; text-align:right;" id="TBL-15-4-5"  
class="td11">          31.36</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-15-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-5-1"  
class="td11">           </td><td  style="white-space:nowrap; text-align:right;" id="TBL-15-5-2"  
class="td11">         3</td><td  style="white-space:nowrap; text-align:right;" id="TBL-15-5-3"  
class="td11">  56</td><td  style="white-space:nowrap; text-align:right;" id="TBL-15-5-4"  
class="td11">              19.4</td><td  style="white-space:nowrap; text-align:right;" id="TBL-15-5-5"  
class="td11">         376.36</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-15-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-6-1"  
class="td11">           </td><td  style="white-space:nowrap; text-align:right;" id="TBL-15-6-2"  
class="td11">         4</td><td  style="white-space:nowrap; text-align:right;" id="TBL-15-6-3"  
class="td11">   8</td><td  style="white-space:nowrap; text-align:right;" id="TBL-15-6-4"  
class="td11">             -28.6</td><td  style="white-space:nowrap; text-align:right;" id="TBL-15-6-5"  
class="td11">         817.96</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-15-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-7-1"  
class="td11">           </td><td  style="white-space:nowrap; text-align:right;" id="TBL-15-7-2"  
class="td11">         5</td><td  style="white-space:nowrap; text-align:right;" id="TBL-15-7-3"  
class="td11">  32</td><td  style="white-space:nowrap; text-align:right;" id="TBL-15-7-4"  
class="td11">              -4.6</td><td  style="white-space:nowrap; text-align:right;" id="TBL-15-7-5"  
class="td11">          21.16</td>
</tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-15-8-"><td  style="white-space:nowrap; text-align:left;" id="TBL-15-8-1"  
class="td11">       </td></tr></table></div></div>
<!--l. 304--><p class="indent" >   That last column contains all of our squared deviations, so all we have to do is average them. If
we do that by hand, i.e. using a calculator, we end up with a variance of 324.64. Exciting, isn’t it?
For the moment, let’s ignore the burning question that you’re all probably thinking (i.e., what the
heck does a variance of 324.64 actually mean?) and instead talk a bit more about how to do the
calculations in jamovi, because this will reveal something very weird. Start a new jamovi
session by clicking on the main menu button (three horizontal lines in the top left corner
and selecting ‘New’. Now type in the ﬁrst ﬁve values from the aﬂ.margins data set in
                                                                                          

                                                                                          
column A (56, 31, 56, 8, 32). Change the variable type to ‘Continuous’ and under
‘Descriptives’ click the ‘Variance’ check box, and you get the same values for variance as the
one we calculated by hand (324.64). No, wait, you get a completely diﬀerent answer
(405.80) - see Figure <a 
href="#x27-790029">4.9<!--tex4ht:ref: fig:aflsmall_margins_variance1 --></a>. That’s just weird. Is jamovi broken? Is this a typo? Am I an
idiot?
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x27-790029"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 308--><p class="noindent" >

</p><!--l. 309--><p class="noindent" ><img 
src="../img/descriptives/aflsmall_margins_variance1.png" alt="PIC"  
 />
<br /> </p><div class="caption" 
><span class="id">Figure 4.9:  </span><span  
class="content">A  screenshot  of  jamovi  showing  the  Variance  for  the  ﬁrst  5  values  of  the
afl.margins variable </span></div><!--tex4ht:label?: x27-790029 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 316--><p class="indent" >   As it happens, the answer is no.<span class="footnote-mark"><a 
href="lsj32.html#fn5x5"><sup class="textsuperscript">5</sup></a></span><a 
 id="x27-79003f5"></a> 
It’s not a typo, and jamovi is not making a mistake. In fact, it’s very simple to explain what jamovi
is doing here, but slightly trickier to explain why jamovi is doing it. So let’s start with the “what”.
What jamovi is doing is evaluating a slightly diﬀerent formula to the one I showed you above.
Instead of averaging the squared deviations, which requires you to divide by the number of data
points N, jamovi has chosen to divide by N   1.
</p><!--l. 320--><p class="indent" >   In other words, the formula that jamovi is using is this one:
</p>
   <center class="math-display" >
<img 
src="lsj16x.png" alt="       N
--1---             ¯  2
N     1     Xi    X
       i  1
" class="math-display"  /></center>
<!--l. 326--><p class="indent" >   So that’s the what. The real question is why jamovi is dividing by N   1 and not by N. After
all, the variance is supposed to be the mean squared deviation, right? So shouldn’t we be dividing
by N, the actual number of observations in the sample? Well, yes, we should. However, as we’ll
discuss in Chapter <a 
href="lsjch8.html#x58-1300008">8<!--tex4ht:ref: ch:estimation --></a>, there’s a subtle distinction between “describing a sample” and “making
guesses about the population from which the sample came”. Up to this point, it’s been a
distinction without a diﬀerence. Regardless of whether you’re describing a sample or drawing
inferences about the population, the mean is calculated exactly the same way. Not so for
the variance, or the standard deviation, or for many other measures besides. What I
outlined to you initially (i.e., take the actual average, and thus divide by N) assumes that
you literally intend to calculate the variance of the sample. Most of the time, however,
you’re not terribly interested in the sample in and of itself. Rather, the sample exists to
tell you something about the world. If so, you’re actually starting to move away from
calculating a “sample statistic” and towards the idea of estimating a “population parameter”.
However, I’m getting ahead of myself. For now, let’s just take it on faith that jamovi knows
what it’s doing, and we’ll revisit the question later on when we talk about estimation in
                                                                                          

                                                                                          
Chapter <a 
href="lsjch8.html#x58-1300008">8<!--tex4ht:ref: ch:estimation --></a>.
</p><!--l. 328--><p class="indent" >   Okay, one last thing. This section so far has read a bit like a mystery novel. I’ve
shown you how to calculate the variance, described the weird “N   1” thing that jamovi
does and hinted at the reason why it’s there, but I haven’t mentioned the single most
important thing. How do you interpret the variance? Descriptive statistics are supposed to
describe things, after all, and right now the variance is really just a gibberish number.
Unfortunately, the reason why I haven’t given you the human-friendly interpretation of
the variance is that there really isn’t one. This is the most serious problem with the
variance. Although it has some elegant mathematical properties that suggest that it
really is a fundamental quantity for expressing variation, it’s completely useless if you
want to communicate with an actual human. Variances are completely uninterpretable
in terms of the original variable! All the numbers have been squared and they don’t
mean anything anymore. This is a huge issue. For instance, according to the table I
presented earlier, the margin in game 1 was “376.36 points-squared higher than the average
margin”. This is exactly as stupid as it sounds, and so when we calculate a variance of
324.64 we’re in the same situation. I’ve watched a lot of footy games, and at no time has
anyone ever referred to “points squared”. It’s not a real unit of measurement, and since
the variance is expressed in terms of this gibberish unit, it is totally meaningless to a
human.
</p>
   <h4 class="subsectionHead"><span class="titlemark">4.2.5   </span> <a 
 id="x27-800004.2.5"></a>Standard deviation</h4>
<!--l. 332--><p class="noindent" >Okay, suppose that you like the idea of using the variance because of those nice mathematical
properties that I haven’t talked about, but since you’re a human and not a robot you’d like to have
a measure that is expressed in the same units as the data itself (i.e., points, not points-squared).
What should you do? The solution to the problem is obvious! Take the square root of the variance,
known as the <span id="textcolor97">standard deviation</span>, also called the “root mean squared deviation”, or RMSD. This
solves our problem fairly neatly. Whilst nobody has a clue what “a variance of 324.68
points-squared” really means, it’s much easier to understand “a standard deviation of
18.01 points” since it’s expressed in the original units. It is traditional to refer to the
standard deviation of a sample of data as s, though “sd” and “std dev.” are also used at
times.
</p><!--l. 336--><p class="indent" >   Because the standard deviation is equal to the square root of the variance, you probably won’t
be surprised to see that the formula is:
                                                                                          

                                                                                          
</p>
   <center class="math-display" >
<img 
src="lsj17x.png" alt="    g -----------------
    ff  1 N              2
s    e ---    Xi    X¯
      N  i  1   " class="math-display"  /></center> and
in jamovi there is a check box for ‘Std. deviation’ right above the check box for ‘Variance’. Selecting
this gives a value of 26.07 for the standard deviation.
<!--l. 343--><p class="indent" >   However, as you might have guessed from our discussion of the variance, what jamovi actually
calculates is slightly diﬀerent to the formula given above. Just like the we saw with
the variance, what jamovi calculates is a version that divides by N   1 rather than
N.
</p><!--l. 347--><p class="indent" >   For reasons that will make sense when we return to this topic in Chapter <a 
href="lsjch8.html#x58-1300008">8<!--tex4ht:ref: ch:estimation --></a> I’ll refer to this new
quantity as <img 
src="lsj18x.png" alt="ˆσ"  class="circ"  /> (read as: “sigma hat”), and the formula for this is:
</p>
   <center class="math-display" >
<img 
src="lsj19x.png" alt="     gf ---------------------
     fe    1     N            2
σˆ      N-- --1     Xi    X¯
              i  1
" class="math-display"  /></center>
<!--l. 354--><p class="indent" >   Interpreting standard deviations is slightly more complex. Because the standard deviation is
derived from the variance, and the variance is a quantity that has little to no meaning that makes
sense to us humans, the standard deviation doesn’t have a simple interpretation. As a consequence,
most of us just rely on a simple rule of thumb. In general, you should expect 68% of the data to
fall within 1 standard deviation of the mean, 95% of the data to fall within 2 standard
deviation of the mean, and 99.7% of the data to fall within 3 standard deviations of
the mean. This rule tends to work pretty well most of the time, but it’s not exact. It’s
                                                                                          

                                                                                          
actually calculated based on an assumption that the histogram is symmetric and “bell
shaped”.<span class="footnote-mark"><a 
href="lsj33.html#fn6x5"><sup class="textsuperscript">6</sup></a></span><a 
 id="x27-80001f6"></a> 
As you can tell from looking at the AFL winning margins histogram in Figure <a 
href="#x27-670032">4.2<!--tex4ht:ref: fig:histogram1 --></a>, this isn’t
exactly true of our data! Even so, the rule is approximately correct. As it turns out, 65.3% of the
AFL margins data fall within one standard deviation of the mean. This is shown visually in
Figure <a 
href="#x27-8000210">4.10<!--tex4ht:ref: fig:aflsd --></a>.
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x27-8000210"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 357--><p class="noindent" >
</p><!--l. 358--><p class="noindent" ><img 
src="lsj20x.png" alt="PIC" class="graphics" width="284" height="219"  /><!--tex4ht:graphics  
name="lsj20x.png" src="../img/descriptives/aflSD.eps"  
-->
<br /> </p><div class="caption" 
><span class="id">Figure 4.10: </span><span  
class="content">An illustration of the standard deviation from the AFL winning margins data.
The shaded bars in the histogram show how much of the data fall within one standard
deviation of the mean. In this case, 65.3% of the data set lies within this range, which is
pretty consistent with the “approximately 68% rule” discussed in the main text.</span></div><!--tex4ht:label?: x27-8000210 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
   <h4 class="subsectionHead"><span class="titlemark">4.2.6   </span> <a 
 id="x27-810004.2.6"></a>Which measure to use?</h4>
<!--l. 367--><p class="noindent" >We’ve discussed quite a few measures of spread: range, IQR, mean absolute deviation, variance
and standard deviation; and hinted at their strengths and weaknesses. Here’s a quick
summary:
</p>
      <ul class="itemize1">
      <li class="itemize">Range. Gives you the full spread of the data. It’s very vulnerable to outliers and as a
      consequence it isn’t often used unless you have good reasons to care about the extremes
      in the data.
      </li>
      <li class="itemize">Interquartile range. Tells you where the “middle half” of the data sits. It’s pretty robust
      and complements the median nicely. This is used a lot.
      </li>
      <li class="itemize">Mean absolute deviation. Tells you how far “on average” the observations are from the
      mean. It’s very interpretable but has a few minor issues (not discussed here) that make
      it less attractive to statisticians than the standard deviation. Used sometimes, but not
      often.
      </li>
      <li class="itemize">Variance. Tells you the average squared deviation from the mean. It’s mathematically
      elegant and is probably the “right” way to describe variation around the mean, but it’s
      completely uninterpretable because it doesn’t use the same units as the data. Almost
      never used except as a mathematical tool, but it’s buried “under the hood” of a very
      large number of statistical tools.
      </li>
      <li class="itemize">Standard  deviation.  This  is  the  square  root  of  the  variance.  It’s  fairly  elegant
      mathematically and it’s expressed in the same units as the data so it can be interpreted
      pretty well. In situations where the mean is the measure of central tendency, this is the
      default. This is by far the most popular measure of variation.</li></ul>
<!--l. 377--><p class="noindent" >In short, the IQR and the standard deviation are easily the two most common measures used to
report the variability of the data. But there are situations in which the others are used. I’ve
described all of them in this book because there’s a fair chance you’ll run into most of these
                                                                                          

                                                                                          
somewhere.
</p><!--l. 380--><p class="noindent" >
</p>
   <h3 class="sectionHead"><span class="titlemark">4.3   </span> <a 
 id="x27-820004.3"></a>Skew and kurtosis </h3>
<!--l. 382--><p class="noindent" >There are two more descriptive statistics that you will sometimes see reported in the psychological
literature: skew and kurtosis. In practice, neither one is used anywhere near as frequently as the
measures of central tendency and variability that we’ve been talking about. Skew is pretty
important, so you do see it mentioned a fair bit, but I’ve actually never seen kurtosis reported in a
scientiﬁc article to date.
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x27-8200111"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 385--><p class="noindent" >
</p><!--l. 386--><p class="noindent" ><img 
src="lsj21x.png" alt="PIC" class="graphics" width="398" height="153"  /><!--tex4ht:graphics  
name="lsj21x.png" src="../img/descriptives/skewness.eps"  
-->
<br /> </p><div class="caption" 
><span class="id">Figure 4.11: </span><span  
class="content">An illustration of skewness. On the left we have a negatively skewed data set
(skewness    .93), in the middle we have a data set with no skew (well, hardly any: skewness
   .006), and on the right we have a positively skewed data set (skewness   .93). </span></div><!--tex4ht:label?: x27-8200111 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 393--><p class="indent" >   Since it’s the more interesting of the two, let’s start by talking about the <span id="textcolor99">skewness</span>. Skewness is
basically a measure of asymmetry and the easiest way to explain it is by drawing some
pictures. As Figure <a 
href="#x27-8200111">4.11<!--tex4ht:ref: fig:skewness --></a> illustrates, if the data tend to have a lot of extreme small values
(i.e., the lower tail is “longer” than the upper tail) and not so many extremely large
values (left panel) then we say that the data are negatively skewed. On the other hand,
if there are more extremely large values than extremely small ones (right panel) we
say that the data are positively skewed. That’s the qualitative idea behind skewness. If
there are relatively more values that are far greater than the mean, the distribution is
positively skewed or right skewed, with a tail stretching to the right. Negative or left skew is
the opposite. A symmetric distribution has a skewness of 0. The skewness value for a
positively skewed distribution is positive, and a negative value for a negatively skewed
distribution.
</p><!--l. 397--><p class="indent" >   One formula for the skewness of a data set is as follows
</p>
   <center class="math-display" >
<img 
src="lsj22x.png" alt="                     N
skewnesspXq      -1---  pXi     ¯Xq3
                N ˆσ3 i  1   " class="math-display"  /></center>
where N is the number of observations, <span class="bar-css">X</span> is the sample mean, and <img 
src="lsj23x.png" alt="σˆ"  class="circ"  /> is the standard deviation (the
“divide by N   1” version, that is).
<!--l. 404--><p class="indent" >   Perhaps more helpfully, you can use jamovi to calculate skewness: it’s a check box in the
‘Statistics’ options under ‘Exploration’ - ‘Descriptives’. For the afl.margins variable, the skewness
ﬁgure is 0.780. If you divide the skewness estimate by the Std. error for skewness you have an
indication of how skewed the data is. Especially in small samples (N¡50), one rule of thumb suggests
that a value of 2 or less can mean that the data is not very skewed, and a value of over
2 that there is suﬃcient skew in the data to possibly limit its use in some statistical
analyses. Though there is no clear agreement on this interpretation. That said, this does
indicate that the AFL winning margins data is somewhat skewed (0.780 / 0.183 =
4.262).
</p><!--l. 406--><p class="indent" >   The ﬁnal measure that is sometimes referred to, though very rarely in practice, is
                                                                                          

                                                                                          
the <span id="textcolor100">kurtosis</span> of a data set. Put simply, kurtosis is a measure of the “pointiness” of a
data set, as illustrated in Figure <a 
href="#x27-8200212">4.12<!--tex4ht:ref: fig:kurtosis --></a>. By convention, we say that the “normal curve”
(black lines) has zero kurtosis, so the pointiness of a data set is assessed relative to this
curve.
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x27-8200212"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 409--><p class="noindent" >
</p><!--l. 410--><p class="noindent" ><img 
src="lsj24x.png" alt="PIC" class="graphics" width="398" height="153"  /><!--tex4ht:graphics  
name="lsj24x.png" src="../img/descriptives/kurtosis.eps"  
-->
<br /> </p><div class="caption" 
><span class="id">Figure 4.12: </span><span  
class="content">An illustration of kurtosis. On the left, we have a “platykurtic” data set (kurtosis
=  .95) meaning that the data set is “too ﬂat”. In the middle we have a “mesokurtic” data
set (kurtosis is almost exactly 0) which means that the pointiness of the data is just about
right. Finally, on the right, we have a “leptokurtic” data set (kurtosis   2.12) indicating that
the data set is “too pointy”. Note that kurtosis is measured with respect to a normal curve
(black line).</span></div><!--tex4ht:label?: x27-8200212 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 417--><p class="indent" >   In this Figure, the data on the left are not pointy enough, so the kurtosis is negative and we call
the data platykurtic. The data on the right are too pointy, so the kurtosis is positive and we
say that the data is leptokurtic. But the data in the middle are just pointy enough,
so we say that it is mesokurtic and has kurtosis zero. This is summarised in the table
below:
</p>
<div class="center" 
>
<!--l. 419--><p class="noindent" >
</p>
<div class="tabular"> <table id="TBL-16" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-16-1g"><col 
id="TBL-16-1" /><col 
id="TBL-16-2" /><col 
id="TBL-16-3" /></colgroup><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-16-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-16-1-1"  
class="td11">informal term         </td><td  style="white-space:nowrap; text-align:left;" id="TBL-16-1-2"  
class="td11">technical name</td><td  style="white-space:nowrap; text-align:left;" id="TBL-16-1-3"  
class="td11">kurtosis value</td></tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-16-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-16-2-1"  
class="td11">“too ﬂat” </td><td  style="white-space:nowrap; text-align:left;" id="TBL-16-2-2"  
class="td11">platykurtic </td><td  style="white-space:nowrap; text-align:left;" id="TBL-16-2-3"  
class="td11">negative</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-16-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-16-3-1"  
class="td11">“just pointy enough”</td><td  style="white-space:nowrap; text-align:left;" id="TBL-16-3-2"  
class="td11">mesokurtic     </td><td  style="white-space:nowrap; text-align:left;" id="TBL-16-3-3"  
class="td11">zero             </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-16-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-16-4-1"  
class="td11">“too pointy”           </td><td  style="white-space:nowrap; text-align:left;" id="TBL-16-4-2"  
class="td11">leptokurtic     </td><td  style="white-space:nowrap; text-align:left;" id="TBL-16-4-3"  
class="td11">positive        </td>
</tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-16-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-16-5-1"  
class="td11">                  </td></tr></table></div></div>
<!--l. 433--><p class="indent" >   The equation for kurtosis is pretty similar in spirit to the formulas we’ve seen already for the
variance and the skewness. Except that where the variance involved squared deviations and the
skewness involved cubed deviations, the kurtosis involves raising the deviations to the fourth
power:<span class="footnote-mark"><a 
href="lsj34.html#fn7x5"><sup class="textsuperscript">7</sup></a></span><a 
 id="x27-82003f7"></a> 
</p>
   <center class="math-display" >
<img 
src="lsj25x.png" alt="                 1    N            4
kurtosispXq     ----4    Xi    X¯      3
               N ˆσ  i  1  " class="math-display"  /></center> I
know, it’s not terribly interesting to me either.
                                                                                          

                                                                                          
<!--l. 440--><p class="indent" >   More to the point, jamovi has a check box for kurtosis just below the check box for skewness,
and this gives a value for kurtosis of 0.101 with a standard error of 0.364. This means that the
AFL winning margins data are just pointy enough.
</p>
   <h3 class="sectionHead"><span class="titlemark">4.4   </span> <a 
 id="x27-830004.4"></a>Descriptive statistics separately for each group </h3>
<!--l. 445--><p class="noindent" >It is very commonly the case that you ﬁnd yourself needing to look at descriptive statistics broken
down by some grouping variable. This is pretty easy to do in jamovi. For instance, let’s say I want
to look at the descriptive statistics for some clin.trial data, broken down separately by therapy
type. This is a new data set, one that you’ve never seen before. The data is stored in the
clinicaltrial.csv ﬁle and we’ll use it a lot in Chapter <a 
href="lsjch13.html#x131-28000013">13<!--tex4ht:ref: ch:anova --></a> (you can ﬁnd a complete
description of the data at the start of that chapter). Let’s load it and see what we’ve
got:
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x27-8300113"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 449--><p class="noindent" >

</p><!--l. 450--><p class="noindent" ><img 
src="../img/descriptives/clinicaltrial.png" alt="PIC"  
 />
<br /> </p><div class="caption" 
><span class="id">Figure 4.13: </span><span  
class="content">A screenshot of jamovi showing the variables stored in the clinicaltrial.csv
ﬁle</span></div><!--tex4ht:label?: x27-8300113 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 457--><p class="indent" >   Evidently there were three drugs: a placebo, something called “anxifree” and something called
“joyzepam”, and there were 6 people administered each drug. There were 9 people treated using
cognitive behavioural therapy (CBT) and 9 people who received no psychological treatment. And
we can see from looking at the ‘Descriptives’ of the mood.gain variable that most people did show
a mood gain (mean   0.88), though without knowing what the scale is here it’s hard to say much
more than that. Still, that’s not too bad. Overall I feel that I learned something from
that.
</p><!--l. 459--><p class="indent" >   We can also go ahead and look at some other descriptive statistics, and this time separately for
each type of therapy. In jamovi, check Std. deviation, Skewness and Kurtosis in the ‘Statistics’
options. At the same time, transfer the therapy variable into the ‘Split by’ box, and you should get
something like Figure <a 
href="#x27-8300214">4.14<!--tex4ht:ref: fig:clinicaltrial_grouping --></a>
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x27-8300214"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 463--><p class="noindent" >

</p><!--l. 464--><p class="noindent" ><img 
src="../img/descriptives/clinicaltrial_grouping.png" alt="PIC"  
 />
<br /> </p><div class="caption" 
><span class="id">Figure 4.14: </span><span  
class="content">A screenshot of jamovi showing Descriptives split by therapy type</span></div><!--tex4ht:label?: x27-8300214 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 471--><p class="indent" >   What if you have multiple grouping variables? Suppose you want to look at the average mood
gain separately for all possible combinations of drug and therapy. It is possible to do this by
adding another variable, drug, into the ‘Split by’ box. Easy peasy, though sometimes if
you split too much there isn’t enough data in each breakdown combination to make
meaningful calculations. In this case jamovi tells you this by stating something like NaN or
Inf.<span class="footnote-mark"><a 
href="lsj35.html#fn8x5"><sup class="textsuperscript">8</sup></a></span><a 
 id="x27-83003f8"></a> 
</p>
   <h3 class="sectionHead"><span class="titlemark">4.5   </span> <a 
 id="x27-840004.5"></a>Standard scores </h3>
<!--l. 476--><p class="noindent" >Suppose my friend is putting together a new questionnaire intended to measure “grumpiness”. The
survey has 50 questions which you can answer in a grumpy way or not. Across a big sample
(hypothetically, let’s imagine a million people or so!) the data are fairly normally distributed, with
the mean grumpiness score being 17 out of 50 questions answered in a grumpy way,
and the standard deviation is 5. In contrast, when I take the questionnaire I answer 35
out of 50 questions in a grumpy way. So, how grumpy am I? One way to think about
it would be to say that I have grumpiness of 35/50, so you might say that I’m 70%
grumpy. But that’s a bit weird, when you think about it. If my friend had phrased her
questions a bit diﬀerently people might have answered them in a diﬀerent way, so the overall
distribution of answers could easily move up or down depending on the precise way in
which the questions were asked. So, I’m only 70% grumpy with respect to this set of
survey questions. Even if it’s a very good questionnaire this isn’t very a informative
statement.
</p><!--l. 478--><p class="indent" >   A simpler way around this is to describe my grumpiness by comparing me to other
people. Shockingly, out of my friend’s sample of 1,000,000 people, only 159 people were as
grumpy as me (that’s not at all unrealistic, frankly) suggesting that I’m in the top 0.016%
of people for grumpiness. This makes much more sense than trying to interpret the
raw data. This idea, that we should describe my grumpiness in terms of the overall
distribution of the grumpiness of humans, is the qualitative idea that standardisation attempts
to get at. One way to do this is to do exactly what I just did and describe everything
in terms of percentiles. However, the problem with doing this is that “it’s lonely at
                                                                                          

                                                                                          
the top”. Suppose that my friend had only collected a sample of 1000 people (still a
pretty big sample for the purposes of testing a new questionnaire, I’d like to add), and
this time gotten, let’s say, a mean of 16 out of 50 with a standard deviation of 5. The
problem is that almost certainly not a single person in that sample would be as grumpy as
me.
</p><!--l. 480--><p class="indent" >   However, all is not lost. A diﬀerent approach is to convert my grumpiness score into a <span id="textcolor103">standard
score</span>, also referred to as a z-score. The standard score is deﬁned as the number of standard
deviations above the mean that my grumpiness score lies. To phrase it in “pseudo-maths” the
standard score is calculated like this:
</p>
   <center class="math-display" >
<img 
src="lsj26x.png" alt="standard score     raw-score----mean--
                 standard  deviation
" class="math-display"  /></center>
<!--l. 487--><p class="indent" >   In actual maths, the equation for the z-score is
</p>
   <center class="math-display" >
<img 
src="lsj27x.png" alt="     Xi    ¯X
zi    --------
       σˆ
" class="math-display"  /></center>
<!--l. 493--><p class="indent" >   So, going back to the grumpiness data, we can now transform Dani’s raw grumpiness into a
standardised grumpiness score.
                                                                                          

                                                                                          
</p>
   <center class="math-display" >
<img 
src="lsj28x.png" alt="z    35----17-    3.6
       5  " class="math-display"  /></center> To
interpret this value, recall the rough heuristic that I provided in Section <a 
href="#x27-800004.2.5">4.2.5<!--tex4ht:ref: sec:sd --></a> in which I noted that
99.7% of values are expected to lie within 3 standard deviations of the mean. So the fact
that my grumpiness corresponds to a z score of 3.6 indicates that I’m very grumpy
indeed. In fact this suggests that I’m grumpier than 99.98% of people. Sounds about
right.
<!--l. 499--><p class="indent" >   In addition to allowing you to interpret a raw score in relation to a larger population (and
thereby allowing you to make sense of variables that lie on arbitrary scales), standard scores serve a
second useful function. Standard scores can be compared to one another in situations where the
raw scores can’t. Suppose, for instance, my friend also had another questionnaire that measured
extraversion using a 24 item questionnaire. The overall mean for this measure turns out to be 13
with standard deviation 4, and I scored a 2. As you can imagine, it doesn’t make a lot
of sense to try to compare my raw score of 2 on the extraversion questionnaire to my
raw score of 35 on the grumpiness questionnaire. The raw scores for the two variables
are “about” fundamentally diﬀerent things, so this would be like comparing apples to
oranges.
</p><!--l. 501--><p class="indent" >   What about the standard scores? Well, this is a little diﬀerent. If we
calculate the standard scores we get z   p35   17q{5   3.6 for grumpiness and
z   p2   13q{4    2.75 for extraversion. These two numbers can be compared to each
other.<span class="footnote-mark"><a 
href="lsj36.html#fn9x5"><sup class="textsuperscript">9</sup></a></span><a 
 id="x27-84001f9"></a> 
I’m much less extraverted than most people (z    2.75) and much grumpier than most people
(z   3.6). But the extent of my unusualness is much more extreme for grumpiness, since 3.6 is a
bigger number than 2.75. Because each standardised score is a statement about where an
observation falls relative to its own population, it <span class="underline">is</span> possible to compare standardised scores across
completely diﬀerent variables.
                                                                                          

                                                                                          
</p>
   <h3 class="sectionHead"><span class="titlemark">4.6   </span> <a 
 id="x27-850004.6"></a>Summary</h3>
<!--l. 506--><p class="noindent" >Calculating some basic descriptive statistics is one of the very ﬁrst things you do when analysing
real data, and descriptive statistics are much simpler to understand than inferential statistics, so
like every other statistics textbook I’ve started with descriptives. In this chapter, we talked about
the following topics:
</p>
      <ul class="itemize1">
      <li class="itemize">Measures of central tendency. Broadly speaking, central tendency measures tell you
      where the data are. There’s three measures that are typically reported in the literature:
      the mean, median and mode. (Section <a 
href="#x27-680004.1">4.1<!--tex4ht:ref: sec:centraltendency --></a>)
      </li>
      <li class="itemize">Measures of variability. In contrast, measures of variability tell you about how “spread
      out” the data are. The key measures are: range, standard deviation, and interquartile
      range. (Section <a 
href="#x27-750004.2">4.2<!--tex4ht:ref: sec:var --></a>)
      </li>
      <li class="itemize">Measures  of  skewness  and  kurtosis.  We  also  looked  at  assymetry  in  a  variable’s
      distribution (skew) and pointness (kurtosis). (Section <a 
href="#x27-820004.3">4.3<!--tex4ht:ref: sec:skewkurt --></a>)
      </li>
      <li class="itemize">Getting group summaries of variables in jamovi. Since this book focuses on doing data
      analysis in jamovi, we spent a bit of time talking about how descriptive statistics are
      computed for diﬀerent subgroups. (Section <a 
href="#x27-830004.4">4.4<!--tex4ht:ref: sec:groupdescriptives --></a>)
      </li>
      <li class="itemize">Standard scores. The z-score is a slightly unusual beast. It’s not quite a descriptive
      statistic, and not quite an inference. We talked about it in Section <a 
href="#x27-840004.5">4.5<!--tex4ht:ref: sec:zscore --></a>. Make sure you
      understand that section. It’ll come up again later.</li></ul>
<!--l. 515--><p class="noindent" >In the next Chapter we’ll move on to a discussion of how to draw pictures! Everyone loves a pretty
picture, right? But before we do, I want to end on an important point. A traditional ﬁrst
course in statistics spends only a small proportion of the class on descriptive statistics,
maybe one or two lectures at most. The vast majority of the lecturer’s time is spent on
inferential statistics because that’s where all the hard stuﬀ is. That makes sense, but it
hides the practical everyday importance of choosing good descriptives. With that in
mind…
                                                                                          

                                                                                          
</p><!--l. 517--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">4.6.1   </span> <a 
 id="x27-860004.6.1"></a>Epilogue: Good descriptive statistics are descriptive!</h4>
<!--l. 519--><p class="noindent" >
      </p><div class="quote">
      <!--l. 520--><p class="noindent" >The death of one man is a tragedy.<br 
class="newline" />The death of millions is a statistic. <br 
class="newline" />                    – Josef Stalin, Potsdam 1945</p></div>
<!--l. 524--><p class="noindent" >
      </p><div class="quote">
      <!--l. 525--><p class="noindent" >950,000 – 1,200,000 <br 
class="newline" />                    – Estimate of Soviet repression deaths, <br 
class="newline" />                       1937-1938 (Ellman 2002)</p></div>
<!--l. 531--><p class="noindent" >Stalin’s infamous quote about the statistical character of the deaths of millions is worth giving
some thought. The clear intent of his statement is that the death of an individual touches us
personally and its force cannot be denied, but that the deaths of a multitude are incomprehensible
and as a consequence are mere statistics and more easily ignored. I’d argue that Stalin was
half right. A statistic is an abstraction, a description of events beyond our personal
experience, and so hard to visualise. Few if any of us can imagine what the deaths of
millions is “really” like, but we can imagine one death and this gives the lone death its
feeling of immediate tragedy, a feeling that is missing from Ellman’s cold statistical
description.
</p><!--l. 533--><p class="indent" >   Yet it is not so simple. Without numbers, without counts, without a description of what
happened, we have no chance of understanding what really happened, no opportunity even to try
to summon the missing feeling. And in truth, as I write this sitting in comfort on a Saturday
morning half a world and a whole lifetime away from the Gulags, when I put the Ellman estimate
next to the Stalin quote a dull dread settles in my stomach and a chill settles over me. The
Stalinist repression is something truly beyond my experience, but with a combination of
statistical data and those recorded personal histories that have come down to us, it
is not entirely beyond my comprehension. Because what Ellman’s numbers tell us is
this: over a two year period Stalinist repression wiped out the equivalent of every man,
woman and child currently alive in the city where I live. Each one of those deaths had it’s
own story, was it’s own tragedy, and only some of those are known to us now. Even
so, with a few carefully chosen statistics, the scale of the atrocity starts to come into
focus.
                                                                                          

                                                                                          
</p><!--l. 535--><p class="indent" >   Thus it is no small thing to say that the ﬁrst task of the statistician and the scientist is to
summarise the data, to ﬁnd some collection of numbers that can convey to an audience a sense of
what has happened. This is the job of descriptive statistics, but it’s not a job that can be told
solely using the numbers. You are a data analyst, and not a statistical software package. Part of
your job is to take these statistics and turn them into a description. When you analyse
data it is not suﬃcient to list oﬀ a collection of numbers. Always remember that what
you’re really trying to do is communicate with a human audience. The numbers are
important, but they need to be put together into a meaningful story that your audience
can interpret. That means you need to think about framing. You need to think about
context. And you need to think about the individual events that your statistics are
summarising.
                                                                                          

                                                                                          
</p>
   <!--l. 6--><div class="crosslinks"><p class="noindent">[<a 
href="lsjch5.html" >next</a>] [<a 
href="lsjch4.html" >front</a>] [<a 
href="lsjpa3.html#lsjch4.html" >up</a>] </p></div>
<!--l. 6--><p class="indent" >   <a 
 id="taillsjch4.html"></a>   </p> 
</body></html> 
