<?xml version="1.0" encoding=""utf-8"" ?> 
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" 
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">  
<!--http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd-->  
<html xmlns="http://www.w3.org/1999/xhtml"  
> 
<head><title>1 Why do we learn statistics? </title> 
<meta http-equiv="Content-Type" content="text/html; charset="utf-8"" /> 
<meta name="generator" content="TeX4ht (http://www.tug.org/tex4ht/)" /> 
<meta name="originator" content="TeX4ht (http://www.tug.org/tex4ht/)" /> 
<!-- 2,html,xhtml,NoFonts,ext=htm,charset="utf-8" --> 
<meta name="src" content="lsj.tex" /> 
<link rel="stylesheet" type="text/css" href="lsj.css" /> 
</head><body 
>
   <!--l. 5--><div class="crosslinks"><p class="noindent">[<a 
href="lsjch2.html" >next</a>] [<a 
href="#taillsjch1.html">tail</a>] [<a 
href="lsjpa1.html#lsjch1.html" >up</a>] </p></div>
   <h2 class="chapterHead"><span class="titlemark">Chapter 1</span><br /><a 
 id="x4-30001"></a>Why do we learn statistics? </h2>
      <div class="quote">
      <!--l. 8--><p class="noindent" >“Thou shalt not answer questionnaires <br 
class="newline" />Or quizzes upon World Aﬀairs, <br 
class="newline" />     Nor with compliance <br 
class="newline" />Take any test. Thou shalt not sit <br 
class="newline" />With statisticians nor commit <br 
class="newline" />     A social science” <br 
class="newline" />                   – W.H. Auden<span class="footnote-mark"><a 
href="http://harvardmagazine.com/2007/11/a-poets-warning.html" title="The quote comes from Auden’s 1946 poem Under Which Lyre: A Reactionary Tract for the Times, delivered as part of a commencement address at Harvard University. The history of the poem is kind of interesting. Click to open the link."><sup class="textsuperscript">*</sup></a></span></p></div>

   <h3 class="sectionHead"><span class="titlemark">1.1   </span> <a 
 id="x4-40001.1"></a>On the psychology of statistics </h3>
                                                                                          

                                                                                          
<!--l. 20--><p class="noindent" >To the surprise of many students, statistics is a fairly signiﬁcant part of a psychological
education. To the surprise of no-one, statistics is very rarely the favourite part of one’s
psychological education. After all, if you really loved the idea of doing statistics, you’d probably
be enrolled in a statistics class right now, not a psychology class. So, not surprisingly,
there’s a pretty large proportion of the student base that isn’t happy about the fact that
psychology has so much statistics in it. In view of this, I thought that the right place to
start might be to answer some of the more common questions that people have about
stats.
</p><!--l. 22--><p class="indent" >   A big part of this issue at hand relates to the very idea of statistics. What is it? What’s it there
for? And why are scientists so bloody obsessed with it? These are all good questions, when
you think about it. So let’s start with the last one. As a group, scientists seem to be
bizarrely ﬁxated on running statistical tests on everything. In fact, we use statistics so often
that we sometimes forget to explain to people why we do. It’s a kind of article of faith
among scientists – and especially social scientists – that your ﬁndings can’t be trusted
until you’ve done some stats. Undergraduate students might be forgiven for thinking
that we’re all completely mad, because no-one takes the time to answer one very simple
question:
      </p><div class="quote">
      <!--l. 24--><p class="noindent" >Why do you do statistics? Why don’t scientists just use <span class="underline">common sense</span>?</p></div>
<!--l. 26--><p class="noindent" >It’s a naive question in some ways, but most good questions are. There’s a lot of good answers to
it,<span class="footnote-mark"><a 
href="lsj6.html#fn2x2"><sup class="textsuperscript">2</sup></a></span><a 
 id="x4-4001f2"></a>  but
for my money, the best answer is a really simple one: we don’t trust ourselves enough. We worry
that we’re human, and susceptible to all of the biases, temptations and frailties that humans suﬀer
from. Much of statistics is basically a safeguard. Using “common sense” to evaluate evidence means
trusting gut instincts, relying on verbal arguments and on using the raw power of human reason to
come up with the right answer. Most scientists don’t think this approach is likely to
work.
</p><!--l. 28--><p class="indent" >   In fact, come to think of it, this sounds a lot like a psychological question to me, and since I do
work in a psychology department, it seems like a good idea to dig a little deeper here. Is it
really plausible to think that this “common sense” approach is very trustworthy? Verbal
arguments have to be constructed in language, and all languages have biases – some
things are harder to say than others, and not necessarily because they’re false (e.g.,
quantum electrodynamics is a good theory, but hard to explain in words). The instincts of
our “gut” aren’t designed to solve scientiﬁc problems, they’re designed to handle day
                                                                                          

                                                                                          
to day inferences – and given that biological evolution is slower than cultural change,
we should say that they’re designed to solve the day to day problems for a diﬀerent
world than the one we live in. Most fundamentally, reasoning sensibly requires people to
engage in “induction”, making wise guesses and going beyond the immediate evidence
of the senses to make generalisations about the world. If you think that you can do
that without being inﬂuenced by various distractors, well, I have a bridge in London
I’d like to sell you. Heck, as the next section shows, we can’t even solve “deductive”
problems (ones where no guessing is required) without being inﬂuenced by our pre-existing
biases.
</p>
   <h4 class="subsectionHead"><span class="titlemark">1.1.1   </span> <a 
 id="x4-50001.1.1"></a>The curse of belief bias</h4>
<!--l. 32--><p class="noindent" >People are mostly pretty smart. We’re certainly smarter than the other species that we share the
planet with (though many people might disagree). Our minds are quite amazing things, and we
seem to be capable of the most incredible feats of thought and reason. That doesn’t make us
perfect though. And among the many things that psychologists have shown over the years is that
we really do ﬁnd it hard to be neutral, to evaluate evidence impartially and without being swayed
by pre-existing biases. A good example of this is the <span id="textcolor3">belief bias eﬀect</span> in logical reasoning: if you
ask people to decide whether a particular argument is logically valid (i.e., conclusion would be true
if the premises were true), we tend to be inﬂuenced by the believability of the conclusion,
even when we shouldn’t. For instance, here’s a valid argument where the conclusion is
believable:
      </p><div class="quote">
      <!--l. 34--><p class="noindent" >All cigarettes are expensive (Premise 1) <br 
class="newline" />Some addictive things are inexpensive (Premise 2)<br 
class="newline" />Therefore, some addictive things are not cigarettes (Conclusion)</p></div>
<!--l. 38--><p class="noindent" >And here’s a valid argument where the conclusion is not believable:
      </p><div class="quote">
      <!--l. 40--><p class="noindent" >All addictive things are expensive (Premise 1)<br 
class="newline" />Some cigarettes are inexpensive (Premise 2)<br 
class="newline" />Therefore, some cigarettes are not addictive (Conclusion)</p></div>
<!--l. 44--><p class="noindent" >The logical structure of argument #2 is identical to the structure of argument #1, and they’re both
                                                                                          

                                                                                          
valid. However, in the second argument, there are good reasons to think that premise 1 is incorrect,
and as a result it’s probably the case that the conclusion is also incorrect. But that’s entirely
irrelevant to the topic at hand; an argument is deductively valid if the conclusion is a logical
consequence of the premises. That is, a valid argument doesn’t have to involve true
statements.
</p><!--l. 46--><p class="indent" >   On the other hand, here’s an invalid argument that has a believable conclusion:
      </p><div class="quote">
      <!--l. 48--><p class="noindent" >All addictive things are expensive (Premise 1)<br 
class="newline" />Some cigarettes are inexpensive (Premise 2)<br 
class="newline" />Therefore, some addictive things are not cigarettes (Conclusion)</p></div>
<!--l. 52--><p class="noindent" >And ﬁnally, an invalid argument with an unbelievable conclusion:
      </p><div class="quote">
      <!--l. 54--><p class="noindent" >All cigarettes are expensive (Premise 1)<br 
class="newline" />Some addictive things are inexpensive (Premise 2)<br 
class="newline" />Therefore, some cigarettes are not addictive (Conclusion)</p></div>
<!--l. 58--><p class="noindent" >Now, suppose that people really are perfectly able to set aside their pre-existing biases about what is
true and what isn’t, and purely evaluate an argument on its logical merits. We’d expect 100% of
people to say that the valid arguments are valid, and 0% of people to say that the invalid
arguments are valid. So if you ran an experiment looking at this, you’d expect to see data like
this:
</p>
<div class="center" 
>
<!--l. 60--><p class="noindent" >
</p>
<div class="tabular"> <table id="TBL-3" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-3-1g"><col 
id="TBL-3-1" /><col 
id="TBL-3-2" /><col 
id="TBL-3-3" /></colgroup><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-3-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-3-1-1"  
class="td11">                        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-3-1-2"  
class="td11">conclusion feels true</td><td  style="white-space:nowrap; text-align:center;" id="TBL-3-1-3"  
class="td11">conclusion feels false</td></tr><tr 
class="cline"><td></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-3-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-3-3-1"  
class="td11">argument is valid  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-3-3-2"  
class="td11"> 100% say “valid”  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-3-3-3"  
class="td11"> 100% say “valid”  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-3-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-3-4-1"  
class="td11">argument is invalid</td><td  style="white-space:nowrap; text-align:center;" id="TBL-3-4-2"  
class="td11">  0% say “valid”    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-3-4-3"  
class="td11">  0% say “valid”    </td>
</tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-3-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-3-5-1"  
class="td11">                </td></tr></table></div></div>
<!--l. 71--><p class="noindent" >If the psychological data looked like this (or even a good approximation to this), we might feel safe
in just trusting our gut instincts. That is, it’d be perfectly okay just to let scientists evaluate
data based on their common sense, and not bother with all this murky statistics stuﬀ.
However, you guys have taken psych classes, and by now you probably know where this is
going.
                                                                                          

                                                                                          
</p><!--l. 74--><p class="indent" >   In a classic study, Evans, Barston, and Pollard (1983) ran an experiment looking at exactly this.
What they found is that when pre-existing biases (i.e., beliefs) were in agreement with the
structure of the data, everything went the way you’d hope: </p>
<div class="center" 
>
<!--l. 75--><p class="noindent" >
</p>
<div class="tabular"> <table id="TBL-4" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-4-1g"><col 
id="TBL-4-1" /><col 
id="TBL-4-2" /><col 
id="TBL-4-3" /></colgroup><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-4-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-4-1-1"  
class="td11">                        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-1-2"  
class="td11">conclusion feels true</td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-1-3"  
class="td11">conclusion feels false</td></tr><tr 
class="cline"><td></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-4-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-4-3-1"  
class="td11">argument is valid  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-3-2"  
class="td11">  92% say “valid”   </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-3-3"  
class="td11">                      </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-4-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-4-4-1"  
class="td11">argument is invalid</td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-4-2"  
class="td11">                     </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-4-3"  
class="td11">  8% say “valid”    </td>
</tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-4-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-4-5-1"  
class="td11">                </td></tr></table></div></div>
<!--l. 85--><p class="noindent" >Not perfect, but that’s pretty good. But look what happens when our intuitive feelings
about the truth of the conclusion run against the logical structure of the argument:
</p>
<div class="center" 
>
<!--l. 86--><p class="noindent" >
</p>
<div class="tabular"> <table id="TBL-5" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-5-1g"><col 
id="TBL-5-1" /><col 
id="TBL-5-2" /><col 
id="TBL-5-3" /></colgroup><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-5-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-5-1-1"  
class="td11">                        </td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-1-2"  
class="td11">conclusion feels true</td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-1-3"  
class="td11">conclusion feels false</td></tr><tr 
class="cline"><td></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-5-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-5-3-1"  
class="td11">argument is valid  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-3-2"  
class="td11">  92% say “valid”   </td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-3-3"  
class="td11"> 46% say “valid” </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-5-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-5-4-1"  
class="td11">argument is invalid</td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-4-2"  
class="td11"> 92% say “valid” </td><td  style="white-space:nowrap; text-align:center;" id="TBL-5-4-3"  
class="td11">  8% say “valid”    </td>
</tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-5-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-5-5-1"  
class="td11">                </td></tr></table></div></div>
<!--l. 96--><p class="noindent" >Oh dear, that’s not as good. Apparently, when people are presented with a strong argument
that contradicts our pre-existing beliefs, we ﬁnd it pretty hard to even perceive it to
be a strong argument (people only did so 46% of the time). Even worse, when people
are presented with a weak argument that agrees with our pre-existing biases, almost
no-one can see that the argument is weak (people got that one wrong 92% of the
time!).<span class="footnote-mark"><a 
href="lsj7.html#fn3x2"><sup class="textsuperscript">3</sup></a></span><a 
 id="x4-5001f3"></a> 
</p><!--l. 98--><p class="indent" >   If you think about it, it’s not as if these data are horribly damning. Overall, people did do
better than chance at compensating for their prior biases, since about 60% of people’s judgements
were correct (you’d expect 50% by chance). Even so, if you were a professional “evaluator of
evidence”, and someone came along and oﬀered you a magic tool that improves your chances of
making the right decision from 60% to (say) 95%, you’d probably jump at it, right? Of course you
would. Thankfully, we actually do have a tool that can do this. But it’s not magic, it’s statistics. So
that’s reason #1 why scientists love statistics. It’s just too easy for us to “believe what we want to
                                                                                          

                                                                                          
believe”. So instead, if we want to “believe in the data”, we’re going to need a bit of help to
keep our personal biases under control. That’s what statistics does, it helps keep us
honest.
</p>
   <h3 class="sectionHead"><span class="titlemark">1.2   </span> <a 
 id="x4-60001.2"></a>The cautionary tale of Simpson’s paradox</h3>
<!--l. 110--><p class="noindent" >The following is a true story (I think!). In 1973, the University of California, Berkeley had some
worries about the admissions of students into their postgraduate courses. Speciﬁcally, the thing
that caused the problem was that the gender breakdown of their admissions, which looked like this:
</p>
<div class="center" 
>
<!--l. 111--><p class="noindent" >
</p>
<div class="tabular"> <table id="TBL-6" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-6-1g"><col 
id="TBL-6-1" /><col 
id="TBL-6-2" /><col 
id="TBL-6-3" /></colgroup><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-6-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-6-1-1"  
class="td11">         </td><td  style="white-space:nowrap; text-align:right;" id="TBL-6-1-2"  
class="td11">Number of applicants</td><td  style="white-space:nowrap; text-align:right;" id="TBL-6-1-3"  
class="td11">Percent admitted</td>
</tr><tr 
class="cline"><td></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-6-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-6-3-1"  
class="td11">Males   </td><td  style="white-space:nowrap; text-align:right;" id="TBL-6-3-2"  
class="td11">              8442</td><td  style="white-space:nowrap; text-align:right;" id="TBL-6-3-3"  
class="td11">           44%</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-6-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-6-4-1"  
class="td11">Females</td><td  style="white-space:nowrap; text-align:right;" id="TBL-6-4-2"  
class="td11">              4321</td><td  style="white-space:nowrap; text-align:right;" id="TBL-6-4-3"  
class="td11">           35%</td>
</tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-6-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-6-5-1"  
class="td11">       </td></tr></table></div></div>
<!--l. 121--><p class="noindent" >Given this, they were worried about being sued!<span class="footnote-mark"><a 
href="lsj8.html#fn4x2"><sup class="textsuperscript">4</sup></a></span><a 
 id="x4-6001f4"></a> 
Given that there were nearly 13,000 applicants, a diﬀerence of 9% in admission rates between males
and females is just way too big to be a coincidence. Pretty compelling data, right? And if I were to
say to you that these data actually reﬂect a weak bias in favour of women (sort of!), you’d probably
think that I was either crazy or sexist.
</p><!--l. 123--><p class="indent" >   Oddly, it’s actually sort of true. When people started looking more carefully at the
admissions data they told a rather diﬀerent story (Bickel, Hammel, and O’Connell 1975).
Speciﬁcally, when they looked at it on a department by department basis, it turned
out that most of the departments actually had a slightly higher success rate for female
applicants than for male applicants. The table below shows the admission ﬁgures for the six
largest departments (with the names of the departments removed for privacy reasons):
</p>
<div class="center" 
>
<!--l. 124--><p class="noindent" >
                                                                                          

                                                                                          
</p>
<div class="tabular"> <table id="TBL-7" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-7-1g"><col 
id="TBL-7-1" /><col 
id="TBL-7-2" /><col 
id="TBL-7-3" /><col 
id="TBL-7-4" /><col 
id="TBL-7-5" /><col 
id="TBL-7-6" /></colgroup><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-7-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-7-1-1"  
class="td11">              </td><td colspan="2" style="white-space:nowrap; text-align:center;" id="TBL-7-1-2"  
class="td11">          <div class="multicolumn"  style="white-space:nowrap; text-align:center;">Males</div>            </td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-1-4"  
class="td11"> </td><td colspan="2" style="white-space:nowrap; text-align:center;" id="TBL-7-1-5"  
class="td11">         <div class="multicolumn"  style="white-space:nowrap; text-align:center;">Females</div></td></tr><tr 
class="cline"><td></td><td><hr /></td><td><hr /></td><td></td><td></td><td></td></tr><tr 
class="cline"><td></td><td></td><td></td><td></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-7-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-7-4-1"  
class="td11">Department</td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-4-2"  
class="td11">Applicants</td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-4-3"  
class="td11">Percent admitted</td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-4-4"  
class="td11"> </td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-4-5"  
class="td11">Applicants</td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-4-6"  
class="td11">Percent admitted</td>
</tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-7-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-7-5-1"  
class="td11">A             </td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-5-2"  
class="td11">      825</td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-5-3"  
class="td11">           62%</td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-5-4"  
class="td11"> </td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-5-5"  
class="td11">      108</td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-5-6"  
class="td11">           82%</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-7-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-7-6-1"  
class="td11">B              </td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-6-2"  
class="td11">      560</td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-6-3"  
class="td11">           63%</td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-6-4"  
class="td11"> </td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-6-5"  
class="td11">       25</td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-6-6"  
class="td11">           68%</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-7-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-7-7-1"  
class="td11">C              </td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-7-2"  
class="td11">      325</td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-7-3"  
class="td11">           37%</td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-7-4"  
class="td11"> </td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-7-5"  
class="td11">      593</td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-7-6"  
class="td11">           34%</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-7-8-"><td  style="white-space:nowrap; text-align:left;" id="TBL-7-8-1"  
class="td11">D             </td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-8-2"  
class="td11">      417</td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-8-3"  
class="td11">           33%</td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-8-4"  
class="td11"> </td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-8-5"  
class="td11">      375</td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-8-6"  
class="td11">           35%</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-7-9-"><td  style="white-space:nowrap; text-align:left;" id="TBL-7-9-1"  
class="td11">E              </td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-9-2"  
class="td11">      191</td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-9-3"  
class="td11">           28%</td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-9-4"  
class="td11"> </td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-9-5"  
class="td11">      393</td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-9-6"  
class="td11">           24%</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-7-10-"><td  style="white-space:nowrap; text-align:left;" id="TBL-7-10-1"  
class="td11">F              </td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-10-2"  
class="td11">      272</td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-10-3"  
class="td11">            6%</td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-10-4"  
class="td11"> </td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-10-5"  
class="td11">      341</td><td  style="white-space:nowrap; text-align:right;" id="TBL-7-10-6"  
class="td11">            7%</td>
</tr><tr 
class="hline"><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td><td><hr /></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-7-11-"><td  style="white-space:nowrap; text-align:left;" id="TBL-7-11-1"  
class="td11">          </td></tr></table></div></div>
<!--l. 140--><p class="noindent" >Remarkably, most departments had a higher rate of admissions for females than for males! Yet the
overall rate of admission across the university for females was lower than for males. How can this
be? How can both of these statements be true at the same time?
</p><!--l. 143--><p class="indent" >   Here’s what’s going on. Firstly, notice that the departments are not equal to one another in
terms of their admission percentages: some departments (e.g., A, B) tended to admit a high
percentage of the qualiﬁed applicants, whereas others (e.g., F) tended to reject most of the
candidates, even if they were high quality. So, among the six departments shown above,
notice that department A is the most generous, followed by B, C, D, E and F in that
order. Next, notice that males and females tended to apply to diﬀerent departments.
If we rank the departments in terms of the total number of male applicants, we get
A\00B\00D\00C\00F\00E (the “easy” departments are in bold). On the whole, males tended to apply to
the departments that had high admission rates. Now compare this to how the female
applicants distributed themselves. Ranking the departments in terms of the total number of
female applicants produces a quite diﬀerent ordering C\00E\00D\00F\00A\00B. In other words,
what these data seem to be suggesting is that the female applicants tended to apply to
“harder” departments. And in fact, if we look at Figure <a 
href="#x4-60021">1.1<!--tex4ht:ref: fig:berkeley --></a> we see that this trend is
systematic, and quite striking. This eﬀect is known as <span id="textcolor5">Simpson’s paradox</span>. It’s not
common, but it does happen in real life, and most people are very surprised by it when they
ﬁrst encounter it, and many people refuse to even believe that it’s real. It is very real.
And while there are lots of very subtle statistical lessons buried in there, I want to use
it to make a much more important point: doing research is hard, and there are lots
of subtle, counter-intuitive traps lying in wait for the unwary. That’s reason #2 why
scientists love statistics, and why we teach research methods. Because science is hard,
and the truth is sometimes cunningly hidden in the nooks and crannies of complicated
data.
</p>
   <hr class="figure" /><div class="figure" 
>
                                                                                          

                                                                                          
<a 
 id="x4-60021"></a>
                                                                                          

                                                                                          
<div class="center" 
>
<!--l. 146--><p class="noindent" >
</p><!--l. 147--><p class="noindent" ><img 
src="lsj0x.png" alt="PIC" class="graphics" width="312" height="322"  /><!--tex4ht:graphics  
name="lsj0x.png" src="../img/whystats/berkeleyadmissions3.eps"  
-->
<br /> </p><div class="caption" 
><span class="id">Figure 1.1: </span><span  
class="content">The Berkeley 1973 college admissions data. This ﬁgure plots the admission rate
for the 85 departments that had at least one female applicant, as a function of the percentage
of applicants that were female. The plot is a redrawing of Figure 1 from Bickel et al. (1975).
Circles plot departments with more than 40 applicants; the area of the circle is proportional to
the total number of applicants. The crosses plot departments with fewer than 40 applicants. </span></div><!--tex4ht:label?: x4-60021 -->
</div>
                                                                                          

                                                                                          
   </div><hr class="endfigure" />
<!--l. 154--><p class="indent" >   Before leaving this topic entirely, I want to point out something else really critical
that is often overlooked in a research methods class. Statistics only solves part of the
problem. Remember that we started all this with the concern that Berkeley’s admissions
processes might be unfairly biased against female applicants. When we looked at the
“aggregated” data, it did seem like the university was discriminating against women, but when
we “disaggregate” and looked at the individual behaviour of all the departments, it
turned out that the actual departments were, if anything, slightly biased in favour of
women. The gender bias in total admissions was caused by the fact that women tended to
self-select for harder departments. From a legal perspective, that would probably put the
university in the clear. Postgraduate admissions are determined at the level of the individual
department, and there are good reasons to do that. At the level of individual departments the
decisions are more or less unbiased (the weak bias in favour of females at that level is
small, and not consistent across departments). Since the university can’t dictate which
departments people choose to apply to, and the decision making takes place at the level
of the department it can hardly be held accountable for any biases that those choices
produce.
</p><!--l. 156--><p class="indent" >   That was the basis for my somewhat glib remarks earlier, but that’s not exactly the whole story,
is it? After all, if we’re interested in this from a more sociological and psychological perspective, we
might want to ask why there are such strong gender diﬀerences in applications. Why do males
tend to apply to engineering more often than females, and why is this reversed for the
English department? And why is it the case that the departments that tend to have a
female-application bias tend to have lower overall admission rates than those departments that
have a male-application bias? Might this not still reﬂect a gender bias, even though
every single department is itself unbiased? It might. Suppose, hypothetically, that males
preferred to apply to “hard sciences” and females prefer “humanities”. And suppose
further that the reason for why the humanities departments have low admission rates is
because the government doesn’t want to fund the humanities (Ph.D. places, for instance,
are often tied to government funded research projects). Does that constitute a gender
bias? Or just an unenlightened view of the value of the humanities? What if someone
at a high level in the government cut the humanities funds because they felt that the
humanities are “useless chick stuﬀ”. That seems pretty blatantly gender biased. None of this
falls within the purview of statistics, but it matters to the research project. If you’re
interested in the overall structural eﬀects of subtle gender biases, then you probably want to
look at both the aggregated and disaggregated data. If you’re interested in the decision
making process at Berkeley itself then you’re probably only interested in the disaggregated
data.
</p><!--l. 158--><p class="indent" >   In short there are a lot of critical questions that you can’t answer with statistics, but the
answers to those questions will have a huge impact on how you analyse and interpret data. And
                                                                                          

                                                                                          
this is the reason why you should always think of statistics as a tool to help you learn about your
data. No more and no less. It’s a powerful tool to that end, but there’s no substitute for careful
thought.
</p>
   <h3 class="sectionHead"><span class="titlemark">1.3   </span> <a 
 id="x4-70001.3"></a>Statistics in psychology</h3>
<!--l. 163--><p class="noindent" >I hope that the discussion above helped explain why science in general is so focused on statistics.
But I’m guessing that you have a lot more questions about what role statistics plays in psychology,
and speciﬁcally why psychology classes always devote so many lectures to stats. So here’s my
attempt to answer a few of them...
</p>
      <ul class="itemize1">
      <li class="itemize">Why does psychology have so much statistics?
      <!--l. 169--><p class="noindent" >To be perfectly honest, there’s a few diﬀerent reasons, some of which are better than
      others. The most important reason is that psychology is a statistical science. What
      I  mean  by  that  is  that  the  “things”  that  we  study  are  people.  Real,  complicated,
      gloriously messy, infuriatingly perverse people. The “things” of physics include objects
      like electrons, and while there are all sorts of complexities that arise in physics, electrons
      don’t have minds of their own. They don’t have opinions, they don’t diﬀer from each
      other in weird and arbitrary ways, they don’t get bored in the middle of an experiment,
      and they don’t get angry at the experimenter and then deliberately try to sabotage the
      data set (not that I’ve ever done that!). At a fundamental level psychology is harder than
      physics.<span class="footnote-mark"><a 
href="lsj9.html#fn5x2"><sup class="textsuperscript">5</sup></a></span><a 
 id="x4-7001f5"></a> 
      </p><!--l. 171--><p class="noindent" >Basically, we teach statistics to you as psychologists because you need to be better at
      stats than physicists. There’s actually a saying used sometimes in physics, to the eﬀect
      that “if your experiment needs statistics, you should have done a better experiment”.
      They have the luxury of being able to say that because their objects of study are
      pathetically simple in comparison to the vast mess that confronts social scientists. And
      it’s not just psychology. Most social sciences are desperately reliant on statistics. Not
      because we’re bad experimenters, but because we’ve picked a harder problem to solve.
      We teach you stats because you really, really need it.
      </p></li>
      <li class="itemize">Can’t someone else do the statistics?
                                                                                          

                                                                                          
      <!--l. 175--><p class="noindent" >To some extent, but not completely. It’s true that you don’t need to become a fully
      trained statistician just to do psychology, but you do need to reach a certain level
      of statistical competence. In my view, there’s three reasons that every psychological
      researcher ought to be able to do basic statistics:
</p>
           <ul class="itemize2">
           <li class="itemize">Firstly,  there’s  the  fundamental  reason:  statistics  is  deeply  intertwined  with
           research design. If you want to be good at designing psychological studies, you
           need to at the very least understand the basics of stats.
           </li>
           <li class="itemize">Secondly, if you want to be good at the psychological side of the research, then you
           need to be able to understand the psychological literature, right? But almost every
           paper in the psychological literature reports the results of statistical analyses. So
           if you really want to understand the psychology, you need to be able to understand
           what other people did with their data. And that means understanding a certain
           amount of statistics.
           </li>
           <li class="itemize">Thirdly, there’s a big practical problem with being dependent on other people to
           do all your statistics: statistical analysis is expensive. If you ever get bored and
           want to look up how much the Australian government charges for university fees,
           you’ll notice something interesting: statistics is designated as a “national priority”
           category, and so the fees are much, much lower than for any other area of study.
           This is because there’s a massive shortage of statisticians out there. So, from your
           perspective as a psychological researcher, the laws of supply and demand aren’t
           exactly on your side here! As a result, in almost any real life situation where you
           want to do psychological research, the cruel facts will be that you don’t have
           enough money to aﬀord a statistician. So the economics of the situation mean that
           you have to be pretty self-suﬃcient.</li></ul>
      <!--l. 183--><p class="noindent" >Note that a lot of these reasons generalise beyond researchers. If you want to be a practicing
      psychologist and stay on top of the ﬁeld, it helps to be able to read the scientiﬁc literature,
      which relies pretty heavily on statistics.
      </p></li>
      <li class="itemize">I don’t care about jobs, research, or clinical work. Do I need statistics?
      <!--l. 188--><p class="noindent" >Okay, now you’re just messing with me. Still, I think it should matter to you too. Statistics
      should matter to you in the same way that statistics should matter to everyone. We live in
                                                                                          

                                                                                          
      the 21st century, and data are everywhere. Frankly, given the world in which we live these
      days, a basic knowledge of statistics is pretty damn close to a survival tool! Which is the topic
      of the next section.
</p>
      </li></ul>
<!--l. 192--><p class="noindent" >
</p>
   <h3 class="sectionHead"><span class="titlemark">1.4   </span> <a 
 id="x4-80001.4"></a>Statistics in everyday life</h3>
<!--l. 194--><p class="noindent" >
      </p><div class="quote">
      <!--l. 195--><p class="noindent" >“We are drowning in information,<br 
class="newline" />but we are starved for knowledge” <br 
class="newline" />                    – Various authors, original probably John Naisbitt</p></div>
<!--l. 199--><p class="noindent" >When I started writing up my lecture notes I took the 20 most recent news articles posted to the
ABC news website. Of those 20 articles, it turned out that 8 of them involved a discussion of
something that I would call a statistical topic and 6 of those made a mistake. The most
common error, if you’re curious, was failing to report baseline data (e.g., the article
mentions that 5% of people in situation X have some characteristic Y, but doesn’t say how
common the characteristic is for everyone else!). The point I’m trying to make here
isn’t that journalists are bad at statistics (though they almost always are), it’s that
a basic knowledge of statistics is very helpful for trying to ﬁgure out when someone
else is either making a mistake or even lying to you. In fact, one of the biggest things
that a knowledge of statistics does to you is cause you to get angry at the newspaper
or the internet on a far more frequent basis. You can ﬁnd a good example of this in
Section <a 
href="lsjch4.html#x27-730004.1.5">4.1.5<!--tex4ht:ref: sec:housingpriceexample --></a>. In later versions of this book I’ll try to include more anecdotes along those
lines.
</p><!--l. 203--><p class="noindent" >
</p>
   <h3 class="sectionHead"><span class="titlemark">1.5   </span> <a 
 id="x4-90001.5"></a>There’s more to research methods than statistics</h3>
                                                                                          

                                                                                          
<!--l. 205--><p class="noindent" >So far, most of what I’ve talked about is statistics, and so you’d be forgiven for thinking that
statistics is all I care about in life. To be fair, you wouldn’t be far wrong, but research methodology
is a broader concept than statistics. So most research methods courses will cover a lot of topics that
relate much more to the pragmatics of research design, and in particular the issues that you
encounter when trying to do research with humans. However, about 99% of student fears relate to
the statistics part of the course, so I’ve focused on the stats in this discussion, and hopefully I’ve
convinced you that statistics matters, and more importantly, that it’s not to be feared.
That being said, it’s pretty typical for introductory research methods classes to be very
stats-heavy. This is not (usually) because the lecturers are evil people. Quite the contrary, in
fact. Introductory classes focus a lot on the statistics because you almost always ﬁnd
yourself needing statistics before you need the other research methods training. Why?
Because almost all of your assignments in other classes will rely on statistical training, to a
much greater extent than they rely on other methodological tools. It’s not common for
undergraduate assignments to require you to design your own study from the ground up (in
which case you would need to know a lot about research design), but it is common for
assignments to ask you to analyse and interpret data that were collected in a study
that someone else designed (in which case you need statistics). In that sense, from the
perspective of allowing you to do well in all your other classes, the statistics is more
urgent.
</p><!--l. 207--><p class="indent" >   But note that “urgent” is diﬀerent from “important” – they both matter. I really do want to
stress that research design is just as important as data analysis, and this book does spend a fair
amount of time on it. However, while statistics has a kind of universality, and provides a set of
core tools that are useful for most types of psychological research, the research methods
side isn’t quite so universal. There are some general principles that everyone should
think about, but a lot of research design is very idiosyncratic, and is speciﬁc to the
area of research that you want to engage in. To the extent that it’s the details that
matter, those details don’t usually show up in an introductory stats and research methods
class.
                                                                                          

                                                                                          
</p>
   <!--l. 6--><div class="crosslinks"><p class="noindent">[<a 
href="lsjch2.html" >next</a>] [<a 
href="lsjch1.html" >front</a>] [<a 
href="lsjpa1.html#lsjch1.html" >up</a>] </p></div>
<!--l. 6--><p class="indent" >   <a 
 id="taillsjch1.html"></a>  </p> 
</body></html> 
